<h1 class=title >Code Profiling and Optimization</h1> <h5>Chris Rackauckas</h5> <h5>December 11th, 2020</h5> <h2><a href="https://youtu.be/h-xVBD2Pk9o">Youtube Video</a></h2> <p>This is just a quick look into code profiling. By now we should be writing high performance parallel code which is combining machine learning and scientific computing techniques and doing large-scale parameter analyses on the models. However, at this point it may be difficult to understand where our performance difficulties lie. This is where we turn to code profiling tooling.</p> <h2>Type Inference Checking</h2> <p>The most common way for code to slow down is via type-inference issues. One can normally work through them by &quot;thinking like a compiler&quot; and seeing what would be inferable. For example, a common issue is to not concretely type one&#39;s types. For example:</p> <pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-n'>MyStruct</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractArray</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyStruct</span><span class='hljl-p'>([</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>3</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>x</span><span class='hljl-oB'>.</span><span class='hljl-n'>a</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>InteractiveUtils</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for f&#40;::MyStruct&#41;
  from f&#40;x&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture18/code_profili
ng.jmd:6
Arguments
  #self#::Core.Const&#40;f&#41;
  x::MyStruct
Body::ANY
1 ─ &#37;1 &#61; Base.getproperty&#40;x, :a&#41;::ABSTRACTARRAY
│   &#37;2 &#61; Base.getindex&#40;&#37;1, 1&#41;::ANY
└──      return &#37;2
</pre> <p>In this case, the return type is not inferred and using <code>MyStruct</code> will generate slow code. The reason for this is quite simple: <code>x.a</code> can only be inferred as <code>AbstractArray</code>, and thus the element type <code>x.a&#91;1&#93;</code> and the exact dispatch cannot be known until the function finds out at runtime what kind of array it is. As a result, the compiler throws the only thing it can: it puts <code>Any</code> as the inferred type and runs slow code.</p> <p>We can instead utilize a concrete struct or use a parametric type to create a family of related structs:</p> <pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>MyStruct2</span><span class='hljl-p'>{</span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;:</span><span class='hljl-t'> </span><span class='hljl-n'>AbstractArray</span><span class='hljl-p'>}</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>A</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>x2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyStruct2</span><span class='hljl-p'>([</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>3</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x2</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for f&#40;::MyStruct2&#123;Vector&#123;Int64&#125;&#125;&#41;
  from f&#40;x&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture18/code_profili
ng.jmd:6
Arguments
  #self#::Core.Const&#40;f&#41;
  x::MyStruct2&#123;Vector&#123;Int64&#125;&#125;
Body::Int64
1 ─ &#37;1 &#61; Base.getproperty&#40;x, :a&#41;::Vector&#123;Int64&#125;
│   &#37;2 &#61; Base.getindex&#40;&#37;1, 1&#41;::Int64
└──      return &#37;2
</pre> <p>and now it&#39;s inferred because the information that it would need is inferrable.</p> <p>But what if we needed help? The first tool of course is <code>@code_warntype</code>. But for deeper functions you may want more tooling. A nice tool is Traceur.jl which will alert you to the lines at which you have performance issues. In our example we see:</p> <pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Traceur</span><span class='hljl-t'>
</span><span class='hljl-nd'>@trace</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span>
</pre> <pre><code>┌ Warning: dynamic dispatch to Base.getindex&#40;Base.getfield&#40;x, a&#41;, 1&#41;
└ @ none:-1
┌ Warning: f returns Any
└ @ none:2</code></pre> <p>which points out our first problem is getting the untyped array out of the <code>MyStruct</code>. On larger functions it can do even more:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>naive_sum</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>0</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>xs</span><span class='hljl-t'>
    </span><span class='hljl-n'>s</span><span class='hljl-t'> </span><span class='hljl-oB'>+=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
  </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>s</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@trace</span><span class='hljl-t'> </span><span class='hljl-nf'>naive_sum</span><span class='hljl-p'>([</span><span class='hljl-nfB'>1.</span><span class='hljl-p'>])</span>
</pre> <pre><code>┌ Warning:  is assigned as Tuple&#123;Int64,Int64&#125;
└ @ array.jl:-1
┌ Warning:  is assigned as Nothing
└ @ array.jl:-1
┌ Warning:  is assigned as Union&#123;Nothing, Tuple&#123;Float64,Int64&#125;&#125;
└ @ none:-1
┌ Warning:  is assigned as Union&#123;Nothing, Tuple&#123;Float64,Int64&#125;&#125;
└ @ none:-1
┌ Warning: s is assigned as Int64
└ @ none:-1
┌ Warning: s is assigned as Float64
└ @ none:-1
┌ Warning: naive_sum returns Union&#123;Float64, Int64&#125;
└ @ none:2</code></pre> <p>and alert you to multiple lines which are causing problems.</p> <p>However, for even larger functions you can still have many issues that are hard to dig into with Julia a linear tool. For thus, Cthulhu.jl&#39;s <code>@descend</code> macro lets you interactively dig into the function to find the problematic lines. For the best introduction, watch <a href="https://www.youtube.com/watch?v&#61;qf9oA09wxXY">Valentin Churavy&#39;s JuliaCon 2019 talk</a></p> <h2>Flame Graphs</h2> <p>Flame graphs are a common tool for illustrating performance. To demonstrate this let&#39;s look at the solution to an ODE from DifferentialEquations.jl&#39;s OrdinaryDiffEq.jl. The code is the following:</p> <pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>OrdinaryDiffEq</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>lorenz</span><span class='hljl-p'>(</span><span class='hljl-n'>du</span><span class='hljl-p'>,</span><span class='hljl-n'>u</span><span class='hljl-p'>,</span><span class='hljl-n'>p</span><span class='hljl-p'>,</span><span class='hljl-n'>t</span><span class='hljl-p'>)</span><span class='hljl-t'>
 </span><span class='hljl-n'>du</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>10.0</span><span class='hljl-p'>(</span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-oB'>-</span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>])</span><span class='hljl-t'>
 </span><span class='hljl-n'>du</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-oB'>*</span><span class='hljl-p'>(</span><span class='hljl-nfB'>28.0</span><span class='hljl-oB'>-</span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>3</span><span class='hljl-p'>])</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'>
 </span><span class='hljl-n'>du</span><span class='hljl-p'>[</span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-oB'>*</span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>8</span><span class='hljl-oB'>/</span><span class='hljl-ni'>3</span><span class='hljl-p'>)</span><span class='hljl-oB'>*</span><span class='hljl-n'>u</span><span class='hljl-p'>[</span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>u0</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>;</span><span class='hljl-nfB'>0.0</span><span class='hljl-p'>;</span><span class='hljl-nfB'>0.0</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>tspan</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>100.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>prob</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>ODEProblem</span><span class='hljl-p'>(</span><span class='hljl-n'>lorenz</span><span class='hljl-p'>,</span><span class='hljl-n'>u0</span><span class='hljl-p'>,</span><span class='hljl-n'>tspan</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>sol</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>solve</span><span class='hljl-p'>(</span><span class='hljl-n'>prob</span><span class='hljl-p'>,</span><span class='hljl-nf'>Tsit5</span><span class='hljl-p'>())</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Plots</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-nf'>plot</span><span class='hljl-p'>(</span><span class='hljl-n'>sol</span><span class='hljl-p'>,</span><span class='hljl-n'>vars</span><span class='hljl-oB'>=</span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>3</span><span class='hljl-p'>))</span>
</pre> <pre class=julia-error >
ERROR: Failed to precompile OrdinaryDiffEq &#91;1dea7af3-3e70-54e6-95c3-0bf5283fa5ed&#93; to &quot;/home/runner/.julia/compiled/v1.10/OrdinaryDiffEq/jl_MXa6In&quot;.
</pre> <p>To generate the flame graph, first we want to create a profile. To do this we will use the Profile module&#39;s <code>@profile</code>. Note that a profile should be &quot;sufficiently large&quot;, so on quick functions you may want to run the code plenty of times. Make sure the profile does not include compilation if you want good results&#33;</p> <pre class='hljl'>
<span class='hljl-cs'># No compilation in the results</span><span class='hljl-t'>
</span><span class='hljl-n'>sol</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>solve</span><span class='hljl-p'>(</span><span class='hljl-n'>prob</span><span class='hljl-p'>,</span><span class='hljl-nf'>Tsit5</span><span class='hljl-p'>())</span><span class='hljl-t'>

</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Profile</span><span class='hljl-t'>
</span><span class='hljl-cs'># Profile 1000 runs</span><span class='hljl-t'>
</span><span class='hljl-nd'>@profile</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>1000</span><span class='hljl-t'> </span><span class='hljl-n'>sol</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>solve</span><span class='hljl-p'>(</span><span class='hljl-n'>prob</span><span class='hljl-p'>,</span><span class='hljl-nf'>Tsit5</span><span class='hljl-p'>())</span><span class='hljl-t'> </span><span class='hljl-k'>end</span>
</pre> <pre class=julia-error >
ERROR: UndefVarError: &#96;prob&#96; not defined
</pre> <p>This profiler is a statistical or sampling profiler, which means it periodically samples where it is at in a code and thus understands the hotspots in the code by tallying how many samples are in a certain area. We can first visualize this by printing it out:</p> <pre class='hljl'>
<span class='hljl-cs'>#Profile.print()</span>
</pre> <p>However, that printout can often times be hard to read. Instead, we can visualize it with a <em>flame graph</em>. There are many ways to get the flame graph, if you&#39;re in Juno, you can simply do:</p> <pre class='hljl'>
<span class='hljl-n'>Juno</span><span class='hljl-oB'>.</span><span class='hljl-nf'>profiler</span><span class='hljl-p'>()</span>
</pre> <p><img src="https://user-images.githubusercontent.com/1814174/69931716-45633180-1496-11ea-888e-e7bcde939083.PNG" alt="" /></p> <p>&#40;Note that if you&#39;re not using Juno, there are equivalent tools in the package ecosystem. ProfileView.jl is a very simple flame graph generator, and PProf.jl exports to Google PProf which has many more features&#41;</p> <p>Each block corresponds to a function call. The horizontal length is the amount of time spent in that function, while the vertical grouping is for call nesting, i.e. you are below the function that called you. The portion that is circled is where the mouse pointer was at, and while hovering over this it said what function it corresponded to: <code>recursivecopy</code> in RecursiveArrayTools.jl. If we click on this, it sends us to the hotspot:</p> <p><img src="https://user-images.githubusercontent.com/1814174/69931830-ad197c80-1496-11ea-80bd-4c0f134d120f.PNG" alt="" /></p> <p>Juno gives you a light indicator that tells you how much time is spent at a given line. Here we see that most of the time is spent inside of the <code>map</code> operation which calls <code>recursivecopy</code> on the elements, which then does <code>copy&#40;a&#41;</code>.</p> <p>This tells us that the main cost of our code is the part that is copying the arrays to save them&#33; Thus let&#39;s generate a new profile where the ODE solver saves less:</p> <pre class='hljl'>
<span class='hljl-n'>Profile</span><span class='hljl-oB'>.</span><span class='hljl-nf'>clear</span><span class='hljl-p'>()</span><span class='hljl-t'>
</span><span class='hljl-cs'># No compilation in the results</span><span class='hljl-t'>
</span><span class='hljl-n'>sol</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>solve</span><span class='hljl-p'>(</span><span class='hljl-n'>prob</span><span class='hljl-p'>,</span><span class='hljl-nf'>Tsit5</span><span class='hljl-p'>(),</span><span class='hljl-n'>save_everystep</span><span class='hljl-oB'>=</span><span class='hljl-kc'>false</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-cs'># Profile 1000 runs</span><span class='hljl-t'>
</span><span class='hljl-nd'>@profile</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>1000</span><span class='hljl-t'> </span><span class='hljl-n'>sol</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>solve</span><span class='hljl-p'>(</span><span class='hljl-n'>prob</span><span class='hljl-p'>,</span><span class='hljl-nf'>Tsit5</span><span class='hljl-p'>(),</span><span class='hljl-n'>save_everystep</span><span class='hljl-oB'>=</span><span class='hljl-kc'>false</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>end</span>
</pre> <pre class=julia-error >
ERROR: UndefVarError: &#96;Profile&#96; not defined
</pre> <pre class='hljl'>
<span class='hljl-n'>Juno</span><span class='hljl-oB'>.</span><span class='hljl-nf'>profiler</span><span class='hljl-p'>()</span>
</pre> <p><img src="https://user-images.githubusercontent.com/1814174/69931923-08e40580-1497-11ea-9583-2d76af8316e4.PNG" alt="" /></p> <p>Now we see that the majority of the time is spent in the <code>perform_step&#33;</code> method, which is:</p> <p><img src="https://user-images.githubusercontent.com/1814174/69931943-2add8800-1497-11ea-94f8-b244dcac12f4.PNG" alt="" /></p> <p>We can notice that there is still quite a bit of jitter in the profile since each of the <code>f</code> calls here should be exactly the same length, but upping the number of solves in the loop would help with that:</p> <pre class='hljl'>
<span class='hljl-nd'>@profile</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>10000</span><span class='hljl-t'> </span><span class='hljl-n'>sol</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>solve</span><span class='hljl-p'>(</span><span class='hljl-n'>prob</span><span class='hljl-p'>,</span><span class='hljl-nf'>Tsit5</span><span class='hljl-p'>(),</span><span class='hljl-n'>save_everystep</span><span class='hljl-oB'>=</span><span class='hljl-kc'>false</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>end</span>
</pre> <pre class=julia-error >
ERROR: LoadError: UndefVarError: &#96;@profile&#96; not defined
in expression starting at /home/runner/work/SciMLBook/SciMLBook/_weave/lecture18/code_profiling.jmd:2
</pre> <pre class='hljl'>
<span class='hljl-n'>Juno</span><span class='hljl-oB'>.</span><span class='hljl-nf'>profiler</span><span class='hljl-p'>()</span>
</pre> <p><img src="https://user-images.githubusercontent.com/1814174/69932011-755f0480-1497-11ea-8839-ecc8f5d7c9fc.PNG" alt="" /></p> <p>Now that this looks like a fairly good profile, we can use this to dig in and find out what lines need to be optimized&#33;</p> <div class=footer > <p> Published from <a href=code_profiling.jmd >code_profiling.jmd</a> using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.9 on 2024-04-09. </p> </div>