<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=icon  href="/assets/favicon.png"> <link rel=stylesheet  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> <link rel=stylesheet  href="/css/weave.css"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}, TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> <title>Optimizing Serial Code - MIT Parallel Computing and Scientific Machine Learning (SciML)</title> <div id=layout > <div id=menu > <ul> <li><a style="font-size:larger;" href=https://github.com/SciML/SciMLBook><i class="fa fa-github"></i></a> <li><a style="font-size:larger;" href="/">Home</a> <li><a style="font-size:larger;" href="/course/">Course</a> <li><a style="font-size:larger;" href="/homework/">Homework</a> <li><a style="font-size:larger;" href="/lectures/">Lectures</a> <li><a style="font-size:larger;" href="/notes/">Notes</a> <ul style="font-size:smaller"> <li><a href="/notes/02-Optimizing_Serial_Code/">02: Serial Code</a> <li><a href="/notes/03-Introduction_to_Scientific_Machine_Learning_through_Physics-Informed_Neural_Networks/">03: SciML Intro</a> <li><a href="/notes/04-How_Loops_Work-An_Introduction_to_Discrete_Dynamics/">04: How Loops Work</a> <li><a href="/notes/05-The_Basics_of_Single_Node_Parallel_Computing/">05: Basics of Parallelism</a> <li><a href="/notes/06-The_Different_Flavors_of_Parallelism/">06: Flavors of Parallelism</a> <li><a href="/notes/07-Ordinary_Differential_Equations-Applications_and_Discretizations/">07: ODEs</a> <li><a href="/notes/08-Forward-Mode_Automatic_Differentiation_(AD)_via_High_Dimensional_Algebras/">08: Forward AD</a> <li><a href="/notes/09-Solving_Stiff_Ordinary_Differential_Equations/">09: Stiff ODEs</a> <li><a href="/notes/10-Basic_Parameter_Estimation-Reverse-Mode_AD-and_Inverse_Problems/">10: Reverse AD</a> <li><a href="/notes/11-Differentiable_Programming_and_Neural_Differential_Equations/">11: δP</a> <li><a href="/notes/12-Description_of_MPI_and_MPI/">12: MPI</a> <li><a href="/notes/13-GPU_programming/">13: GPUs</a> <li><a href="/notes/14-PDEs_Convolutions_and_the_Mathematics_of_Locality/">14: PDEs</a> <li><a href="/notes/15-Mixing_Differential_Equations_and_Neural_Networks_for_Physics-Informed_Learning/">15: Physics Informed Learning</a> <li><a href="/notes/16-From_Optimization_to_Probabilistic_Programming/">16: Probabilistic Programming</a> <li><a href="/notes/17-Global_Sensitivity_Analysis/">17: Global Sensitivity Analysis</a> <li><a href="/notes/18-Code_Profiling_and_Optimization/">18: Profiling & Optimization</a> <li><a href="/notes/19-Uncertainty_Programming-Generalized_Uncertainty_Quantification/">19: Uncertainty Programming</a> </ul> </ul> </div> <div id=main > <div class=franklin-content > <h1 class=title >Optimizing Serial Code</h1> <h5>Chris Rackauckas</h5> <h5>September 3rd, 2019</h5> <h2><a href="https://youtu.be/M2i7sSRcSIw">Youtube Video Link Part 1</a></h2> <h2><a href="https://youtu.be/10_Ukm9wr9g">Youtube Video Link Part 2</a></h2> <p>At the center of any fast parallel code is a fast serial code. Parallelism is made to be a performance multiplier, so if you start from a bad position it won&#39;t ever get much better. Thus the first thing that we need to do is understand what makes code slow and how to avoid the pitfalls. This discussion of serial code optimization will also directly motivate why we will be using Julia throughout this course.</p> <h2>Mental Model of a Memory</h2> <p>To start optimizing code you need a good mental model of a computer.</p> <h3>High Level View</h3> <p>At the highest level you have a CPU&#39;s core memory which directly accesses a L1 cache. The L1 cache has the fastest access, so things which will be needed soon are kept there. However, it is filled from the L2 cache, which itself is filled from the L3 cache, which is filled from the main memory. This bring us to the first idea in optimizing code: using things that are already in a closer cache can help the code run faster because it doesn&#39;t have to be queried for and moved up this chain.</p> <p><img src="https://hackernoon.com/hn-images/1*nT3RAGnOAWmKmvOBnizNtw.png" alt="" /></p> <p>When something needs to be pulled directly from main memory this is known as a <em>cache miss</em>. To understand the cost of a cache miss vs standard calculations, take a look at <a href="http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/">this classic chart</a>.</p> <p>&#40;Cache-aware and cache-oblivious algorithms are methods which change their indexing structure to optimize their use of the cache lines. We will return to this when talking about performance of linear algebra.&#41;</p> <h3>Cache Lines and Row/Column-Major</h3> <p>Many algorithms in numerical linear algebra are designed to minimize cache misses. Because of this chain, many modern CPUs try to guess what you will want next in your cache. When dealing with arrays, it will speculate ahead and grab what is known as a <em>cache line</em>: the next chunk in the array. Thus, your algorithms will be faster if you iterate along the values that it is grabbing.</p> <p>The values that it grabs are the next values in the contiguous order of the stored array. There are two common conventions: row major and column major. Row major means that the linear array of memory is formed by stacking the rows one after another, while column major puts the column vectors one after another.</p> <p><img src="https://eli.thegreenplace.net/images/2015/column-major-2D.png" alt="" /></p> <p><em>Julia, MATLAB, and Fortran are column major</em>. Python&#39;s numpy is row-major.</p> <pre class='hljl'>
<span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>B</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>C</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-ni'>100</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>BenchmarkTools</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_rows!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_rows!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
7.569 μs &#40;0 allocations: 0 bytes&#41;
</pre> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_cols!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_cols!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
2.422 μs &#40;0 allocations: 0 bytes&#41;
</pre> <h3>Lower Level View: The Stack and the Heap</h3> <p>Locally, the stack is composed of a <em>stack</em> and a <em>heap</em>. The stack requires a static allocation: it is ordered. Because it&#39;s ordered, it is very clear where things are in the stack, and therefore accesses are very quick &#40;think instantaneous&#41;. However, because this is static, it requires that the size of the variables is known at compile time &#40;to determine all of the variable locations&#41;. Since that is not possible with all variables, there exists the heap. The heap is essentially a stack of pointers to objects in memory. When heap variables are needed, their values are pulled up the cache chain and accessed.</p> <p><img src="https://bayanbox.ir/view/581244719208138556/virtual-memory.jpg" alt="" /> <img src="https://camo.githubusercontent.com/ca96d70d09ce694363e44b93fd975bb3033898c1/687474703a2f2f7475746f7269616c732e6a656e6b6f762e636f6d2f696d616765732f6a6176612d636f6e63757272656e63792f6a6176612d6d656d6f72792d6d6f64656c2d352e706e67" alt="" /></p> <h3>Heap Allocations and Speed</h3> <p>Heap allocations are costly because they involve this pointer indirection, so stack allocation should be done when sensible &#40;it&#39;s not helpful for really large arrays, but for small values like scalars it&#39;s essential&#33;&#41;</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_alloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_alloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
234.630 μs &#40;10000 allocations: 625.00 KiB&#41;
</pre> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
2.425 μs &#40;0 allocations: 0 bytes&#41;
</pre> <p>Why does the array here get heap-allocated? It isn&#39;t able to prove/guarantee at compile-time that the array&#39;s size will always be a given value, and thus it allocates it to the heap. <code>@btime</code> tells us this allocation occurred and shows us the total heap memory that was taken. Meanwhile, the size of a Float64 number is known at compile-time &#40;64-bits&#41;, and so this is stored onto the stack and given a specific location that the compiler will be able to directly address.</p> <p>Note that one can use the StaticArrays.jl library to get statically-sized arrays and thus arrays which are stack-allocated:</p> <pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>StaticArrays</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>static_inner_alloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@SVector</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>static_inner_alloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
2.422 μs &#40;0 allocations: 0 bytes&#41;
</pre> <h3>Mutation to Avoid Heap Allocations</h3> <p>Many times you do need to write into an array, so how can you write into an array without performing a heap allocation? The answer is mutation. Mutation is changing the values of an already existing array. In that case, no free memory has to be found to put the array &#40;and no memory has to be freed by the garbage collector&#41;.</p> <p>In Julia, functions which mutate the first value are conventionally noted by a <code>&#33;</code>. See the difference between these two equivalent functions:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
2.421 μs &#40;0 allocations: 0 bytes&#41;
</pre> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_alloc</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>C</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>similar</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_alloc</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
7.349 μs &#40;2 allocations: 78.17 KiB&#41;
</pre> <p>To use this algorithm effectively, the <code>&#33;</code> algorithm assumes that the caller already has allocated the output array to put as the output argument. If that is not true, then one would need to manually allocate. The goal of that interface is to give the caller control over the allocations to allow them to manually reduce the total number of heap allocations and thus increase the speed.</p> <h3>Julia&#39;s Broadcasting Mechanism</h3> <p>Wouldn&#39;t it be nice to not have to write the loop there? In many high level languages this is simply called <em>vectorization</em>. In Julia, we will call it <em>array vectorization</em> to distinguish it from the <em>SIMD vectorization</em> which is common in lower level languages like C, Fortran, and Julia.</p> <p>In Julia, if you use <code>.</code> on an operator it will transform it to the broadcasted form. Broadcast is <em>lazy</em>: it will build up an entire <code>.</code>&#39;d expression and then call <code>broadcast&#33;</code> on composed expression. This is customizable and <a href="https://docs.julialang.org/en/v1/manual/interfaces/#man-interfaces-broadcasting-1">documented in detail</a>. However, to a first approximation we can think of the broadcast mechanism as a mechanism for building <em>fused expressions</em>. For example, the Julia code:</p> <pre class='hljl'>
<span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>C</span><span class='hljl-p'>;</span>
</pre> <p>under the hood lowers to something like:</p> <pre class='hljl'>
<span class='hljl-nf'>map</span><span class='hljl-p'>((</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-oB'>-&gt;</span><span class='hljl-n'>a</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>+</span><span class='hljl-n'>c</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>);</span>
</pre> <p>where <code>map</code> is a function that just loops over the values element-wise.</p> <p><strong>Take a quick second to think about why loop fusion may be an optimization.</strong></p> <p>This about what would happen if you did not fuse the operations. We can write that out as:</p> <pre class='hljl'>
<span class='hljl-n'>tmp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-t'>
</span><span class='hljl-n'>tmp</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>C</span><span class='hljl-p'>;</span>
</pre> <p>Notice that if we did not fuse the expressions, we would need some place to put the result of <code>A .&#43; B</code>, and that would have to be an array, which means it would cause a heap allocation. Thus broadcast fusion eliminates the <em>temporary variable</em> &#40;colloquially called just a <em>temporary</em>&#41;.</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>unfused</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>tmp</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-t'>
  </span><span class='hljl-n'>tmp</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>C</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>unfused</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>);</span>
</pre> <pre class=output >
9.778 μs &#40;4 allocations: 156.34 KiB&#41;
</pre> <pre class='hljl'>
<span class='hljl-nf'>fused</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>C</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>fused</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>);</span>
</pre> <pre class=output >
5.510 μs &#40;2 allocations: 78.17 KiB&#41;
</pre> <p>Note that we can also fuse the output by using <code>.&#61;</code>. This is essentially the vectorized version of a <code>&#33;</code> function:</p> <pre class='hljl'>
<span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>similar</span><span class='hljl-p'>(</span><span class='hljl-n'>A</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>fused!</span><span class='hljl-p'>(</span><span class='hljl-n'>D</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>D</span><span class='hljl-t'> </span><span class='hljl-oB'>.=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-t'> </span><span class='hljl-oB'>.+</span><span class='hljl-t'> </span><span class='hljl-n'>C</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>fused!</span><span class='hljl-p'>(</span><span class='hljl-n'>D</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-p'>);</span>
</pre> <pre class=output >
3.504 μs &#40;0 allocations: 0 bytes&#41;
</pre> <h3>Note on Broadcasting Function Calls</h3> <p>Julia allows for broadcasting the call <code>&#40;&#41;</code> operator as well. <code>.&#40;&#41;</code> will call the function element-wise on all arguments, so <code>sin.&#40;A&#41;</code> will be the elementwise sine function. This will fuse Julia like the other operators.</p> <h3>Note on Vectorization and Speed</h3> <p>In articles on MATLAB, Python, R, etc., this is where you will be told to vectorize your code. Notice from above that this isn&#39;t a performance difference between writing loops and using vectorized broadcasts. This is not abnormal&#33; The reason why you are told to vectorize code in these other languages is because they have a high per-operation overhead &#40;which will be discussed further down&#41;. This means that every call, like <code>&#43;</code>, is costly in these languages. To get around this issue and make the language usable, someone wrote and compiled the loop for the C/Fortran function that does the broadcasted form &#40;see numpy&#39;s Github repo&#41;. Thus <code>A .&#43; B</code>&#39;s MATLAB/Python/R equivalents are calling a single C function to generally avoid the cost of function calls and thus are faster.</p> <p>But this is not an intrinsic property of vectorization. Vectorization isn&#39;t &quot;fast&quot; in these languages, it&#39;s just close to the correct speed. The reason vectorization is recommended is because looping is slow in these languages. Because looping isn&#39;t slow in Julia &#40;or C, C&#43;&#43;, Fortran, etc.&#41;, loops and vectorization generally have the same speed. So use the one that works best for your code without a care about performance.</p> <p>&#40;As a small side effect, these high level languages tend to allocate a lot of temporary variables since the individual C kernels are written for specific numbers of inputs and thus don&#39;t naturally fuse. Julia&#39;s broadcast mechanism is just generating and JIT compiling Julia functions on the fly, and thus it can accommodate the combinatorial explosion in the amount of choices just by only compiling the combinations that are necessary for a specific code&#41;</p> <h3>Heap Allocations from Slicing</h3> <p>It&#39;s important to note that slices in Julia produce copies instead of views. Thus for example:</p> <pre class='hljl'>
<span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-ni'>50</span><span class='hljl-p'>,</span><span class='hljl-ni'>50</span><span class='hljl-p'>]</span>
</pre> <pre class=output >
0.4309718283801406
</pre> <p>allocates a new output. This is for safety, since if it pointed to the same array then writing to it would change the original array. We can demonstrate this by asking for a <em>view</em> instead of a copy.</p> <pre class='hljl'>
<span class='hljl-nd'>@show</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>E</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@view</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>5</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>5</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>E</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>2.0</span><span class='hljl-t'>
</span><span class='hljl-nd'>@show</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span>
</pre> <pre class=output >
A&#91;1&#93; &#61; 0.8732593203756598
A&#91;1&#93; &#61; 2.0
2.0
</pre> <p>However, this means that <code>@view A&#91;1:5,1:5&#93;</code> did not allocate an array &#40;it does allocate a pointer if the escape analysis is unable to prove that it can be elided. This means that in small loops there will be no allocation, while if the view is returned from a function for example it will allocate the pointer, ~80 bytes, but not the memory of the array. This means that it is O&#40;1&#41; in cost but with a relatively small constant&#41;.</p> <h3>Asymptotic Cost of Heap Allocations</h3> <p>Heap allocations have to locate and prepare a space in RAM that is proportional to the amount of memory that is calculated, which means that the cost of a heap allocation for an array is O&#40;n&#41;, with a large constant. As RAM begins to fill up, this cost dramatically increases. If you run out of RAM, your computer may begin to use <em>swap</em>, which is essentially RAM simulated on your hard drive. Generally when you hit swap your performance is so dead that you may think that your computation froze, but if you check your resource use you will notice that it&#39;s actually just filled the RAM and starting to use the swap.</p> <p>But think of it as O&#40;n&#41; with a large constant factor. This means that for operations which only touch the data once, heap allocations can dominate the computational cost:</p> <pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>LinearAlgebra</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>BenchmarkTools</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>alloc_timer</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>,</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>B</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>,</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>,</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>t1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@belapsed</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.*</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>B</span><span class='hljl-t'>
    </span><span class='hljl-n'>t2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@belapsed</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-oB'>$</span><span class='hljl-n'>C</span><span class='hljl-t'> </span><span class='hljl-oB'>.=</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>.*</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>t1</span><span class='hljl-p'>,</span><span class='hljl-n'>t2</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>ns</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-oB'>:</span><span class='hljl-ni'>11</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>res</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>alloc_timer</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>n</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>ns</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>alloc</span><span class='hljl-t'>   </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>res</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>noalloc</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>res</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Plots</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot</span><span class='hljl-p'>(</span><span class='hljl-n'>ns</span><span class='hljl-p'>,</span><span class='hljl-n'>alloc</span><span class='hljl-p'>,</span><span class='hljl-n'>label</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;=&quot;</span><span class='hljl-p'>,</span><span class='hljl-n'>xscale</span><span class='hljl-oB'>=:</span><span class='hljl-n'>log10</span><span class='hljl-p'>,</span><span class='hljl-n'>yscale</span><span class='hljl-oB'>=:</span><span class='hljl-n'>log10</span><span class='hljl-p'>,</span><span class='hljl-n'>legend</span><span class='hljl-oB'>=:</span><span class='hljl-n'>bottomright</span><span class='hljl-p'>,</span><span class='hljl-t'>
     </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;Micro-optimizations matter for BLAS1&quot;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot!</span><span class='hljl-p'>(</span><span class='hljl-n'>ns</span><span class='hljl-p'>,</span><span class='hljl-n'>noalloc</span><span class='hljl-p'>,</span><span class='hljl-n'>label</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;.=&quot;</span><span class='hljl-p'>)</span>
</pre> <img src="data:image/png;base64,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" /> <p>However, when the computation takes O&#40;n^3&#41;, like in matrix multiplications, the high constant factor only comes into play when the matrices are sufficiently small:</p> <pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>LinearAlgebra</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>BenchmarkTools</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>alloc_timer</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>,</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>B</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>,</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>,</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>t1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@belapsed</span><span class='hljl-t'> </span><span class='hljl-oB'>$</span><span class='hljl-n'>A</span><span class='hljl-oB'>*$</span><span class='hljl-n'>B</span><span class='hljl-t'>
    </span><span class='hljl-n'>t2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@belapsed</span><span class='hljl-t'> </span><span class='hljl-nf'>mul!</span><span class='hljl-p'>(</span><span class='hljl-oB'>$</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-oB'>$</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-oB'>$</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>t1</span><span class='hljl-p'>,</span><span class='hljl-n'>t2</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-n'>ns</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'> </span><span class='hljl-oB'>.^</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-oB'>:</span><span class='hljl-ni'>7</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>res</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>alloc_timer</span><span class='hljl-p'>(</span><span class='hljl-n'>n</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>n</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>ns</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>alloc</span><span class='hljl-t'>   </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>res</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>noalloc</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>res</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Plots</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot</span><span class='hljl-p'>(</span><span class='hljl-n'>ns</span><span class='hljl-p'>,</span><span class='hljl-n'>alloc</span><span class='hljl-p'>,</span><span class='hljl-n'>label</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;*&quot;</span><span class='hljl-p'>,</span><span class='hljl-n'>xscale</span><span class='hljl-oB'>=:</span><span class='hljl-n'>log10</span><span class='hljl-p'>,</span><span class='hljl-n'>yscale</span><span class='hljl-oB'>=:</span><span class='hljl-n'>log10</span><span class='hljl-p'>,</span><span class='hljl-n'>legend</span><span class='hljl-oB'>=:</span><span class='hljl-n'>bottomright</span><span class='hljl-p'>,</span><span class='hljl-t'>
     </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;Micro-optimizations only matter for small matmuls&quot;</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot!</span><span class='hljl-p'>(</span><span class='hljl-n'>ns</span><span class='hljl-p'>,</span><span class='hljl-n'>noalloc</span><span class='hljl-p'>,</span><span class='hljl-n'>label</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;mul!&quot;</span><span class='hljl-p'>)</span>
</pre> <img src="data:image/png;base64,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" /> <p>Though using a mutating form is never bad and always is a little bit better.</p> <h3>Optimizing Memory Use Summary</h3> <ul> <li><p>Avoid cache misses by reusing values</p> <li><p>Iterate along columns</p> <li><p>Avoid heap allocations in inner loops</p> <li><p>Heap allocations occur when the size of things is not proven at compile-time</p> <li><p>Use fused broadcasts &#40;with mutated outputs&#41; to avoid heap allocations</p> <li><p>Array vectorization confers no special benefit in Julia because Julia loops are as fast as C or Fortran</p> <li><p>Use views instead of slices when applicable</p> <li><p>Avoiding heap allocations is most necessary for O&#40;n&#41; algorithms or algorithms with small arrays</p> <li><p>Use StaticArrays.jl to avoid heap allocations of small arrays in inner loops</p> </ul> <h2>Julia&#39;s Type Inference and the Compiler</h2> <p>Many people think Julia is fast because it is JIT compiled. That is simply not true &#40;we&#39;ve already shown examples where Julia code isn&#39;t fast, but it&#39;s always JIT compiled&#33;&#41;. Instead, the reason why Julia is fast is because the combination of two ideas:</p> <ul> <li><p>Type inference</p> <li><p>Type specialization in functions</p> </ul> <p>These two features naturally give rise to Julia&#39;s core design feature: multiple dispatch. Let&#39;s break down these pieces.</p> <h3>Type Inference</h3> <p>At the core level of the computer, everything has a type. Some languages are more explicit about said types, while others try to hide the types from the user. A type tells the compiler how to to store and interpret the memory of a value. For example, if the compiled code knows that the value in the register is supposed to be interpreted as a 64-bit floating point number, then it understands that slab of memory like:</p> <p><img src="https://i.stack.imgur.com/ZUbLc.png" alt="" /></p> <p>Importantly, it will know what to do for function calls. If the code tells it to add two floating point numbers, it will send them as inputs to the Floating Point Unit &#40;FPU&#41; which will give the output.</p> <p>If the types are not known, then... ? So one cannot actually compute until the types are known, since otherwise it&#39;s impossible to interpret the memory. In languages like C, the programmer has to declare the types of variables in the program:</p> <pre><code>void add&#40;double *a, double *b, double *c, size_t n&#41;&#123;
  size_t i;
  for&#40;i &#61; 0; i &lt; n; &#43;&#43;i&#41; &#123;
    c&#91;i&#93; &#61; a&#91;i&#93; &#43; b&#91;i&#93;;
  &#125;
&#125;</code></pre> <p>The types are known at compile time because the programmer set it in stone. In many interpreted languages Python, types are checked at runtime. For example,</p> <pre><code>a &#61; 2
b &#61; 4
a &#43; b</code></pre> <p>when the addition occurs, the Python interpreter will check the object holding the values and ask it for its types, and use those types to know how to compute the &#43; function. For this reason, the add function in Python is rather complex since it needs to decode and have a version for all primitive types&#33;</p> <p>Not only is there runtime overhead checks in function calls due to to not being explicit about types, there is also a memory overhead since it is impossible to know how much memory a value with take since that&#39;s a property of its type. Thus the Python interpreter cannot statically guarantee exact unchanging values for the size that a value would take in the stack, meaning that the variables are not stack-allocated. This means that every number ends up heap-allocated, which hopefully begins to explain why this is not as fast as C.</p> <p>The solution is Julia is somewhat of a hybrid. The Julia code looks like:</p> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
</span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
</span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>b</span>
</pre> <pre class=output >
6
</pre> <p>However, before JIT compilation, Julia runs a type inference algorithm which finds out that <code>A</code> is an <code>Int</code>, and <code>B</code> is an <code>Int</code>. You can then understand that if it can prove that <code>A&#43;B</code> is an <code>Int</code>, then it can propagate all of the types through.</p> <h3>Type Specialization in Functions</h3> <p>Julia is able to propagate type inference through functions because, even if a function is &quot;untyped&quot;, Julia will interpret this as a <em>generic function</em> over possible <em>methods</em>, where every method has a concrete type. This means that in Julia, the function:</p> <pre class='hljl'>
<span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>+</span><span class='hljl-n'>y</span>
</pre> <pre class=output >
f &#40;generic function with 1 method&#41;
</pre> <p>is not what you may think of as a &quot;single function&quot;, since given inputs of different types it will actually be a different function. We can see this by examining the <em>LLVM IR</em> &#40;LLVM is Julia&#39;s compiler, the IR is the <em>Intermediate Representation</em>, i.e. a platform-independent representation of assembly that lives in LLVM that it knows how to convert into assembly per architecture&#41;:</p> <pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>InteractiveUtils</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;f&#96;
define i64 @julia_f_3079&#40;i64 signext &#37;0, i64 signext &#37;1&#41; #0 &#123;
top:
; ┌ @ int.jl:87 within &#96;&#43;&#96;
   &#37;2 &#61; add i64 &#37;1, &#37;0
   ret i64 &#37;2
; └
&#125;
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>5.0</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;f&#96;
define double @julia_f_3081&#40;double &#37;0, double &#37;1&#41; #0 &#123;
top:
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;2 &#61; fadd double &#37;0, &#37;1
   ret double &#37;2
; └
&#125;
</pre> <p>Notice that when <code>f</code> is the function that takes in two <code>Int</code>s, <code>Int</code>s add to give an <code>Int</code> and thus <code>f</code> outputs an <code>Int</code>. When <code>f</code> is the function that takes two <code>Float64</code>s, <code>f</code> returns a <code>Float64</code>. Thus in the code:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
  </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-n'>c</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;g&#96;
define i64 @julia_g_3083&#40;i64 signext &#37;0, i64 signext &#37;1&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ int.jl:87 within &#96;&#43;&#96;
    &#37;2 &#61; add i64 &#37;0, 6
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
7 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ int.jl:87 within &#96;&#43;&#96;
    &#37;3 &#61; add i64 &#37;2, &#37;1
    ret i64 &#37;3
; └└
&#125;
</pre> <p><code>g</code> on two <code>Int</code> inputs is a function that has <code>Int</code>s at every step along the way and spits out an <code>Int</code>. We can use the <code>@code_warntype</code> macro to better see the inference along the steps of the function:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for g&#40;::Int64, ::Int64&#41;
  from g&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;g&#41;
  x::Int64
  y::Int64
Locals
  d::Int64
  c::Int64
  b::Int64
  a::Int64
Body::Int64
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│        &#40;c &#61; Main.f&#40;x, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;5 &#61; Main.f&#40;d, y&#41;::Int64
└──      return &#37;5
</pre> <p>What happens on mixtures?</p> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;f&#96;
define double @julia_f_3542&#40;double &#37;0, i64 signext &#37;1&#41; #0 &#123;
top:
; ┌ @ promotion.jl:422 within &#96;&#43;&#96;
; │┌ @ promotion.jl:393 within &#96;promote&#96;
; ││┌ @ promotion.jl:370 within &#96;_promote&#96;
; │││┌ @ number.jl:7 within &#96;convert&#96;
; ││││┌ @ float.jl:159 within &#96;Float64&#96;
       &#37;2 &#61; sitofp i64 &#37;1 to double
; │└└└└
; │ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
   &#37;3 &#61; fadd double &#37;2, &#37;0
   ret double &#37;3
; └
&#125;
</pre> <p>When we add an <code>Int</code> to a <code>Float64</code>, we promote the <code>Int</code> to a <code>Float64</code> and then perform the <code>&#43;</code> between two <code>Float64</code>s. When we go to the full function, we see that it can still infer:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for g&#40;::Float64, ::Int64&#41;
  from g&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;g&#41;
  x::Float64
  y::Int64
Locals
  d::Float64
  c::Float64
  b::Int64
  a::Int64
Body::Float64
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│        &#40;c &#61; Main.f&#40;x, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;5 &#61; Main.f&#40;d, y&#41;::Float64
└──      return &#37;5
</pre> <p>and it uses this to build a very efficient assembly code because it knows exactly what the types will be at every step:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;g&#96;
define double @julia_g_3545&#40;double &#37;0, i64 signext &#37;1&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
    &#37;2 &#61; fadd double &#37;0, 4.000000e&#43;00
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
    &#37;3 &#61; fadd double &#37;2, 2.000000e&#43;00
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
7 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ promotion.jl:422 within &#96;&#43;&#96;
; ││┌ @ promotion.jl:393 within &#96;promote&#96;
; │││┌ @ promotion.jl:370 within &#96;_promote&#96;
; ││││┌ @ number.jl:7 within &#96;convert&#96;
; │││││┌ @ float.jl:159 within &#96;Float64&#96;
        &#37;4 &#61; sitofp i64 &#37;1 to double
; ││└└└└
; ││ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
    &#37;5 &#61; fadd double &#37;3, &#37;4
    ret double &#37;5
; └└
&#125;
</pre> <p>&#40;notice how it handles the constant <em>literals</em> 4 and 2: it converted them at compile time to reduce the algorithm to 3 floating point additions&#41;.</p> <h3>Type Stability</h3> <p>Why is the inference algorithm able to infer all of the types of <code>g</code>? It&#39;s because it knows the types coming out of <code>f</code> at compile time. Given an <code>Int</code> and a <code>Float64</code>, <code>f</code> will always output a <code>Float64</code>, and thus it can continue with inference knowing that <code>c</code>, <code>d</code>, and eventually the output is <code>Float64</code>. Thus in order for this to occur, we need that the type of the output on our function is directly inferred from the type of the input. This property is known as type-stability.</p> <p>An example of breaking it is as follows:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>h</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>out</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'>
  </span><span class='hljl-nf'>rand</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>&lt;</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-t'> </span><span class='hljl-oB'>?</span><span class='hljl-t'> </span><span class='hljl-n'>out</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-t'> </span><span class='hljl-nf'>Float64</span><span class='hljl-p'>(</span><span class='hljl-n'>out</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre> <pre class=output >
h &#40;generic function with 1 method&#41;
</pre> <p>Here, on an integer input the output&#39;s type is randomly either Int or Float64, and thus the output is unknown:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>h</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for h&#40;::Int64, ::Int64&#41;
  from h&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;h&#41;
  x::Int64
  y::Int64
Locals
  out::Int64
Body::UNION&#123;FLOAT64, INT64&#125;
1 ─      &#40;out &#61; x &#43; y&#41;
│   &#37;2 &#61; Main.rand&#40;&#41;::Float64
│   &#37;3 &#61; &#40;&#37;2 &lt; 0.5&#41;::Bool
└──      goto #3 if not &#37;3
2 ─      return out
3 ─ &#37;6 &#61; Main.Float64&#40;out&#41;::Float64
└──      return &#37;6
</pre> <p>This means that its output type is <code>Union&#123;Int,Float64&#125;</code> &#40;Julia uses union types to keep the types still somewhat constrained&#41;. Once there are multiple choices, those need to get propagate through the compiler, and all subsequent calculations are the result of either being an <code>Int</code> or a <code>Float64</code>.</p> <p>&#40;Note that Julia has small union optimizations, so if this union is of size 4 or less then Julia will still be able to optimize it quite a bit.&#41;</p> <h3>Multiple Dispatch</h3> <p>The <code>&#43;</code> function on numbers was implemented in Julia, so how were these rules all written down? The answer is multiple dispatch. In Julia, you can tell a function how to act differently on different types by using type assertions on the input values. For example, let&#39;s make a function that computes <code>2x &#43; y</code> on <code>Int</code> and <code>x/y</code> on <code>Float64</code>:</p> <pre class='hljl'>
<span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'>
</span><span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>::</span><span class='hljl-n'>Float64</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-oB'>::</span><span class='hljl-n'>Float64</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>/</span><span class='hljl-n'>y</span><span class='hljl-t'>
</span><span class='hljl-nd'>@show</span><span class='hljl-t'> </span><span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@show</span><span class='hljl-t'> </span><span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>5.0</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
ff&#40;2, 5&#41; &#61; 9
ff&#40;2.0, 5.0&#41; &#61; 0.4
0.4
</pre> <p>The <code>&#43;</code> function in Julia is just defined as <code>&#43;&#40;a,b&#41;</code>, and we can actually point to that code in the Julia distribution:</p> <pre class='hljl'>
<span class='hljl-nd'>@which</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> +(x::<b>Number</b>, y::<b>Number</b>) in Base at <a href="https://github.com/JuliaLang/julia/tree/6f3fdf7b36250fb95f512a2b927ad2518c07d2b5/base/promotion.jl#L422" target=_blank >promotion.jl:422</a> <p>To control at a higher level, Julia uses <em>abstract types</em>. For example, <code>Float64 &lt;: AbstractFloat</code>, meaning <code>Float64</code>s are a subtype of <code>AbstractFloat</code>. We also have that <code>Int &lt;: Integer</code>, while both <code>AbstractFloat &lt;: Number</code> and <code>Integer &lt;: Number</code>.</p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Type-hierarchy-for-julia-numbers.png/800px-Type-hierarchy-for-julia-numbers.png" alt="" /></p> <p>Julia allows the user to define dispatches at a higher level, and the version that is called is the most strict version that is correct. For example, right now with <code>ff</code> we will get a <code>MethodError</code> if we call it between a <code>Int</code> and a <code>Float64</code> because no such method exists:</p> <pre class='hljl'>
<span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=julia-error >
ERROR: MethodError: no method matching ff&#40;::Float64, ::Int64&#41;

Closest candidates are:
  ff&#40;::Float64, &#33;Matched::Float64&#41;
   @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:3
  ff&#40;&#33;Matched::Int64, ::Int64&#41;
   @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:2

</pre> <p>However, we can add a <em>fallback method</em> to the function <code>ff</code> for two numbers:</p> <pre class='hljl'>
<span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>::</span><span class='hljl-n'>Number</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-oB'>::</span><span class='hljl-n'>Number</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'>
</span><span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
7.0
</pre> <p>Notice that the fallback method still specializes on the inputs:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;ff&#96;
define double @julia_ff_3664&#40;double &#37;0, i64 signext &#37;1&#41; #0 &#123;
top:
; ┌ @ promotion.jl:422 within &#96;&#43;&#96;
; │┌ @ promotion.jl:393 within &#96;promote&#96;
; ││┌ @ promotion.jl:370 within &#96;_promote&#96;
; │││┌ @ number.jl:7 within &#96;convert&#96;
; ││││┌ @ float.jl:159 within &#96;Float64&#96;
       &#37;2 &#61; sitofp i64 &#37;1 to double
; │└└└└
; │ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
   &#37;3 &#61; fadd double &#37;2, &#37;0
   ret double &#37;3
; └
&#125;
</pre> <p>It&#39;s essentially just a template for what functions to possibly try and create given the types that are seen. When it sees <code>Float64</code> and <code>Int</code>, it knows it should try and create the function that does <code>x&#43;y</code>, and once it knows it&#39;s <code>Float64</code> plus a <code>Int</code>, it knows it should create the function that converts the <code>Int</code> to a <code>Float64</code> and then does addition between two <code>Float64</code>s, and that is precisely the generated LLVM IR on this pair of input types.</p> <p>And that&#39;s essentially Julia&#39;s secret sauce: since it&#39;s always specializing its types on each function, if those functions themselves can infer the output, then the entire function can be inferred and generate optimal code, which is then optimized by the compiler and out comes an efficient function. If types can&#39;t be inferred, Julia falls back to a slower &quot;Python&quot; mode &#40;though with optimizations in cases like small unions&#41;. Users then get control over this specialization process through multiple dispatch, which is then Julia&#39;s core feature since it allows adding new options without any runtime cost.</p> <h3>Any Fallbacks</h3> <p>Note that <code>f&#40;x,y&#41; &#61; x&#43;y</code> is equivalent to <code>f&#40;x::Any,y::Any&#41; &#61; x&#43;y</code>, where <code>Any</code> is the maximal supertype of every Julia type. Thus <code>f&#40;x,y&#41; &#61; x&#43;y</code> is essentially a fallback for all possible input values, telling it what to do in the case that no other dispatches exist. However, note that this dispatch itself is not slow, since it will be specialized on the input types.</p> <h3>Ambiguities</h3> <p>The version that is called is the most strict version that is correct. What happens if it&#39;s impossible to define &quot;the most strict version&quot;? For example,</p> <pre class='hljl'>
<span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>::</span><span class='hljl-n'>Float64</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-oB'>::</span><span class='hljl-n'>Number</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-n'>y</span><span class='hljl-t'>
</span><span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>::</span><span class='hljl-n'>Number</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-n'>y</span>
</pre> <pre class=output >
ff &#40;generic function with 5 methods&#41;
</pre> <p>What should it call on <code>f&#40;2.0,5&#41;</code> now? <code>ff&#40;x::Float64,y::Number&#41;</code> and <code>ff&#40;x::Number,y::Int&#41;</code> are both more strict than <code>ff&#40;x::Number,y::Number&#41;</code>, so one of them should be called, but neither are more strict than each other, and thus you will end up with an ambiguity error:</p> <pre class='hljl'>
<span class='hljl-nf'>ff</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=julia-error >
ERROR: MethodError: ff&#40;::Float64, ::Int64&#41; is ambiguous.

Candidates:
  ff&#40;x::Number, y::Int64&#41;
    @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:3
  ff&#40;x::Float64, y::Number&#41;
    @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:2

Possible fix, define
  ff&#40;::Float64, ::Int64&#41;

</pre> <h3>Untyped Containers</h3> <p>One way to ruin inference is to use an untyped container. For example, the array constructors use type inference themselves to know what their container type will be. Therefore,</p> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>3.0</span><span class='hljl-p'>]</span>
</pre> <pre class=output >
3-element Vector&#123;Float64&#125;:
 1.0
 2.0
 3.0
</pre> <p>uses type inference on its inputs to know that it should be something that holds <code>Float64</code> values, and thus it is a 1-dimensional array of <code>Float64</code> values, or <code>Array&#123;Float64,1&#125;</code>. The accesses:</p> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span>
</pre> <pre class=output >
1.0
</pre> <p>are then inferred, since this is just the function <code>getindex&#40;a::Array&#123;T&#125;,i&#41; where T</code> which is a function that will produce something of type <code>T</code>, the element type of the array. However, if we tell Julia to make an array with element type <code>Any</code>:</p> <pre class='hljl'>
<span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-s'>&quot;1.0&quot;</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>]</span>
</pre> <pre class=output >
3-element Vector&#123;Any&#125;:
  &quot;1.0&quot;
 2
 2.0
</pre> <p>&#40;here, Julia falls back to <code>Any</code> because it cannot promote the values to the same type&#41;, then the best inference can do on the output is to say it could have any type:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>bad_container</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>bad_container</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for bad_container&#40;::Vector&#123;Float64&#125;&#41;
  from bad_container&#40;a&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/
optimizing.jmd:2
Arguments
  #self#::Core.Const&#40;bad_container&#41;
  a::Vector&#123;Float64&#125;
Body::Float64
1 ─ &#37;1 &#61; Base.getindex&#40;a, 2&#41;::Float64
└──      return &#37;1
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>bad_container</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for bad_container&#40;::Vector&#123;Any&#125;&#41;
  from bad_container&#40;a&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/
optimizing.jmd:2
Arguments
  #self#::Core.Const&#40;bad_container&#41;
  a::Vector&#123;Any&#125;
Body::ANY
1 ─ &#37;1 &#61; Base.getindex&#40;a, 2&#41;::ANY
└──      return &#37;1
</pre> <p>This is one common way that type inference can breakdown. For example, even if the array is all numbers, we can still break inference:</p> <pre class='hljl'>
<span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Number</span><span class='hljl-p'>[</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-ni'>3</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>q</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
  </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-n'>c</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>,</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>q</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for q&#40;::Vector&#123;Number&#125;&#41;
  from q&#40;x&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.j
md:3
Arguments
  #self#::Core.Const&#40;q&#41;
  x::Vector&#123;Number&#125;
Locals
  d::ANY
  c::ANY
  b::Int64
  a::Int64
Body::ANY
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│   &#37;3 &#61; Base.getindex&#40;x, 1&#41;::NUMBER
│        &#40;c &#61; Main.f&#40;&#37;3, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;6 &#61; d::ANY
│   &#37;7 &#61; Base.getindex&#40;x, 2&#41;::NUMBER
│   &#37;8 &#61; Main.f&#40;&#37;6, &#37;7&#41;::ANY
└──      return &#37;8
</pre> <p>Here the type inference algorithm quickly gives up and infers to <code>Any</code>, losing all specialization and automatically switching to Python-style runtime type checking.</p> <h3>Type definitions</h3> <h3>Value types and isbits</h3> <p>In Julia, types which can fully inferred and which are composed of primitive or <code>isbits</code> types are value types. This means that, inside of an array, their values are the values of the type itself, and not a pointer to the values.</p> <p>You can check if the type is a value type through <code>isbits</code>:</p> <pre class='hljl'>
<span class='hljl-nf'>isbits</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
true
</pre> <p>Note that a Julia <code>struct</code> which holds i<code>sbits</code> values is <code>isbits</code> as well, if it&#39;s fully inferred:</p> <pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-n'>MyComplex</span><span class='hljl-t'>
  </span><span class='hljl-n'>real</span><span class='hljl-oB'>::</span><span class='hljl-n'>Float64</span><span class='hljl-t'>
  </span><span class='hljl-n'>imag</span><span class='hljl-oB'>::</span><span class='hljl-n'>Float64</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nf'>isbits</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
true
</pre> <p>We can see that the compiler knows how to use this efficiently since it knows that what comes out is always <code>Float64</code>:</p> <pre class='hljl'>
<span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyComplex</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyComplex</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyComplex</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyComplex</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MyComplex&#40;8.0, 2.0&#41;
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MethodInstance for g&#40;::MyComplex, ::MyComplex&#41;
  from g&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;g&#41;
  x::MyComplex
  y::MyComplex
Locals
  d::MyComplex
  c::MyComplex
  b::Int64
  a::Int64
Body::MyComplex
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│        &#40;c &#61; Main.f&#40;x, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;5 &#61; Main.f&#40;d, y&#41;::MyComplex
└──      return &#37;5
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;g&#96;
define void @julia_g_3803&#40;&#91;2 x double&#93;* noalias nocapture noundef nonnull s
ret&#40;&#91;2 x double&#93;&#41; align 8 dereferenceable&#40;16&#41; &#37;0, &#91;2 x double&#93;* nocapture n
oundef nonnull readonly align 8 dereferenceable&#40;16&#41; &#37;1, &#91;2 x double&#93;* nocap
ture noundef nonnull readonly align 8 dereferenceable&#40;16&#41; &#37;2&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:3 within &#96;&#43;&#96;
; ││┌ @ Base.jl:37 within &#96;getproperty&#96;
     &#37;3 &#61; getelementptr inbounds &#91;2 x double&#93;, &#91;2 x double&#93;* &#37;1, i64 0, i64
 0
; ││└
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:3 within &#96;&#43;&#96; @ promotion.jl:422 @ float.jl:409
    &#37;unbox &#61; load double, double* &#37;3, align 8
    &#37;4 &#61; fadd double &#37;unbox, 4.000000e&#43;00
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:3 within &#96;&#43;&#96;
; ││┌ @ Base.jl:37 within &#96;getproperty&#96;
     &#37;5 &#61; getelementptr inbounds &#91;2 x double&#93;, &#91;2 x double&#93;* &#37;1, i64 0, i64
 1
; └└└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:4 within &#96;&#43;&#96; @ promotion.jl:422 @ float.jl:409
    &#37;6 &#61; fadd double &#37;4, 2.000000e&#43;00
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
7 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96; @ float.jl:409
    &#37;unbox2 &#61; load double, double* &#37;5, align 8
    &#37;7 &#61; bitcast &#91;2 x double&#93;* &#37;2 to &lt;2 x double&gt;*
    &#37;8 &#61; load &lt;2 x double&gt;, &lt;2 x double&gt;* &#37;7, align 8
    &#37;9 &#61; insertelement &lt;2 x double&gt; poison, double &#37;6, i64 0
    &#37;10 &#61; insertelement &lt;2 x double&gt; &#37;9, double &#37;unbox2, i64 1
    &#37;11 &#61; fadd &lt;2 x double&gt; &#37;8, &#37;10
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96;
; ││┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.j
md:3 within &#96;MyComplex&#96;
     &#37;12 &#61; bitcast &#91;2 x double&#93;* &#37;0 to &lt;2 x double&gt;*
     store &lt;2 x double&gt; &#37;11, &lt;2 x double&gt;* &#37;12, align 8
     ret void
; └└└
&#125;
</pre> <p>Note that the compiled code simply works directly on the <code>double</code> pieces. We can also make this be concrete without pre-specifying that the values always have to be <code>Float64</code> by using a type parameter.</p> <pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>{</span><span class='hljl-n'>T</span><span class='hljl-p'>}</span><span class='hljl-t'>
  </span><span class='hljl-n'>real</span><span class='hljl-oB'>::</span><span class='hljl-n'>T</span><span class='hljl-t'>
  </span><span class='hljl-n'>imag</span><span class='hljl-oB'>::</span><span class='hljl-n'>T</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nf'>isbits</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
true
</pre> <p>Note that <code>MyParameterizedComplex&#123;T&#125;</code> is a concrete type for every <code>T</code>: it is a shorthand form for defining a whole family of types.</p> <pre class='hljl'>
<span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyParameterizedComplex</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyParameterizedComplex</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyParameterizedComplex</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MyParameterizedComplex</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MyParameterizedComplex&#123;Float64&#125;&#40;8.0, 2.0&#41;
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MethodInstance for g&#40;::MyParameterizedComplex&#123;Float64&#125;, ::MyParameterizedCo
mplex&#123;Float64&#125;&#41;
  from g&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;g&#41;
  x::MyParameterizedComplex&#123;Float64&#125;
  y::MyParameterizedComplex&#123;Float64&#125;
Locals
  d::MyParameterizedComplex&#123;Float64&#125;
  c::MyParameterizedComplex&#123;Float64&#125;
  b::Int64
  a::Int64
Body::MyParameterizedComplex&#123;Float64&#125;
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│        &#40;c &#61; Main.f&#40;x, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;5 &#61; Main.f&#40;d, y&#41;::MyParameterizedComplex&#123;Float64&#125;
└──      return &#37;5
</pre> <p>See that this code also automatically works and compiles efficiently for <code>Float32</code> as well:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MethodInstance for g&#40;::MyParameterizedComplex&#123;Float32&#125;, ::MyParameterizedCo
mplex&#123;Float32&#125;&#41;
  from g&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;g&#41;
  x::MyParameterizedComplex&#123;Float32&#125;
  y::MyParameterizedComplex&#123;Float32&#125;
Locals
  d::MyParameterizedComplex&#123;Float32&#125;
  c::MyParameterizedComplex&#123;Float32&#125;
  b::Int64
  a::Int64
Body::MyParameterizedComplex&#123;Float32&#125;
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│        &#40;c &#61; Main.f&#40;x, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;5 &#61; Main.f&#40;d, y&#41;::MyParameterizedComplex&#123;Float32&#125;
└──      return &#37;5
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0f0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;g&#96;
define &#91;2 x float&#93; @julia_g_3815&#40;&#91;2 x float&#93;* nocapture noundef nonnull rea
donly align 4 dereferenceable&#40;8&#41; &#37;0, &#91;2 x float&#93;* nocapture noundef nonnull
 readonly align 4 dereferenceable&#40;8&#41; &#37;1&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:3 within &#96;&#43;&#96;
; ││┌ @ Base.jl:37 within &#96;getproperty&#96;
     &#37;2 &#61; getelementptr inbounds &#91;2 x float&#93;, &#91;2 x float&#93;* &#37;0, i64 0, i64 0
; ││└
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:3 within &#96;&#43;&#96; @ promotion.jl:422 @ float.jl:409
    &#37;unbox &#61; load float, float* &#37;2, align 4
    &#37;3 &#61; fadd float &#37;unbox, 4.000000e&#43;00
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:3 within &#96;&#43;&#96;
; ││┌ @ Base.jl:37 within &#96;getproperty&#96;
     &#37;4 &#61; getelementptr inbounds &#91;2 x float&#93;, &#91;2 x float&#93;* &#37;0, i64 0, i64 1
; └└└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:4 within &#96;&#43;&#96; @ promotion.jl:422 @ float.jl:409
    &#37;5 &#61; fadd float &#37;3, 2.000000e&#43;00
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
7 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
; │┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96;
; ││┌ @ Base.jl:37 within &#96;getproperty&#96;
     &#37;6 &#61; getelementptr inbounds &#91;2 x float&#93;, &#91;2 x float&#93;* &#37;1, i64 0, i64 0
; ││└
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96; @ float.jl:409
    &#37;unbox1 &#61; load float, float* &#37;6, align 4
    &#37;7 &#61; fadd float &#37;unbox1, &#37;5
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96;
; ││┌ @ Base.jl:37 within &#96;getproperty&#96;
     &#37;8 &#61; getelementptr inbounds &#91;2 x float&#93;, &#91;2 x float&#93;* &#37;1, i64 0, i64 1
; ││└
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96; @ float.jl:409
    &#37;unbox2 &#61; load float, float* &#37;4, align 4
    &#37;unbox3 &#61; load float, float* &#37;8, align 4
    &#37;9 &#61; fadd float &#37;unbox2, &#37;unbox3
; ││ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jm
d:2 within &#96;&#43;&#96;
; ││┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.j
md:3 within &#96;MyParameterizedComplex&#96;
     &#37;unbox4.fca.0.insert &#61; insertvalue &#91;2 x float&#93; zeroinitializer, float 
&#37;7, 0
     &#37;unbox4.fca.1.insert &#61; insertvalue &#91;2 x float&#93; &#37;unbox4.fca.0.insert, f
loat &#37;9, 1
     ret &#91;2 x float&#93; &#37;unbox4.fca.1.insert
; └└└
&#125;
</pre> <p>It is important to know that if there is any piece of a type which doesn&#39;t contain type information, then it cannot be isbits because then it would have to be compiled in such a way that the size is not known in advance. For example:</p> <pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-n'>MySlowComplex</span><span class='hljl-t'>
  </span><span class='hljl-n'>real</span><span class='hljl-t'>
  </span><span class='hljl-n'>imag</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nf'>isbits</span><span class='hljl-p'>(</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
false
</pre> <pre class='hljl'>
<span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MySlowComplex&#40;8.0, 2.0&#41;
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MethodInstance for g&#40;::MySlowComplex, ::MySlowComplex&#41;
  from g&#40;x, y&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizin
g.jmd:2
Arguments
  #self#::Core.Const&#40;g&#41;
  x::MySlowComplex
  y::MySlowComplex
Locals
  d::MySlowComplex
  c::MySlowComplex
  b::Int64
  a::Int64
Body::MySlowComplex
1 ─      &#40;a &#61; 4&#41;
│        &#40;b &#61; 2&#41;
│        &#40;c &#61; Main.f&#40;x, a::Core.Const&#40;4&#41;&#41;&#41;
│        &#40;d &#61; Main.f&#40;b::Core.Const&#40;2&#41;, c&#41;&#41;
│   &#37;5 &#61; Main.f&#40;d, y&#41;::MySlowComplex
└──      return &#37;5
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;g&#96;
define void @julia_g_3834&#40;&#91;2 x &#123;&#125;*&#93;* noalias nocapture noundef nonnull sret
&#40;&#91;2 x &#123;&#125;*&#93;&#41; align 8 dereferenceable&#40;16&#41; &#37;0, &#91;2 x &#123;&#125;*&#93;* nocapture noundef no
nnull readonly align 8 dereferenceable&#40;16&#41; &#37;1, &#91;2 x &#123;&#125;*&#93;* nocapture noundef
 nonnull readonly align 8 dereferenceable&#40;16&#41; &#37;2&#41; #0 &#123;
top:
  &#37;gcframe2 &#61; alloca &#91;8 x &#123;&#125;*&#93;, align 16
  &#37;gcframe2.sub &#61; getelementptr inbounds &#91;8 x &#123;&#125;*&#93;, &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2, i
64 0, i64 0
  &#37;3 &#61; bitcast &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2 to i8*
  call void @llvm.memset.p0i8.i64&#40;i8* align 16 &#37;3, i8 0, i64 64, i1 true&#41;
  &#37;4 &#61; getelementptr inbounds &#91;8 x &#123;&#125;*&#93;, &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2, i64 0, i64 6
  &#37;5 &#61; bitcast &#123;&#125;** &#37;4 to &#91;2 x &#123;&#125;*&#93;*
  &#37;6 &#61; getelementptr inbounds &#91;8 x &#123;&#125;*&#93;, &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2, i64 0, i64 4
  &#37;7 &#61; bitcast &#123;&#125;** &#37;6 to &#91;2 x &#123;&#125;*&#93;*
  &#37;8 &#61; getelementptr inbounds &#91;8 x &#123;&#125;*&#93;, &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2, i64 0, i64 2
  &#37;9 &#61; bitcast &#123;&#125;** &#37;8 to &#91;2 x &#123;&#125;*&#93;*
  &#37;thread_ptr &#61; call i8* asm &quot;movq &#37;fs:0, &#36;0&quot;, &quot;&#61;r&quot;&#40;&#41; #9
  &#37;tls_ppgcstack &#61; getelementptr i8, i8* &#37;thread_ptr, i64 -8
  &#37;10 &#61; bitcast i8* &#37;tls_ppgcstack to &#123;&#125;****
  &#37;tls_pgcstack &#61; load &#123;&#125;***, &#123;&#125;**** &#37;10, align 8
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
   &#37;11 &#61; bitcast &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2 to i64*
   store i64 24, i64* &#37;11, align 16
   &#37;12 &#61; getelementptr inbounds &#91;8 x &#123;&#125;*&#93;, &#91;8 x &#123;&#125;*&#93;* &#37;gcframe2, i64 0, i64
 1
   &#37;13 &#61; bitcast &#123;&#125;** &#37;12 to &#123;&#125;***
   &#37;14 &#61; load &#123;&#125;**, &#123;&#125;*** &#37;tls_pgcstack, align 8
   store &#123;&#125;** &#37;14, &#123;&#125;*** &#37;13, align 8
   &#37;15 &#61; bitcast &#123;&#125;*** &#37;tls_pgcstack to &#123;&#125;***
   store &#123;&#125;** &#37;gcframe2.sub, &#123;&#125;*** &#37;15, align 8
   call void @&quot;j_&#43;_3836&quot;&#40;&#91;2 x &#123;&#125;*&#93;* noalias nocapture noundef nonnull sret&#40;
&#91;2 x &#123;&#125;*&#93;&#41; &#37;7, &#91;2 x &#123;&#125;*&#93;* nocapture nonnull readonly &#37;1, i64 signext 4&#41;
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
   call void @&quot;j_&#43;_3837&quot;&#40;&#91;2 x &#123;&#125;*&#93;* noalias nocapture noundef nonnull sret&#40;
&#91;2 x &#123;&#125;*&#93;&#41; &#37;9, i64 signext 2, &#91;2 x &#123;&#125;*&#93;* nocapture readonly &#37;7&#41;
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
7 within &#96;g&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:2 within &#96;f&#96;
   call void @&quot;j_&#43;_3838&quot;&#40;&#91;2 x &#123;&#125;*&#93;* noalias nocapture noundef nonnull sret&#40;
&#91;2 x &#123;&#125;*&#93;&#41; &#37;5, &#91;2 x &#123;&#125;*&#93;* nocapture readonly &#37;9, &#91;2 x &#123;&#125;*&#93;* nocapture nonnu
ll readonly &#37;2&#41;
   &#37;16 &#61; bitcast &#91;2 x &#123;&#125;*&#93;* &#37;0 to i8*
   &#37;17 &#61; bitcast &#123;&#125;** &#37;4 to i8*
   call void @llvm.memcpy.p0i8.p0i8.i64&#40;i8* noundef nonnull align 8 derefer
enceable&#40;16&#41; &#37;16, i8* noundef nonnull align 16 dereferenceable&#40;16&#41; &#37;17, i64
 16, i1 false&#41;
   &#37;18 &#61; load &#123;&#125;*, &#123;&#125;** &#37;12, align 8
   &#37;19 &#61; bitcast &#123;&#125;*** &#37;tls_pgcstack to &#123;&#125;**
   store &#123;&#125;* &#37;18, &#123;&#125;** &#37;19, align 8
   ret void
; └
&#125;
</pre> <pre class='hljl'>
<span class='hljl-k'>struct</span><span class='hljl-t'> </span><span class='hljl-n'>MySlowComplex2</span><span class='hljl-t'>
  </span><span class='hljl-n'>real</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractFloat</span><span class='hljl-t'>
  </span><span class='hljl-n'>imag</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractFloat</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nf'>isbits</span><span class='hljl-p'>(</span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
false
</pre> <pre class='hljl'>
<span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex2</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex2</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex2</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Base</span><span class='hljl-oB'>.:+</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-oB'>::</span><span class='hljl-n'>Int</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>::</span><span class='hljl-n'>MySlowComplex2</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>real</span><span class='hljl-oB'>+</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-oB'>.</span><span class='hljl-n'>imag</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>),</span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>))</span>
</pre> <pre class=output >
MySlowComplex2&#40;8.0, 2.0&#41;
</pre> <p>Here&#39;s the timings:</p> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
19.063 ns &#40;1 allocation: 32 bytes&#41;
MyComplex&#40;9.0, 2.0&#41;
</pre> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MyParameterizedComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
19.494 ns &#40;1 allocation: 32 bytes&#41;
MyParameterizedComplex&#123;Float64&#125;&#40;9.0, 2.0&#41;
</pre> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
98.400 ns &#40;5 allocations: 96 bytes&#41;
MySlowComplex&#40;9.0, 2.0&#41;
</pre> <pre class='hljl'>
<span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>MySlowComplex2</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>g</span><span class='hljl-p'>(</span><span class='hljl-n'>a</span><span class='hljl-p'>,</span><span class='hljl-n'>b</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
729.865 ns &#40;14 allocations: 288 bytes&#41;
MySlowComplex2&#40;9.0, 2.0&#41;
</pre> <h3>Note on Julia</h3> <p>Note that, because of these type specialization, value types, etc. properties, the number types, even ones such as <code>Int</code>, <code>Float64</code>, and <code>Complex</code>, are all themselves implemented in pure Julia&#33; Thus even basic pieces can be implemented in Julia with full performance, given one uses the features correctly.</p> <h3>Note on isbits</h3> <p>Note that a type which is <code>mutable struct</code> will not be isbits. This means that mutable structs will be a pointer to a heap allocated object, unless it&#39;s shortlived and the compiler can erase its construction. Also, note that <code>isbits</code> compiles down to bit operations from pure Julia, which means that these types can directly compile to GPU kernels through CUDAnative without modification.</p> <h3>Function Barriers</h3> <p>Since functions automatically specialize on their input types in Julia, we can use this to our advantage in order to make an inner loop fully inferred. For example, take the code from above but with a loop:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>r</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
  </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>c</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>,</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>])</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>r</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
4.763 μs &#40;300 allocations: 4.69 KiB&#41;
604.0
</pre> <p>In here, the loop variables are not inferred and thus this is really slow. However, we can force a function call in the middle to end up with specialization and in the inner loop be stable:</p> <pre class='hljl'>
<span class='hljl-nf'>s</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>_s</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-n'>x</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>_s</span><span class='hljl-p'>(</span><span class='hljl-n'>x1</span><span class='hljl-p'>,</span><span class='hljl-n'>x2</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
  </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>c</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>x1</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>f</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>,</span><span class='hljl-n'>x2</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>s</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
297.660 ns &#40;1 allocation: 16 bytes&#41;
604.0
</pre> <p>Notice that this algorithm still doesn&#39;t infer:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_warntype</span><span class='hljl-t'> </span><span class='hljl-nf'>s</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
MethodInstance for s&#40;::Vector&#123;Number&#125;&#41;
  from s&#40;x&#41; @ Main ~/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.j
md:2
Arguments
  #self#::Core.Const&#40;s&#41;
  x::Vector&#123;Number&#125;
Body::ANY
1 ─ &#37;1 &#61; Base.getindex&#40;x, 1&#41;::NUMBER
│   &#37;2 &#61; Base.getindex&#40;x, 2&#41;::NUMBER
│   &#37;3 &#61; Main._s&#40;&#37;1, &#37;2&#41;::ANY
└──      return &#37;3
</pre> <p>since the output of <code>_s</code> isn&#39;t inferred, but while it&#39;s in <code>_s</code> it will have specialized on the fact that <code>x&#91;1&#93;</code> is a <code>Float64</code> while <code>x&#91;2&#93;</code> is a <code>Int</code>, making that inner loop fast. In fact, it will only need to pay one <em>dynamic dispatch</em>, i.e. a multiple dispatch determination that happens at runtime. Notice that whenever functions are inferred, the dispatching is static since the choice of the dispatch is already made and compiled into the LLVM IR.</p> <h3>Specialization at Compile Time</h3> <p>Julia code will specialize at compile time if it can prove something about the result. For example:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>fff</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>if</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-n'>isa</span><span class='hljl-t'> </span><span class='hljl-n'>Int</span><span class='hljl-t'>
    </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-k'>else</span><span class='hljl-t'>
    </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.0</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
  </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre> <pre class=output >
fff &#40;generic function with 1 method&#41;
</pre> <p>You might think this function has a branch, but in reality Julia can determine whether <code>x</code> is an <code>Int</code> or not at compile time, so it will actually compile it away and just turn it into the function <code>x&#43;2</code> or <code>x&#43;4.0</code>:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>fff</span><span class='hljl-p'>(</span><span class='hljl-ni'>5</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;fff&#96;
define i64 @julia_fff_3928&#40;i64 signext &#37;0&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
8 within &#96;fff&#96;
; ┌ @ int.jl:87 within &#96;&#43;&#96;
   &#37;1 &#61; add i64 &#37;0, 2
   ret i64 &#37;1
; └
&#125;
</pre> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>fff</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;fff&#96;
define double @julia_fff_3930&#40;double &#37;0&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
8 within &#96;fff&#96;
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;1 &#61; fadd double &#37;0, 4.000000e&#43;00
   ret double &#37;1
; └
&#125;
</pre> <p>Thus one does not need to worry about over-optimizing since in the obvious cases the compiler will actually remove all of the extra pieces when it can&#33;</p> <h3>Global Scope and Optimizations</h3> <p>This discussion shows how Julia&#39;s optimizations all apply during function specialization times. Thus calling Julia functions is fast. But what about when doing something outside of the function, like directly in a module or in the REPL?</p> <pre class='hljl'>
<span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
  </span><span class='hljl-kd'>global</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>,</span><span class='hljl-n'>C</span><span class='hljl-t'>
  </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre> <pre class=output >
727.965 μs &#40;30000 allocations: 468.75 KiB&#41;
</pre> <p>This is very slow because the types of <code>A</code>, <code>B</code>, and <code>C</code> cannot be inferred. Why can&#39;t they be inferred? Well, at any time in the dynamic REPL scope I can do something like <code>C &#61; &quot;haha now a string&#33;&quot;</code>, and thus it cannot specialize on the types currently existing in the REPL &#40;since asynchronous changes could also occur&#41;, and therefore it defaults back to doing a type check at every single function which slows it down. Moral of the story, Julia functions are fast but its global scope is too dynamic to be optimized.</p> <h3>Summary</h3> <ul> <li><p>Julia is not fast because of its JIT, it&#39;s fast because of function specialization and type inference</p> <li><p>Type stable functions allow inference to fully occur</p> <li><p>Multiple dispatch works within the function specialization mechanism to create overhead-free compile time controls</p> <li><p>Julia will specialize the generic functions</p> <li><p>Making sure values are concretely typed in inner loops is essential for performance</p> </ul> <h2>Overheads of Individual Operations</h2> <p>Now let&#39;s dig even a little deeper. Everything the processor does has a cost. A great chart to keep in mind is <a href="http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/">this classic one</a>. A few things should immediately jump out to you:</p> <ul> <li><p>Simple arithmetic, like floating point additions, are super cheap. ~1 clock cycle, or a few nanoseconds.</p> <li><p>Processors do <em>branch prediction</em> on <code>if</code> statements. If the code goes down the predicted route, the <code>if</code> statement costs ~1-2 clock cycles. If it goes down the wrong route, then it will take ~10-20 clock cycles. This means that predictable branches, like ones with clear patterns or usually the same output, are much cheaper &#40;almost free&#41; than unpredictable branches.</p> <li><p>Function calls are expensive: 15-60 clock cycles&#33;</p> <li><p>RAM reads are very expensive, with lower caches less expensive.</p> </ul> <h3>Bounds Checking</h3> <p>Let&#39;s check the LLVM IR on one of our earlier loops:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;inner_noalloc&#33;&#96;
define nonnull &#123;&#125;* @&quot;japi1_inner_noalloc&#33;_3939&quot;&#40;&#123;&#125;* &#37;function, &#123;&#125;** noalias
 nocapture noundef readonly &#37;args, i32 &#37;nargs&#41; #0 &#123;
top:
  &#37;stackargs &#61; alloca &#123;&#125;**, align 8
  store volatile &#123;&#125;** &#37;args, &#123;&#125;*** &#37;stackargs, align 8
  &#37;0 &#61; load &#123;&#125;*, &#123;&#125;** &#37;args, align 8
  &#37;1 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;args, i64 1
  &#37;2 &#61; load &#123;&#125;*, &#123;&#125;** &#37;1, align 8
  &#37;3 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;args, i64 2
  &#37;4 &#61; load &#123;&#125;*, &#123;&#125;** &#37;3, align 8
  &#37;5 &#61; bitcast &#123;&#125;* &#37;2 to &#123;&#125;**
  &#37;arraysize_ptr &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;5, i64 3
  &#37;6 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr to i64*
  &#37;arraysize &#61; load i64, i64* &#37;6, align 8
  &#37;arraysize_ptr4 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;5, i64 4
  &#37;7 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr4 to i64*
  &#37;8 &#61; bitcast &#123;&#125;* &#37;2 to double**
  &#37;9 &#61; bitcast &#123;&#125;* &#37;4 to &#123;&#125;**
  &#37;arraysize_ptr7 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;9, i64 3
  &#37;10 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr7 to i64*
  &#37;arraysize_ptr12 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;9, i64 4
  &#37;11 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr12 to i64*
  &#37;12 &#61; bitcast &#123;&#125;* &#37;4 to double**
  &#37;13 &#61; bitcast &#123;&#125;* &#37;0 to &#123;&#125;**
  &#37;arraysize_ptr21 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;13, i64 3
  &#37;14 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr21 to i64*
  &#37;arraysize_ptr26 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;13, i64 4
  &#37;15 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr26 to i64*
  &#37;16 &#61; bitcast &#123;&#125;* &#37;0 to double**
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
3 within &#96;inner_noalloc&#33;&#96;
  br label &#37;L2

L2:                                               ; preds &#61; &#37;L27.split.us.s
plit.us.split.us.1, &#37;top
  &#37;indvar &#61; phi i64 &#91; 0, &#37;top &#93;, &#91; &#37;indvar.next.1, &#37;L27.split.us.split.us.s
plit.us.1 &#93;
  &#37;value_phi &#61; phi i64 &#91; 1, &#37;top &#93;, &#91; &#37;264, &#37;L27.split.us.split.us.split.us
.1 &#93;
  &#37;17 &#61; shl nuw nsw i64 &#37;indvar, 3
  &#37;18 &#61; mul i64 &#37;arraysize, &#37;indvar
  &#37;19 &#61; add nsw i64 &#37;value_phi, -1
  &#37;arraysize5 &#61; load i64, i64* &#37;7, align 8
  &#37;inbounds6 &#61; icmp ult i64 &#37;19, &#37;arraysize5
  &#37;20 &#61; mul i64 &#37;arraysize, &#37;19
  &#37;arrayptr41 &#61; load double*, double** &#37;8, align 8
  &#37;arraysize8 &#61; load i64, i64* &#37;10, align 8
  &#37;21 &#61; mul i64 &#37;arraysize8, &#37;19
  &#37;arrayptr1943 &#61; load double*, double** &#37;12, align 8
  &#37;arrayptr1943224 &#61; bitcast double* &#37;arrayptr1943 to i8*
  &#37;arraysize22 &#61; load i64, i64* &#37;14, align 8
  &#37;arraysize27 &#61; load i64, i64* &#37;15, align 8
  &#37;inbounds28 &#61; icmp ult i64 &#37;19, &#37;arraysize27
  &#37;22 &#61; mul i64 &#37;arraysize22, &#37;19
  &#37;arrayptr3345 &#61; load double*, double** &#37;16, align 8
  &#37;arrayptr3345217 &#61; bitcast double* &#37;arrayptr3345 to i8*
  &#37;inbounds6.fr &#61; freeze i1 &#37;inbounds6
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   br i1 &#37;inbounds6.fr, label &#37;L2.split.us, label &#37;oob

L2.split.us:                                      ; preds &#61; &#37;L2
   &#37;arraysize13 &#61; load i64, i64* &#37;11, align 8
   &#37;inbounds14 &#61; icmp ult i64 &#37;19, &#37;arraysize13
   &#37;inbounds14.fr &#61; freeze i1 &#37;inbounds14
   br i1 &#37;inbounds14.fr, label &#37;L2.split.us.split.us, label &#37;L2.split.us.sp
lit

L2.split.us.split.us:                             ; preds &#61; &#37;L2.split.us
   &#37;inbounds28.fr &#61; freeze i1 &#37;inbounds28
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   br i1 &#37;inbounds28.fr, label &#37;L2.split.us.split.us.split.us, label &#37;L2.sp
lit.us.split.us.split

L2.split.us.split.us.split.us:                    ; preds &#61; &#37;L2.split.us.sp
lit.us
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
3 within &#96;inner_noalloc&#33;&#96;
  &#37;smin &#61; call i64 @llvm.smin.i64&#40;i64 &#37;arraysize8, i64 0&#41;
  &#37;23 &#61; sub i64 &#37;arraysize8, &#37;smin
  &#37;smax &#61; call i64 @llvm.smax.i64&#40;i64 &#37;smin, i64 -1&#41;
  &#37;24 &#61; add nsw i64 &#37;smax, 1
  &#37;25 &#61; mul nuw nsw i64 &#37;23, &#37;24
  &#37;umin &#61; call i64 @llvm.umin.i64&#40;i64 &#37;arraysize, i64 &#37;25&#41;
  &#37;smin156 &#61; call i64 @llvm.smin.i64&#40;i64 &#37;arraysize22, i64 0&#41;
  &#37;26 &#61; sub i64 &#37;arraysize22, &#37;smin156
  &#37;smax157 &#61; call i64 @llvm.smax.i64&#40;i64 &#37;smin156, i64 -1&#41;
  &#37;27 &#61; add nsw i64 &#37;smax157, 1
  &#37;28 &#61; mul nuw nsw i64 &#37;26, &#37;27
  &#37;umin158 &#61; call i64 @llvm.umin.i64&#40;i64 &#37;umin, i64 &#37;28&#41;
  &#37;exit.mainloop.at &#61; call i64 @llvm.umin.i64&#40;i64 &#37;umin158, i64 100&#41;
  &#37;.not196 &#61; icmp eq i64 &#37;exit.mainloop.at, 0
  br i1 &#37;.not196, label &#37;main.pseudo.exit, label &#37;ib24.us.us.us.preheader

ib24.us.us.us.preheader:                          ; preds &#61; &#37;L2.split.us.sp
lit.us.split.us
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
  &#37;min.iters.check &#61; icmp ult i64 &#37;exit.mainloop.at, 12
  br i1 &#37;min.iters.check, label &#37;scalar.ph, label &#37;vector.memcheck

vector.memcheck:                                  ; preds &#61; &#37;ib24.us.us.us.
preheader
  &#37;29 &#61; mul i64 &#37;arraysize22, &#37;17
  &#37;uglygep &#61; getelementptr i8, i8* &#37;arrayptr3345217, i64 &#37;29
  &#37;scevgep &#61; getelementptr double, double* &#37;arrayptr3345, i64 &#37;exit.mainloo
p.at
  &#37;scevgep218 &#61; bitcast double* &#37;scevgep to i8*
  &#37;uglygep219 &#61; getelementptr i8, i8* &#37;scevgep218, i64 &#37;29
  &#37;scevgep220 &#61; getelementptr double, double* &#37;arrayptr41, i64 &#37;18
  &#37;scevgep220221 &#61; bitcast double* &#37;scevgep220 to i8*
  &#37;30 &#61; add i64 &#37;exit.mainloop.at, &#37;18
  &#37;scevgep222 &#61; getelementptr double, double* &#37;arrayptr41, i64 &#37;30
  &#37;scevgep222223 &#61; bitcast double* &#37;scevgep222 to i8*
  &#37;31 &#61; mul i64 &#37;arraysize8, &#37;17
  &#37;uglygep225 &#61; getelementptr i8, i8* &#37;arrayptr1943224, i64 &#37;31
  &#37;scevgep226 &#61; getelementptr double, double* &#37;arrayptr1943, i64 &#37;exit.main
loop.at
  &#37;scevgep226227 &#61; bitcast double* &#37;scevgep226 to i8*
  &#37;uglygep228 &#61; getelementptr i8, i8* &#37;scevgep226227, i64 &#37;31
  &#37;bound0 &#61; icmp ult i8* &#37;uglygep, &#37;scevgep222223
  &#37;bound1 &#61; icmp ugt i8* &#37;uglygep219, &#37;scevgep220221
  &#37;found.conflict &#61; and i1 &#37;bound0, &#37;bound1
  &#37;bound0229 &#61; icmp ult i8* &#37;uglygep, &#37;uglygep228
  &#37;bound1230 &#61; icmp ult i8* &#37;uglygep225, &#37;uglygep219
  &#37;found.conflict231 &#61; and i1 &#37;bound0229, &#37;bound1230
  &#37;conflict.rdx &#61; or i1 &#37;found.conflict, &#37;found.conflict231
  br i1 &#37;conflict.rdx, label &#37;scalar.ph, label &#37;vector.ph

vector.ph:                                        ; preds &#61; &#37;vector.memchec
k
  &#37;n.vec &#61; and i64 &#37;exit.mainloop.at, 124
  &#37;ind.end &#61; or i64 &#37;n.vec, 1
  &#37;32 &#61; add nsw i64 &#37;n.vec, -4
  &#37;33 &#61; lshr exact i64 &#37;32, 2
  &#37;34 &#61; add nuw nsw i64 &#37;33, 1
  &#37;xtraiter &#61; and i64 &#37;34, 7
  &#37;35 &#61; icmp ult i64 &#37;32, 28
  br i1 &#37;35, label &#37;middle.block.unr-lcssa, label &#37;vector.ph.new

vector.ph.new:                                    ; preds &#61; &#37;vector.ph
  &#37;unroll_iter &#61; and i64 &#37;34, 9223372036854775800
  br label &#37;vector.body

vector.body:                                      ; preds &#61; &#37;vector.body, &#37;
vector.ph.new
  &#37;index &#61; phi i64 &#91; 0, &#37;vector.ph.new &#93;, &#91; &#37;index.next.7, &#37;vector.body &#93;
  &#37;niter &#61; phi i64 &#91; 0, &#37;vector.ph.new &#93;, &#91; &#37;niter.next.7, &#37;vector.body &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;36 &#61; add i64 &#37;20, &#37;index
   &#37;37 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;36
   &#37;38 &#61; bitcast double* &#37;37 to &lt;4 x double&gt;*
   &#37;wide.load &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;38, align 8
   &#37;39 &#61; add i64 &#37;21, &#37;index
   &#37;40 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;39
   &#37;41 &#61; bitcast double* &#37;40 to &lt;4 x double&gt;*
   &#37;wide.load232 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;41, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;42 &#61; fadd &lt;4 x double&gt; &#37;wide.load, &#37;wide.load232
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;43 &#61; add i64 &#37;22, &#37;index
   &#37;44 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;43
   &#37;45 &#61; bitcast double* &#37;44 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;42, &lt;4 x double&gt;* &#37;45, align 8
   &#37;index.next &#61; or i64 &#37;index, 4
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;46 &#61; add i64 &#37;20, &#37;index.next
   &#37;47 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;46
   &#37;48 &#61; bitcast double* &#37;47 to &lt;4 x double&gt;*
   &#37;wide.load.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;48, align 8
   &#37;49 &#61; add i64 &#37;21, &#37;index.next
   &#37;50 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;49
   &#37;51 &#61; bitcast double* &#37;50 to &lt;4 x double&gt;*
   &#37;wide.load232.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;51, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;52 &#61; fadd &lt;4 x double&gt; &#37;wide.load.1, &#37;wide.load232.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;53 &#61; add i64 &#37;22, &#37;index.next
   &#37;54 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;53
   &#37;55 &#61; bitcast double* &#37;54 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;52, &lt;4 x double&gt;* &#37;55, align 8
   &#37;index.next.1 &#61; or i64 &#37;index, 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;56 &#61; add i64 &#37;20, &#37;index.next.1
   &#37;57 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;56
   &#37;58 &#61; bitcast double* &#37;57 to &lt;4 x double&gt;*
   &#37;wide.load.2 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;58, align 8
   &#37;59 &#61; add i64 &#37;21, &#37;index.next.1
   &#37;60 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;59
   &#37;61 &#61; bitcast double* &#37;60 to &lt;4 x double&gt;*
   &#37;wide.load232.2 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;61, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;62 &#61; fadd &lt;4 x double&gt; &#37;wide.load.2, &#37;wide.load232.2
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;63 &#61; add i64 &#37;22, &#37;index.next.1
   &#37;64 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;63
   &#37;65 &#61; bitcast double* &#37;64 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;62, &lt;4 x double&gt;* &#37;65, align 8
   &#37;index.next.2 &#61; or i64 &#37;index, 12
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;66 &#61; add i64 &#37;20, &#37;index.next.2
   &#37;67 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;66
   &#37;68 &#61; bitcast double* &#37;67 to &lt;4 x double&gt;*
   &#37;wide.load.3 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;68, align 8
   &#37;69 &#61; add i64 &#37;21, &#37;index.next.2
   &#37;70 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;69
   &#37;71 &#61; bitcast double* &#37;70 to &lt;4 x double&gt;*
   &#37;wide.load232.3 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;71, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;72 &#61; fadd &lt;4 x double&gt; &#37;wide.load.3, &#37;wide.load232.3
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;73 &#61; add i64 &#37;22, &#37;index.next.2
   &#37;74 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;73
   &#37;75 &#61; bitcast double* &#37;74 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;72, &lt;4 x double&gt;* &#37;75, align 8
   &#37;index.next.3 &#61; or i64 &#37;index, 16
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;76 &#61; add i64 &#37;20, &#37;index.next.3
   &#37;77 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;76
   &#37;78 &#61; bitcast double* &#37;77 to &lt;4 x double&gt;*
   &#37;wide.load.4 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;78, align 8
   &#37;79 &#61; add i64 &#37;21, &#37;index.next.3
   &#37;80 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;79
   &#37;81 &#61; bitcast double* &#37;80 to &lt;4 x double&gt;*
   &#37;wide.load232.4 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;81, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;82 &#61; fadd &lt;4 x double&gt; &#37;wide.load.4, &#37;wide.load232.4
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;83 &#61; add i64 &#37;22, &#37;index.next.3
   &#37;84 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;83
   &#37;85 &#61; bitcast double* &#37;84 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;82, &lt;4 x double&gt;* &#37;85, align 8
   &#37;index.next.4 &#61; or i64 &#37;index, 20
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;86 &#61; add i64 &#37;20, &#37;index.next.4
   &#37;87 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;86
   &#37;88 &#61; bitcast double* &#37;87 to &lt;4 x double&gt;*
   &#37;wide.load.5 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;88, align 8
   &#37;89 &#61; add i64 &#37;21, &#37;index.next.4
   &#37;90 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;89
   &#37;91 &#61; bitcast double* &#37;90 to &lt;4 x double&gt;*
   &#37;wide.load232.5 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;91, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;92 &#61; fadd &lt;4 x double&gt; &#37;wide.load.5, &#37;wide.load232.5
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;93 &#61; add i64 &#37;22, &#37;index.next.4
   &#37;94 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;93
   &#37;95 &#61; bitcast double* &#37;94 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;92, &lt;4 x double&gt;* &#37;95, align 8
   &#37;index.next.5 &#61; or i64 &#37;index, 24
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;96 &#61; add i64 &#37;20, &#37;index.next.5
   &#37;97 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;96
   &#37;98 &#61; bitcast double* &#37;97 to &lt;4 x double&gt;*
   &#37;wide.load.6 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;98, align 8
   &#37;99 &#61; add i64 &#37;21, &#37;index.next.5
   &#37;100 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;99
   &#37;101 &#61; bitcast double* &#37;100 to &lt;4 x double&gt;*
   &#37;wide.load232.6 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;101, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;102 &#61; fadd &lt;4 x double&gt; &#37;wide.load.6, &#37;wide.load232.6
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;103 &#61; add i64 &#37;22, &#37;index.next.5
   &#37;104 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;103
   &#37;105 &#61; bitcast double* &#37;104 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;102, &lt;4 x double&gt;* &#37;105, align 8
   &#37;index.next.6 &#61; or i64 &#37;index, 28
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;106 &#61; add i64 &#37;20, &#37;index.next.6
   &#37;107 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;106
   &#37;108 &#61; bitcast double* &#37;107 to &lt;4 x double&gt;*
   &#37;wide.load.7 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;108, align 8
   &#37;109 &#61; add i64 &#37;21, &#37;index.next.6
   &#37;110 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;109
   &#37;111 &#61; bitcast double* &#37;110 to &lt;4 x double&gt;*
   &#37;wide.load232.7 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;111, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;112 &#61; fadd &lt;4 x double&gt; &#37;wide.load.7, &#37;wide.load232.7
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;113 &#61; add i64 &#37;22, &#37;index.next.6
   &#37;114 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;113
   &#37;115 &#61; bitcast double* &#37;114 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;112, &lt;4 x double&gt;* &#37;115, align 8
   &#37;index.next.7 &#61; add nuw i64 &#37;index, 32
   &#37;niter.next.7 &#61; add i64 &#37;niter, 8
   &#37;niter.ncmp.7 &#61; icmp eq i64 &#37;niter.next.7, &#37;unroll_iter
   br i1 &#37;niter.ncmp.7, label &#37;middle.block.unr-lcssa, label &#37;vector.body

middle.block.unr-lcssa:                           ; preds &#61; &#37;vector.body, &#37;
vector.ph
   &#37;index.unr &#61; phi i64 &#91; 0, &#37;vector.ph &#93;, &#91; &#37;index.next.7, &#37;vector.body &#93;
   &#37;lcmp.mod.not &#61; icmp eq i64 &#37;xtraiter, 0
   br i1 &#37;lcmp.mod.not, label &#37;middle.block, label &#37;vector.body.epil

vector.body.epil:                                 ; preds &#61; &#37;vector.body.ep
il, &#37;middle.block.unr-lcssa
   &#37;index.epil &#61; phi i64 &#91; &#37;index.next.epil, &#37;vector.body.epil &#93;, &#91; &#37;index.
unr, &#37;middle.block.unr-lcssa &#93;
   &#37;epil.iter &#61; phi i64 &#91; &#37;epil.iter.next, &#37;vector.body.epil &#93;, &#91; 0, &#37;middl
e.block.unr-lcssa &#93;
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;116 &#61; add i64 &#37;20, &#37;index.epil
   &#37;117 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;116
   &#37;118 &#61; bitcast double* &#37;117 to &lt;4 x double&gt;*
   &#37;wide.load.epil &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;118, align 8
   &#37;119 &#61; add i64 &#37;21, &#37;index.epil
   &#37;120 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;119
   &#37;121 &#61; bitcast double* &#37;120 to &lt;4 x double&gt;*
   &#37;wide.load232.epil &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;121, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;122 &#61; fadd &lt;4 x double&gt; &#37;wide.load.epil, &#37;wide.load232.epil
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;123 &#61; add i64 &#37;22, &#37;index.epil
   &#37;124 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;123
   &#37;125 &#61; bitcast double* &#37;124 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;122, &lt;4 x double&gt;* &#37;125, align 8
   &#37;index.next.epil &#61; add nuw i64 &#37;index.epil, 4
   &#37;epil.iter.next &#61; add i64 &#37;epil.iter, 1
   &#37;epil.iter.cmp.not &#61; icmp eq i64 &#37;epil.iter.next, &#37;xtraiter
   br i1 &#37;epil.iter.cmp.not, label &#37;middle.block, label &#37;vector.body.epil

middle.block:                                     ; preds &#61; &#37;vector.body.ep
il, &#37;middle.block.unr-lcssa
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
  &#37;cmp.n &#61; icmp eq i64 &#37;exit.mainloop.at, &#37;n.vec
  br i1 &#37;cmp.n, label &#37;main.exit.selector, label &#37;scalar.ph

scalar.ph:                                        ; preds &#61; &#37;middle.block, 
&#37;vector.memcheck, &#37;ib24.us.us.us.preheader
  &#37;bc.resume.val &#61; phi i64 &#91; &#37;ind.end, &#37;middle.block &#93;, &#91; 1, &#37;ib24.us.us.us
.preheader &#93;, &#91; 1, &#37;vector.memcheck &#93;
  br label &#37;ib24.us.us.us

ib24.us.us.us:                                    ; preds &#61; &#37;ib24.us.us.us,
 &#37;scalar.ph
  &#37;value_phi2.us.us.us &#61; phi i64 &#91; &#37;134, &#37;ib24.us.us.us &#93;, &#91; &#37;bc.resume.val
, &#37;scalar.ph &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;126 &#61; add nsw i64 &#37;value_phi2.us.us.us, -1
   &#37;127 &#61; add i64 &#37;20, &#37;126
   &#37;128 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;127
   &#37;arrayref.us.us.us &#61; load double, double* &#37;128, align 8
   &#37;129 &#61; add i64 &#37;21, &#37;126
   &#37;130 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;129
   &#37;arrayref20.us.us.us &#61; load double, double* &#37;130, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;131 &#61; fadd double &#37;arrayref.us.us.us, &#37;arrayref20.us.us.us
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;132 &#61; add i64 &#37;22, &#37;126
   &#37;133 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;132
   store double &#37;131, double* &#37;133, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;134 &#61; add nuw i64 &#37;value_phi2.us.us.us, 1
; └
  &#37;.not197 &#61; icmp ult i64 &#37;value_phi2.us.us.us, &#37;exit.mainloop.at
  br i1 &#37;.not197, label &#37;ib24.us.us.us, label &#37;main.exit.selector

main.exit.selector:                               ; preds &#61; &#37;ib24.us.us.us,
 &#37;middle.block
  &#37;value_phi2.us.us.us.lcssa &#61; phi i64 &#91; &#37;exit.mainloop.at, &#37;middle.block &#93;
, &#91; &#37;value_phi2.us.us.us, &#37;ib24.us.us.us &#93;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;.lcssa &#61; phi i64 &#91; &#37;ind.end, &#37;middle.block &#93;, &#91; &#37;134, &#37;ib24.us.us.us &#93;
; └
  &#37;135 &#61; icmp ult i64 &#37;value_phi2.us.us.us.lcssa, 100
  br i1 &#37;135, label &#37;main.pseudo.exit, label &#37;L27.split.us.split.us.split.u
s

main.pseudo.exit:                                 ; preds &#61; &#37;main.exit.sele
ctor, &#37;L2.split.us.split.us.split.us
  &#37;value_phi2.us.us.us.copy &#61; phi i64 &#91; 1, &#37;L2.split.us.split.us.split.us &#93;
, &#91; &#37;.lcssa, &#37;main.exit.selector &#93;
  br label &#37;L5.us.us.us.postloop

L27.split.us.split.us.split.us:                   ; preds &#61; &#37;ib24.us.us.us.
postloop, &#37;main.exit.selector
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;136 &#61; add nuw nsw i64 &#37;value_phi, 1
; └
  &#37;indvar.next &#61; or i64 &#37;indvar, 1
  &#37;137 &#61; shl nuw nsw i64 &#37;indvar.next, 3
  &#37;138 &#61; mul i64 &#37;arraysize, &#37;indvar.next
  &#37;arraysize5.1 &#61; load i64, i64* &#37;7, align 8
  &#37;inbounds6.1 &#61; icmp ult i64 &#37;value_phi, &#37;arraysize5.1
  &#37;139 &#61; mul i64 &#37;arraysize, &#37;value_phi
  &#37;arrayptr41.1 &#61; load double*, double** &#37;8, align 8
  &#37;arraysize8.1 &#61; load i64, i64* &#37;10, align 8
  &#37;140 &#61; mul i64 &#37;arraysize8.1, &#37;value_phi
  &#37;arrayptr1943.1 &#61; load double*, double** &#37;12, align 8
  &#37;arrayptr1943224.1 &#61; bitcast double* &#37;arrayptr1943.1 to i8*
  &#37;arraysize22.1 &#61; load i64, i64* &#37;14, align 8
  &#37;arraysize27.1 &#61; load i64, i64* &#37;15, align 8
  &#37;inbounds28.1 &#61; icmp ult i64 &#37;value_phi, &#37;arraysize27.1
  &#37;141 &#61; mul i64 &#37;arraysize22.1, &#37;value_phi
  &#37;arrayptr3345.1 &#61; load double*, double** &#37;16, align 8
  &#37;arrayptr3345217.1 &#61; bitcast double* &#37;arrayptr3345.1 to i8*
  &#37;inbounds6.fr.1 &#61; freeze i1 &#37;inbounds6.1
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   br i1 &#37;inbounds6.fr.1, label &#37;L2.split.us.1, label &#37;oob

L2.split.us.1:                                    ; preds &#61; &#37;L27.split.us.s
plit.us.split.us
   &#37;arraysize13.1 &#61; load i64, i64* &#37;11, align 8
   &#37;inbounds14.1 &#61; icmp ult i64 &#37;value_phi, &#37;arraysize13.1
   &#37;inbounds14.fr.1 &#61; freeze i1 &#37;inbounds14.1
   br i1 &#37;inbounds14.fr.1, label &#37;L2.split.us.split.us.1, label &#37;L2.split.u
s.split

L2.split.us.split.us.1:                           ; preds &#61; &#37;L2.split.us.1
   &#37;inbounds28.fr.1 &#61; freeze i1 &#37;inbounds28.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   br i1 &#37;inbounds28.fr.1, label &#37;L2.split.us.split.us.split.us.1, label &#37;L
2.split.us.split.us.split

L2.split.us.split.us.split.us.1:                  ; preds &#61; &#37;L2.split.us.sp
lit.us.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
3 within &#96;inner_noalloc&#33;&#96;
  &#37;smin.1 &#61; call i64 @llvm.smin.i64&#40;i64 &#37;arraysize8.1, i64 0&#41;
  &#37;142 &#61; sub i64 &#37;arraysize8.1, &#37;smin.1
  &#37;smax.1 &#61; call i64 @llvm.smax.i64&#40;i64 &#37;smin.1, i64 -1&#41;
  &#37;143 &#61; add nsw i64 &#37;smax.1, 1
  &#37;144 &#61; mul nuw nsw i64 &#37;142, &#37;143
  &#37;umin.1 &#61; call i64 @llvm.umin.i64&#40;i64 &#37;arraysize, i64 &#37;144&#41;
  &#37;smin156.1 &#61; call i64 @llvm.smin.i64&#40;i64 &#37;arraysize22.1, i64 0&#41;
  &#37;145 &#61; sub i64 &#37;arraysize22.1, &#37;smin156.1
  &#37;smax157.1 &#61; call i64 @llvm.smax.i64&#40;i64 &#37;smin156.1, i64 -1&#41;
  &#37;146 &#61; add nsw i64 &#37;smax157.1, 1
  &#37;147 &#61; mul nuw nsw i64 &#37;145, &#37;146
  &#37;umin158.1 &#61; call i64 @llvm.umin.i64&#40;i64 &#37;umin.1, i64 &#37;147&#41;
  &#37;exit.mainloop.at.1 &#61; call i64 @llvm.umin.i64&#40;i64 &#37;umin158.1, i64 100&#41;
  &#37;.not196.1 &#61; icmp eq i64 &#37;exit.mainloop.at.1, 0
  br i1 &#37;.not196.1, label &#37;main.pseudo.exit.1, label &#37;ib24.us.us.us.prehead
er.1

ib24.us.us.us.preheader.1:                        ; preds &#61; &#37;L2.split.us.sp
lit.us.split.us.1
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
  &#37;min.iters.check.1 &#61; icmp ult i64 &#37;exit.mainloop.at.1, 12
  br i1 &#37;min.iters.check.1, label &#37;scalar.ph.1, label &#37;vector.memcheck.1

vector.memcheck.1:                                ; preds &#61; &#37;ib24.us.us.us.
preheader.1
  &#37;148 &#61; mul i64 &#37;arraysize22.1, &#37;137
  &#37;uglygep.1 &#61; getelementptr i8, i8* &#37;arrayptr3345217.1, i64 &#37;148
  &#37;scevgep.1 &#61; getelementptr double, double* &#37;arrayptr3345.1, i64 &#37;exit.mai
nloop.at.1
  &#37;scevgep218.1 &#61; bitcast double* &#37;scevgep.1 to i8*
  &#37;uglygep219.1 &#61; getelementptr i8, i8* &#37;scevgep218.1, i64 &#37;148
  &#37;scevgep220.1 &#61; getelementptr double, double* &#37;arrayptr41.1, i64 &#37;138
  &#37;scevgep220221.1 &#61; bitcast double* &#37;scevgep220.1 to i8*
  &#37;149 &#61; add i64 &#37;exit.mainloop.at.1, &#37;138
  &#37;scevgep222.1 &#61; getelementptr double, double* &#37;arrayptr41.1, i64 &#37;149
  &#37;scevgep222223.1 &#61; bitcast double* &#37;scevgep222.1 to i8*
  &#37;150 &#61; mul i64 &#37;arraysize8.1, &#37;137
  &#37;uglygep225.1 &#61; getelementptr i8, i8* &#37;arrayptr1943224.1, i64 &#37;150
  &#37;scevgep226.1 &#61; getelementptr double, double* &#37;arrayptr1943.1, i64 &#37;exit.
mainloop.at.1
  &#37;scevgep226227.1 &#61; bitcast double* &#37;scevgep226.1 to i8*
  &#37;uglygep228.1 &#61; getelementptr i8, i8* &#37;scevgep226227.1, i64 &#37;150
  &#37;bound0.1 &#61; icmp ult i8* &#37;uglygep.1, &#37;scevgep222223.1
  &#37;bound1.1 &#61; icmp ugt i8* &#37;uglygep219.1, &#37;scevgep220221.1
  &#37;found.conflict.1 &#61; and i1 &#37;bound0.1, &#37;bound1.1
  &#37;bound0229.1 &#61; icmp ult i8* &#37;uglygep.1, &#37;uglygep228.1
  &#37;bound1230.1 &#61; icmp ult i8* &#37;uglygep225.1, &#37;uglygep219.1
  &#37;found.conflict231.1 &#61; and i1 &#37;bound0229.1, &#37;bound1230.1
  &#37;conflict.rdx.1 &#61; or i1 &#37;found.conflict.1, &#37;found.conflict231.1
  br i1 &#37;conflict.rdx.1, label &#37;scalar.ph.1, label &#37;vector.ph.1

vector.ph.1:                                      ; preds &#61; &#37;vector.memchec
k.1
  &#37;n.vec.1 &#61; and i64 &#37;exit.mainloop.at.1, 124
  &#37;ind.end.1 &#61; or i64 &#37;n.vec.1, 1
  &#37;151 &#61; add nsw i64 &#37;n.vec.1, -4
  &#37;152 &#61; lshr exact i64 &#37;151, 2
  &#37;153 &#61; add nuw nsw i64 &#37;152, 1
  &#37;xtraiter.1 &#61; and i64 &#37;153, 7
  &#37;154 &#61; icmp ult i64 &#37;151, 28
  br i1 &#37;154, label &#37;middle.block.unr-lcssa.1, label &#37;vector.ph.new.1

vector.ph.new.1:                                  ; preds &#61; &#37;vector.ph.1
  &#37;unroll_iter.1 &#61; and i64 &#37;153, 9223372036854775800
  br label &#37;vector.body.1

vector.body.1:                                    ; preds &#61; &#37;vector.body.1,
 &#37;vector.ph.new.1
  &#37;index.1 &#61; phi i64 &#91; 0, &#37;vector.ph.new.1 &#93;, &#91; &#37;index.next.7.1, &#37;vector.bo
dy.1 &#93;
  &#37;niter.1 &#61; phi i64 &#91; 0, &#37;vector.ph.new.1 &#93;, &#91; &#37;niter.next.7.1, &#37;vector.bo
dy.1 &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;155 &#61; add i64 &#37;139, &#37;index.1
   &#37;156 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;155
   &#37;157 &#61; bitcast double* &#37;156 to &lt;4 x double&gt;*
   &#37;wide.load.1254 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;157, align 8
   &#37;158 &#61; add i64 &#37;140, &#37;index.1
   &#37;159 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;158
   &#37;160 &#61; bitcast double* &#37;159 to &lt;4 x double&gt;*
   &#37;wide.load232.1255 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;160, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;161 &#61; fadd &lt;4 x double&gt; &#37;wide.load.1254, &#37;wide.load232.1255
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;162 &#61; add i64 &#37;141, &#37;index.1
   &#37;163 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;162
   &#37;164 &#61; bitcast double* &#37;163 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;161, &lt;4 x double&gt;* &#37;164, align 8
   &#37;index.next.1256 &#61; or i64 &#37;index.1, 4
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;165 &#61; add i64 &#37;139, &#37;index.next.1256
   &#37;166 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;165
   &#37;167 &#61; bitcast double* &#37;166 to &lt;4 x double&gt;*
   &#37;wide.load.1.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;167, align 8
   &#37;168 &#61; add i64 &#37;140, &#37;index.next.1256
   &#37;169 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;168
   &#37;170 &#61; bitcast double* &#37;169 to &lt;4 x double&gt;*
   &#37;wide.load232.1.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;170, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;171 &#61; fadd &lt;4 x double&gt; &#37;wide.load.1.1, &#37;wide.load232.1.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;172 &#61; add i64 &#37;141, &#37;index.next.1256
   &#37;173 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;172
   &#37;174 &#61; bitcast double* &#37;173 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;171, &lt;4 x double&gt;* &#37;174, align 8
   &#37;index.next.1.1 &#61; or i64 &#37;index.1, 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;175 &#61; add i64 &#37;139, &#37;index.next.1.1
   &#37;176 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;175
   &#37;177 &#61; bitcast double* &#37;176 to &lt;4 x double&gt;*
   &#37;wide.load.2.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;177, align 8
   &#37;178 &#61; add i64 &#37;140, &#37;index.next.1.1
   &#37;179 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;178
   &#37;180 &#61; bitcast double* &#37;179 to &lt;4 x double&gt;*
   &#37;wide.load232.2.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;180, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;181 &#61; fadd &lt;4 x double&gt; &#37;wide.load.2.1, &#37;wide.load232.2.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;182 &#61; add i64 &#37;141, &#37;index.next.1.1
   &#37;183 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;182
   &#37;184 &#61; bitcast double* &#37;183 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;181, &lt;4 x double&gt;* &#37;184, align 8
   &#37;index.next.2.1 &#61; or i64 &#37;index.1, 12
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;185 &#61; add i64 &#37;139, &#37;index.next.2.1
   &#37;186 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;185
   &#37;187 &#61; bitcast double* &#37;186 to &lt;4 x double&gt;*
   &#37;wide.load.3.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;187, align 8
   &#37;188 &#61; add i64 &#37;140, &#37;index.next.2.1
   &#37;189 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;188
   &#37;190 &#61; bitcast double* &#37;189 to &lt;4 x double&gt;*
   &#37;wide.load232.3.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;190, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;191 &#61; fadd &lt;4 x double&gt; &#37;wide.load.3.1, &#37;wide.load232.3.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;192 &#61; add i64 &#37;141, &#37;index.next.2.1
   &#37;193 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;192
   &#37;194 &#61; bitcast double* &#37;193 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;191, &lt;4 x double&gt;* &#37;194, align 8
   &#37;index.next.3.1 &#61; or i64 &#37;index.1, 16
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;195 &#61; add i64 &#37;139, &#37;index.next.3.1
   &#37;196 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;195
   &#37;197 &#61; bitcast double* &#37;196 to &lt;4 x double&gt;*
   &#37;wide.load.4.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;197, align 8
   &#37;198 &#61; add i64 &#37;140, &#37;index.next.3.1
   &#37;199 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;198
   &#37;200 &#61; bitcast double* &#37;199 to &lt;4 x double&gt;*
   &#37;wide.load232.4.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;200, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;201 &#61; fadd &lt;4 x double&gt; &#37;wide.load.4.1, &#37;wide.load232.4.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;202 &#61; add i64 &#37;141, &#37;index.next.3.1
   &#37;203 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;202
   &#37;204 &#61; bitcast double* &#37;203 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;201, &lt;4 x double&gt;* &#37;204, align 8
   &#37;index.next.4.1 &#61; or i64 &#37;index.1, 20
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;205 &#61; add i64 &#37;139, &#37;index.next.4.1
   &#37;206 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;205
   &#37;207 &#61; bitcast double* &#37;206 to &lt;4 x double&gt;*
   &#37;wide.load.5.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;207, align 8
   &#37;208 &#61; add i64 &#37;140, &#37;index.next.4.1
   &#37;209 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;208
   &#37;210 &#61; bitcast double* &#37;209 to &lt;4 x double&gt;*
   &#37;wide.load232.5.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;210, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;211 &#61; fadd &lt;4 x double&gt; &#37;wide.load.5.1, &#37;wide.load232.5.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;212 &#61; add i64 &#37;141, &#37;index.next.4.1
   &#37;213 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;212
   &#37;214 &#61; bitcast double* &#37;213 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;211, &lt;4 x double&gt;* &#37;214, align 8
   &#37;index.next.5.1 &#61; or i64 &#37;index.1, 24
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;215 &#61; add i64 &#37;139, &#37;index.next.5.1
   &#37;216 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;215
   &#37;217 &#61; bitcast double* &#37;216 to &lt;4 x double&gt;*
   &#37;wide.load.6.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;217, align 8
   &#37;218 &#61; add i64 &#37;140, &#37;index.next.5.1
   &#37;219 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;218
   &#37;220 &#61; bitcast double* &#37;219 to &lt;4 x double&gt;*
   &#37;wide.load232.6.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;220, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;221 &#61; fadd &lt;4 x double&gt; &#37;wide.load.6.1, &#37;wide.load232.6.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;222 &#61; add i64 &#37;141, &#37;index.next.5.1
   &#37;223 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;222
   &#37;224 &#61; bitcast double* &#37;223 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;221, &lt;4 x double&gt;* &#37;224, align 8
   &#37;index.next.6.1 &#61; or i64 &#37;index.1, 28
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;225 &#61; add i64 &#37;139, &#37;index.next.6.1
   &#37;226 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;225
   &#37;227 &#61; bitcast double* &#37;226 to &lt;4 x double&gt;*
   &#37;wide.load.7.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;227, align 8
   &#37;228 &#61; add i64 &#37;140, &#37;index.next.6.1
   &#37;229 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;228
   &#37;230 &#61; bitcast double* &#37;229 to &lt;4 x double&gt;*
   &#37;wide.load232.7.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;230, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;231 &#61; fadd &lt;4 x double&gt; &#37;wide.load.7.1, &#37;wide.load232.7.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;232 &#61; add i64 &#37;141, &#37;index.next.6.1
   &#37;233 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;232
   &#37;234 &#61; bitcast double* &#37;233 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;231, &lt;4 x double&gt;* &#37;234, align 8
   &#37;index.next.7.1 &#61; add nuw i64 &#37;index.1, 32
   &#37;niter.next.7.1 &#61; add i64 &#37;niter.1, 8
   &#37;niter.ncmp.7.1 &#61; icmp eq i64 &#37;niter.next.7.1, &#37;unroll_iter.1
   br i1 &#37;niter.ncmp.7.1, label &#37;middle.block.unr-lcssa.1, label &#37;vector.bo
dy.1

middle.block.unr-lcssa.1:                         ; preds &#61; &#37;vector.body.1,
 &#37;vector.ph.1
   &#37;index.unr.1 &#61; phi i64 &#91; 0, &#37;vector.ph.1 &#93;, &#91; &#37;index.next.7.1, &#37;vector.b
ody.1 &#93;
   &#37;lcmp.mod.1.not &#61; icmp eq i64 &#37;xtraiter.1, 0
   br i1 &#37;lcmp.mod.1.not, label &#37;middle.block.1, label &#37;vector.body.epil.1

vector.body.epil.1:                               ; preds &#61; &#37;vector.body.ep
il.1, &#37;middle.block.unr-lcssa.1
   &#37;index.epil.1 &#61; phi i64 &#91; &#37;index.next.epil.1, &#37;vector.body.epil.1 &#93;, &#91; &#37;
index.unr.1, &#37;middle.block.unr-lcssa.1 &#93;
   &#37;epil.iter.1 &#61; phi i64 &#91; &#37;epil.iter.next.1, &#37;vector.body.epil.1 &#93;, &#91; 0, 
&#37;middle.block.unr-lcssa.1 &#93;
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;235 &#61; add i64 &#37;139, &#37;index.epil.1
   &#37;236 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;235
   &#37;237 &#61; bitcast double* &#37;236 to &lt;4 x double&gt;*
   &#37;wide.load.epil.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;237, align 8
   &#37;238 &#61; add i64 &#37;140, &#37;index.epil.1
   &#37;239 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;238
   &#37;240 &#61; bitcast double* &#37;239 to &lt;4 x double&gt;*
   &#37;wide.load232.epil.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;240, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;241 &#61; fadd &lt;4 x double&gt; &#37;wide.load.epil.1, &#37;wide.load232.epil.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;242 &#61; add i64 &#37;141, &#37;index.epil.1
   &#37;243 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;242
   &#37;244 &#61; bitcast double* &#37;243 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;241, &lt;4 x double&gt;* &#37;244, align 8
   &#37;index.next.epil.1 &#61; add nuw i64 &#37;index.epil.1, 4
   &#37;epil.iter.next.1 &#61; add i64 &#37;epil.iter.1, 1
   &#37;epil.iter.cmp.1.not &#61; icmp eq i64 &#37;epil.iter.next.1, &#37;xtraiter.1
   br i1 &#37;epil.iter.cmp.1.not, label &#37;middle.block.1, label &#37;vector.body.ep
il.1

middle.block.1:                                   ; preds &#61; &#37;vector.body.ep
il.1, &#37;middle.block.unr-lcssa.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
  &#37;cmp.n.1 &#61; icmp eq i64 &#37;exit.mainloop.at.1, &#37;n.vec.1
  br i1 &#37;cmp.n.1, label &#37;main.exit.selector.1, label &#37;scalar.ph.1

scalar.ph.1:                                      ; preds &#61; &#37;middle.block.1
, &#37;vector.memcheck.1, &#37;ib24.us.us.us.preheader.1
  &#37;bc.resume.val.1 &#61; phi i64 &#91; &#37;ind.end.1, &#37;middle.block.1 &#93;, &#91; 1, &#37;ib24.us
.us.us.preheader.1 &#93;, &#91; 1, &#37;vector.memcheck.1 &#93;
  br label &#37;ib24.us.us.us.1

ib24.us.us.us.1:                                  ; preds &#61; &#37;ib24.us.us.us.
1, &#37;scalar.ph.1
  &#37;value_phi2.us.us.us.1 &#61; phi i64 &#91; &#37;253, &#37;ib24.us.us.us.1 &#93;, &#91; &#37;bc.resume
.val.1, &#37;scalar.ph.1 &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;245 &#61; add nsw i64 &#37;value_phi2.us.us.us.1, -1
   &#37;246 &#61; add i64 &#37;139, &#37;245
   &#37;247 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;246
   &#37;arrayref.us.us.us.1 &#61; load double, double* &#37;247, align 8
   &#37;248 &#61; add i64 &#37;140, &#37;245
   &#37;249 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;248
   &#37;arrayref20.us.us.us.1 &#61; load double, double* &#37;249, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;250 &#61; fadd double &#37;arrayref.us.us.us.1, &#37;arrayref20.us.us.us.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;251 &#61; add i64 &#37;141, &#37;245
   &#37;252 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;251
   store double &#37;250, double* &#37;252, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;253 &#61; add nuw i64 &#37;value_phi2.us.us.us.1, 1
; └
  &#37;.not197.1 &#61; icmp ult i64 &#37;value_phi2.us.us.us.1, &#37;exit.mainloop.at.1
  br i1 &#37;.not197.1, label &#37;ib24.us.us.us.1, label &#37;main.exit.selector.1

main.exit.selector.1:                             ; preds &#61; &#37;ib24.us.us.us.
1, &#37;middle.block.1
  &#37;value_phi2.us.us.us.lcssa.1 &#61; phi i64 &#91; &#37;exit.mainloop.at.1, &#37;middle.blo
ck.1 &#93;, &#91; &#37;value_phi2.us.us.us.1, &#37;ib24.us.us.us.1 &#93;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;.lcssa.1 &#61; phi i64 &#91; &#37;ind.end.1, &#37;middle.block.1 &#93;, &#91; &#37;253, &#37;ib24.us.us
.us.1 &#93;
; └
  &#37;254 &#61; icmp ult i64 &#37;value_phi2.us.us.us.lcssa.1, 100
  br i1 &#37;254, label &#37;main.pseudo.exit.1, label &#37;L27.split.us.split.us.split
.us.1

main.pseudo.exit.1:                               ; preds &#61; &#37;main.exit.sele
ctor.1, &#37;L2.split.us.split.us.split.us.1
  &#37;value_phi2.us.us.us.copy.1 &#61; phi i64 &#91; 1, &#37;L2.split.us.split.us.split.us
.1 &#93;, &#91; &#37;.lcssa.1, &#37;main.exit.selector.1 &#93;
  br label &#37;L5.us.us.us.postloop.1

L5.us.us.us.postloop.1:                           ; preds &#61; &#37;ib24.us.us.us.
postloop.1, &#37;main.pseudo.exit.1
  &#37;value_phi2.us.us.us.postloop.1 &#61; phi i64 &#91; &#37;value_phi2.us.us.us.copy.1, 
&#37;main.pseudo.exit.1 &#93;, &#91; &#37;263, &#37;ib24.us.us.us.postloop.1 &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;255 &#61; add i64 &#37;value_phi2.us.us.us.postloop.1, -1
   &#37;inbounds.us.us.us.postloop.1 &#61; icmp ult i64 &#37;255, &#37;arraysize
   br i1 &#37;inbounds.us.us.us.postloop.1, label &#37;ib.us.us.us.postloop.1, labe
l &#37;oob

ib.us.us.us.postloop.1:                           ; preds &#61; &#37;L5.us.us.us.po
stloop.1
   &#37;inbounds9.us.us.us.postloop.1 &#61; icmp ult i64 &#37;255, &#37;arraysize8.1
   br i1 &#37;inbounds9.us.us.us.postloop.1, label &#37;ib10.us.us.us.postloop.1, l
abel &#37;oob15.split.us

ib10.us.us.us.postloop.1:                         ; preds &#61; &#37;ib.us.us.us.po
stloop.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;inbounds23.us.us.us.postloop.1 &#61; icmp ult i64 &#37;255, &#37;arraysize22.1
   br i1 &#37;inbounds23.us.us.us.postloop.1, label &#37;ib24.us.us.us.postloop.1, 
label &#37;oob29.split.us.split.us

ib24.us.us.us.postloop.1:                         ; preds &#61; &#37;ib10.us.us.us.
postloop.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;256 &#61; add i64 &#37;139, &#37;255
   &#37;257 &#61; getelementptr inbounds double, double* &#37;arrayptr41.1, i64 &#37;256
   &#37;arrayref.us.us.us.postloop.1 &#61; load double, double* &#37;257, align 8
   &#37;258 &#61; add i64 &#37;140, &#37;255
   &#37;259 &#61; getelementptr inbounds double, double* &#37;arrayptr1943.1, i64 &#37;258
   &#37;arrayref20.us.us.us.postloop.1 &#61; load double, double* &#37;259, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;260 &#61; fadd double &#37;arrayref.us.us.us.postloop.1, &#37;arrayref20.us.us.us.p
ostloop.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;261 &#61; add i64 &#37;141, &#37;255
   &#37;262 &#61; getelementptr inbounds double, double* &#37;arrayptr3345.1, i64 &#37;261
   store double &#37;260, double* &#37;262, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
; │┌ @ promotion.jl:521 within &#96;&#61;&#61;&#96;
    &#37;.not.not.us.us.us.postloop.1 &#61; icmp eq i64 &#37;value_phi2.us.us.us.postlo
op.1, 100
; │└
   &#37;263 &#61; add nuw nsw i64 &#37;value_phi2.us.us.us.postloop.1, 1
; └
  br i1 &#37;.not.not.us.us.us.postloop.1, label &#37;L27.split.us.split.us.split.u
s.1, label &#37;L5.us.us.us.postloop.1

L27.split.us.split.us.split.us.1:                 ; preds &#61; &#37;ib24.us.us.us.
postloop.1, &#37;main.exit.selector.1
; ┌ @ range.jl:901 within &#96;iterate&#96;
; │┌ @ promotion.jl:521 within &#96;&#61;&#61;&#96;
    &#37;.not.1 &#61; icmp eq i64 &#37;136, 100
; │└
   &#37;264 &#61; add nuw nsw i64 &#37;value_phi, 2
; └
  &#37;indvar.next.1 &#61; add nuw nsw i64 &#37;indvar, 2
  br i1 &#37;.not.1, label &#37;L38, label &#37;L2

L2.split.us.split.us.split:                       ; preds &#61; &#37;L2.split.us.sp
lit.us.1, &#37;L2.split.us.split.us
  &#37;value_phi.lcssa246 &#61; phi i64 &#91; &#37;value_phi, &#37;L2.split.us.split.us &#93;, &#91; &#37;1
36, &#37;L2.split.us.split.us.1 &#93;
  &#37;arraysize8.lcssa240 &#61; phi i64 &#91; &#37;arraysize8, &#37;L2.split.us.split.us &#93;, &#91; 
&#37;arraysize8.1, &#37;L2.split.us.split.us.1 &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;inbounds.us.us.not &#61; icmp eq i64 &#37;arraysize, 0
   br i1 &#37;inbounds.us.us.not, label &#37;oob, label &#37;ib.us.us

ib.us.us:                                         ; preds &#61; &#37;L2.split.us.sp
lit.us.split
   &#37;inbounds9.us.us.not &#61; icmp eq i64 &#37;arraysize8.lcssa240, 0
   br i1 &#37;inbounds9.us.us.not, label &#37;oob15.split.us, label &#37;oob29.split.us
.split.us

oob29.split.us.split.us:                          ; preds &#61; &#37;ib10.us.us.us.
postloop, &#37;ib.us.us, &#37;ib10.us.us.us.postloop.1
   &#37;value_phi251 &#61; phi i64 &#91; &#37;value_phi.lcssa246, &#37;ib.us.us &#93;, &#91; &#37;value_phi
, &#37;ib10.us.us.us.postloop &#93;, &#91; &#37;136, &#37;ib10.us.us.us.postloop.1 &#93;
   &#37;.us-phi104 &#61; phi i64 &#91; 1, &#37;ib.us.us &#93;, &#91; &#37;value_phi2.us.us.us.postloop,
 &#37;ib10.us.us.us.postloop &#93;, &#91; &#37;value_phi2.us.us.us.postloop.1, &#37;ib10.us.us.
us.postloop.1 &#93;
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;errorbox3044 &#61; alloca &#91;2 x i64&#93;, align 8
   &#37;errorbox3044.sub &#61; getelementptr inbounds &#91;2 x i64&#93;, &#91;2 x i64&#93;* &#37;errorb
ox3044, i64 0, i64 0
   store i64 &#37;.us-phi104, i64* &#37;errorbox3044.sub, align 8
   &#37;265 &#61; getelementptr inbounds &#91;2 x i64&#93;, &#91;2 x i64&#93;* &#37;errorbox3044, i64 0
, i64 1
   store i64 &#37;value_phi251, i64* &#37;265, align 8
   call void @ijl_bounds_error_ints&#40;&#123;&#125;* &#37;0, i64* nonnull &#37;errorbox3044.sub,
 i64 2&#41;
   unreachable

L2.split.us.split:                                ; preds &#61; &#37;L2.split.us.1,
 &#37;L2.split.us
   &#37;value_phi.lcssa245 &#61; phi i64 &#91; &#37;value_phi, &#37;L2.split.us &#93;, &#91; &#37;136, &#37;L2.
split.us.1 &#93;
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;inbounds.us.not &#61; icmp eq i64 &#37;arraysize, 0
   br i1 &#37;inbounds.us.not, label &#37;oob, label &#37;oob15.split.us

oob15.split.us:                                   ; preds &#61; &#37;ib.us.us.us.po
stloop, &#37;L2.split.us.split, &#37;ib.us.us, &#37;ib.us.us.us.postloop.1
   &#37;value_phi252 &#61; phi i64 &#91; &#37;value_phi.lcssa246, &#37;ib.us.us &#93;, &#91; &#37;value_phi
.lcssa245, &#37;L2.split.us.split &#93;, &#91; &#37;value_phi, &#37;ib.us.us.us.postloop &#93;, &#91; &#37;
136, &#37;ib.us.us.us.postloop.1 &#93;
   &#37;.us-phi69 &#61; phi i64 &#91; 1, &#37;ib.us.us &#93;, &#91; 1, &#37;L2.split.us.split &#93;, &#91; &#37;val
ue_phi2.us.us.us.postloop, &#37;ib.us.us.us.postloop &#93;, &#91; &#37;value_phi2.us.us.us.
postloop.1, &#37;ib.us.us.us.postloop.1 &#93;
   &#37;errorbox1642 &#61; alloca &#91;2 x i64&#93;, align 8
   &#37;errorbox1642.sub &#61; getelementptr inbounds &#91;2 x i64&#93;, &#91;2 x i64&#93;* &#37;errorb
ox1642, i64 0, i64 0
   store i64 &#37;.us-phi69, i64* &#37;errorbox1642.sub, align 8
   &#37;266 &#61; getelementptr inbounds &#91;2 x i64&#93;, &#91;2 x i64&#93;* &#37;errorbox1642, i64 0
, i64 1
   store i64 &#37;value_phi252, i64* &#37;266, align 8
   call void @ijl_bounds_error_ints&#40;&#123;&#125;* &#37;4, i64* nonnull &#37;errorbox1642.sub,
 i64 2&#41;
   unreachable

L38:                                              ; preds &#61; &#37;L27.split.us.s
plit.us.split.us.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
  ret &#123;&#125;* inttoptr &#40;i64 140125612802056 to &#123;&#125;*&#41;

oob:                                              ; preds &#61; &#37;L5.us.us.us.po
stloop, &#37;L2.split.us.split, &#37;L2.split.us.split.us.split, &#37;L5.us.us.us.postl
oop.1, &#37;L27.split.us.split.us.split.us, &#37;L2
  &#37;value_phi253 &#61; phi i64 &#91; &#37;value_phi.lcssa246, &#37;L2.split.us.split.us.spli
t &#93;, &#91; &#37;value_phi.lcssa245, &#37;L2.split.us.split &#93;, &#91; &#37;value_phi, &#37;L5.us.us.u
s.postloop &#93;, &#91; &#37;136, &#37;L5.us.us.us.postloop.1 &#93;, &#91; &#37;value_phi, &#37;L2 &#93;, &#91; &#37;13
6, &#37;L27.split.us.split.us.split.us &#93;
  &#37;.us-phi52 &#61; phi i64 &#91; 1, &#37;L2.split.us.split.us.split &#93;, &#91; 1, &#37;L2.split.u
s.split &#93;, &#91; &#37;value_phi2.us.us.us.postloop, &#37;L5.us.us.us.postloop &#93;, &#91; &#37;val
ue_phi2.us.us.us.postloop.1, &#37;L5.us.us.us.postloop.1 &#93;, &#91; 1, &#37;L27.split.us.
split.us.split.us &#93;, &#91; 1, &#37;L2 &#93;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;errorbox40 &#61; alloca &#91;2 x i64&#93;, align 8
   &#37;errorbox40.sub &#61; getelementptr inbounds &#91;2 x i64&#93;, &#91;2 x i64&#93;* &#37;errorbox
40, i64 0, i64 0
   store i64 &#37;.us-phi52, i64* &#37;errorbox40.sub, align 8
   &#37;267 &#61; getelementptr inbounds &#91;2 x i64&#93;, &#91;2 x i64&#93;* &#37;errorbox40, i64 0, 
i64 1
   store i64 &#37;value_phi253, i64* &#37;267, align 8
   call void @ijl_bounds_error_ints&#40;&#123;&#125;* &#37;2, i64* nonnull &#37;errorbox40.sub, i
64 2&#41;
   unreachable

L5.us.us.us.postloop:                             ; preds &#61; &#37;ib24.us.us.us.
postloop, &#37;main.pseudo.exit
   &#37;value_phi2.us.us.us.postloop &#61; phi i64 &#91; &#37;value_phi2.us.us.us.copy, &#37;ma
in.pseudo.exit &#93;, &#91; &#37;276, &#37;ib24.us.us.us.postloop &#93;
   &#37;268 &#61; add i64 &#37;value_phi2.us.us.us.postloop, -1
   &#37;inbounds.us.us.us.postloop &#61; icmp ult i64 &#37;268, &#37;arraysize
   br i1 &#37;inbounds.us.us.us.postloop, label &#37;ib.us.us.us.postloop, label &#37;o
ob

ib.us.us.us.postloop:                             ; preds &#61; &#37;L5.us.us.us.po
stloop
   &#37;inbounds9.us.us.us.postloop &#61; icmp ult i64 &#37;268, &#37;arraysize8
   br i1 &#37;inbounds9.us.us.us.postloop, label &#37;ib10.us.us.us.postloop, label
 &#37;oob15.split.us

ib10.us.us.us.postloop:                           ; preds &#61; &#37;ib.us.us.us.po
stloop
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;inbounds23.us.us.us.postloop &#61; icmp ult i64 &#37;268, &#37;arraysize22
   br i1 &#37;inbounds23.us.us.us.postloop, label &#37;ib24.us.us.us.postloop, labe
l &#37;oob29.split.us.split.us

ib24.us.us.us.postloop:                           ; preds &#61; &#37;ib10.us.us.us.
postloop
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;269 &#61; add i64 &#37;20, &#37;268
   &#37;270 &#61; getelementptr inbounds double, double* &#37;arrayptr41, i64 &#37;269
   &#37;arrayref.us.us.us.postloop &#61; load double, double* &#37;270, align 8
   &#37;271 &#61; add i64 &#37;21, &#37;268
   &#37;272 &#61; getelementptr inbounds double, double* &#37;arrayptr1943, i64 &#37;271
   &#37;arrayref20.us.us.us.postloop &#61; load double, double* &#37;272, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;273 &#61; fadd double &#37;arrayref.us.us.us.postloop, &#37;arrayref20.us.us.us.pos
tloop
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;274 &#61; add i64 &#37;22, &#37;268
   &#37;275 &#61; getelementptr inbounds double, double* &#37;arrayptr3345, i64 &#37;274
   store double &#37;273, double* &#37;275, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
; │┌ @ promotion.jl:521 within &#96;&#61;&#61;&#96;
    &#37;.not.not.us.us.us.postloop &#61; icmp eq i64 &#37;value_phi2.us.us.us.postloop
, 100
; │└
   &#37;276 &#61; add nuw nsw i64 &#37;value_phi2.us.us.us.postloop, 1
; └
  br i1 &#37;.not.not.us.us.us.postloop, label &#37;L27.split.us.split.us.split.us,
 label &#37;L5.us.us.us.postloop
&#125;
</pre> <p>Notice that this <code>getelementptr inbounds</code> stuff is bounds checking. Julia, like all other high level languages, enables bounds checking by default in order to not allow the user to index outside of an array. Indexing outside of an array is dangerous: it can quite easily segfault your system if you change some memory that is unknown beyond your actual array. Thus Julia throws an error:</p> <pre class='hljl'>
<span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-ni'>101</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span>
</pre> <pre class=julia-error >
ERROR: BoundsError: attempt to access 100×100 Matrix&#123;Float64&#125; at index &#91;101, 1&#93;
</pre> <p>In tight inner loops, we can remove this bounds checking process using the <code>@inbounds</code> macro:</p> <pre class='hljl'>
<span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc_ib!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-nd'>@inbounds</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>j</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>100</span><span class='hljl-t'>
    </span><span class='hljl-n'>val</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>B</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-n'>C</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-n'>j</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>val</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>
  </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
2.424 μs &#40;0 allocations: 0 bytes&#41;
</pre> <pre class='hljl'>
<span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc_ib!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
2.341 μs &#40;0 allocations: 0 bytes&#41;
</pre> <h3>SIMD</h3> <p>Now let&#39;s inspect the LLVM IR again:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>inner_noalloc_ib!</span><span class='hljl-p'>(</span><span class='hljl-n'>C</span><span class='hljl-p'>,</span><span class='hljl-n'>A</span><span class='hljl-p'>,</span><span class='hljl-n'>B</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;inner_noalloc_ib&#33;&#96;
define nonnull &#123;&#125;* @&quot;japi1_inner_noalloc_ib&#33;_3975&quot;&#40;&#123;&#125;* &#37;function, &#123;&#125;** noal
ias nocapture noundef readonly &#37;args, i32 &#37;nargs&#41; #0 &#123;
top:
  &#37;stackargs &#61; alloca &#123;&#125;**, align 8
  store volatile &#123;&#125;** &#37;args, &#123;&#125;*** &#37;stackargs, align 8
  &#37;0 &#61; load &#123;&#125;*, &#123;&#125;** &#37;args, align 8
  &#37;1 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;args, i64 1
  &#37;2 &#61; load &#123;&#125;*, &#123;&#125;** &#37;1, align 8
  &#37;3 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;args, i64 2
  &#37;4 &#61; load &#123;&#125;*, &#123;&#125;** &#37;3, align 8
  &#37;5 &#61; bitcast &#123;&#125;* &#37;2 to &#123;&#125;**
  &#37;arraysize_ptr &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;5, i64 3
  &#37;6 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr to i64*
  &#37;arraysize &#61; load i64, i64* &#37;6, align 8
  &#37;7 &#61; bitcast &#123;&#125;* &#37;2 to double**
  &#37;arrayptr21 &#61; load double*, double** &#37;7, align 8
  &#37;8 &#61; bitcast &#123;&#125;* &#37;4 to &#123;&#125;**
  &#37;arraysize_ptr4 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;8, i64 3
  &#37;9 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr4 to i64*
  &#37;arraysize5 &#61; load i64, i64* &#37;9, align 8
  &#37;10 &#61; bitcast &#123;&#125;* &#37;4 to double**
  &#37;arrayptr822 &#61; load double*, double** &#37;10, align 8
  &#37;11 &#61; bitcast &#123;&#125;* &#37;0 to &#123;&#125;**
  &#37;arraysize_ptr10 &#61; getelementptr inbounds &#123;&#125;*, &#123;&#125;** &#37;11, i64 3
  &#37;12 &#61; bitcast &#123;&#125;** &#37;arraysize_ptr10 to i64*
  &#37;arraysize11 &#61; load i64, i64* &#37;12, align 8
  &#37;13 &#61; bitcast &#123;&#125;* &#37;0 to double**
  &#37;arrayptr1423 &#61; load double*, double** &#37;13, align 8
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
3 within &#96;inner_noalloc_ib&#33;&#96;
  br label &#37;L2

L2:                                               ; preds &#61; &#37;L25, &#37;top
  &#37;indvar &#61; phi i64 &#91; &#37;indvar.next, &#37;L25 &#93;, &#91; 0, &#37;top &#93;
  &#37;value_phi &#61; phi i64 &#91; &#37;671, &#37;L25 &#93;, &#91; 1, &#37;top &#93;
  &#37;14 &#61; add nsw i64 &#37;value_phi, -1
  &#37;15 &#61; mul i64 &#37;arraysize, &#37;14
  &#37;16 &#61; mul i64 &#37;arraysize5, &#37;14
  &#37;17 &#61; mul i64 &#37;arraysize11, &#37;14
  &#37;18 &#61; mul i64 &#37;arraysize5, &#37;indvar
  &#37;19 &#61; add i64 &#37;18, 100
  &#37;scevgep34 &#61; getelementptr double, double* &#37;arrayptr822, i64 &#37;19
  &#37;scevgep32 &#61; getelementptr double, double* &#37;arrayptr822, i64 &#37;18
  &#37;20 &#61; mul i64 &#37;arraysize, &#37;indvar
  &#37;21 &#61; add i64 &#37;20, 100
  &#37;scevgep30 &#61; getelementptr double, double* &#37;arrayptr21, i64 &#37;21
  &#37;scevgep28 &#61; getelementptr double, double* &#37;arrayptr21, i64 &#37;20
  &#37;22 &#61; mul i64 &#37;arraysize11, &#37;indvar
  &#37;23 &#61; add i64 &#37;22, 100
  &#37;scevgep26 &#61; getelementptr double, double* &#37;arrayptr1423, i64 &#37;23
  &#37;scevgep &#61; getelementptr double, double* &#37;arrayptr1423, i64 &#37;22
  &#37;bound0 &#61; icmp ult double* &#37;scevgep, &#37;scevgep30
  &#37;bound1 &#61; icmp ult double* &#37;scevgep28, &#37;scevgep26
  &#37;found.conflict &#61; and i1 &#37;bound0, &#37;bound1
  &#37;bound036 &#61; icmp ult double* &#37;scevgep, &#37;scevgep34
  &#37;bound137 &#61; icmp ult double* &#37;scevgep32, &#37;scevgep26
  &#37;found.conflict38 &#61; and i1 &#37;bound036, &#37;bound137
  &#37;conflict.rdx &#61; or i1 &#37;found.conflict, &#37;found.conflict38
  br i1 &#37;conflict.rdx, label &#37;L5, label &#37;vector.body.preheader

vector.body.preheader:                            ; preds &#61; &#37;L2
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;24 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;15
   &#37;25 &#61; bitcast double* &#37;24 to &lt;4 x double&gt;*
   &#37;wide.load &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;25, align 8
   &#37;26 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;16
   &#37;27 &#61; bitcast double* &#37;26 to &lt;4 x double&gt;*
   &#37;wide.load39 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;27, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;28 &#61; fadd &lt;4 x double&gt; &#37;wide.load, &#37;wide.load39
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;29 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;17
   &#37;30 &#61; bitcast double* &#37;29 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;28, &lt;4 x double&gt;* &#37;30, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;31 &#61; add i64 &#37;15, 4
   &#37;32 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;31
   &#37;33 &#61; bitcast double* &#37;32 to &lt;4 x double&gt;*
   &#37;wide.load.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;33, align 8
   &#37;34 &#61; add i64 &#37;16, 4
   &#37;35 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;34
   &#37;36 &#61; bitcast double* &#37;35 to &lt;4 x double&gt;*
   &#37;wide.load39.1 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;36, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;37 &#61; fadd &lt;4 x double&gt; &#37;wide.load.1, &#37;wide.load39.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;38 &#61; add i64 &#37;17, 4
   &#37;39 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;38
   &#37;40 &#61; bitcast double* &#37;39 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;37, &lt;4 x double&gt;* &#37;40, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;41 &#61; add i64 &#37;15, 8
   &#37;42 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;41
   &#37;43 &#61; bitcast double* &#37;42 to &lt;4 x double&gt;*
   &#37;wide.load.2 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;43, align 8
   &#37;44 &#61; add i64 &#37;16, 8
   &#37;45 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;44
   &#37;46 &#61; bitcast double* &#37;45 to &lt;4 x double&gt;*
   &#37;wide.load39.2 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;46, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;47 &#61; fadd &lt;4 x double&gt; &#37;wide.load.2, &#37;wide.load39.2
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;48 &#61; add i64 &#37;17, 8
   &#37;49 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;48
   &#37;50 &#61; bitcast double* &#37;49 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;47, &lt;4 x double&gt;* &#37;50, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;51 &#61; add i64 &#37;15, 12
   &#37;52 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;51
   &#37;53 &#61; bitcast double* &#37;52 to &lt;4 x double&gt;*
   &#37;wide.load.3 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;53, align 8
   &#37;54 &#61; add i64 &#37;16, 12
   &#37;55 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;54
   &#37;56 &#61; bitcast double* &#37;55 to &lt;4 x double&gt;*
   &#37;wide.load39.3 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;56, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;57 &#61; fadd &lt;4 x double&gt; &#37;wide.load.3, &#37;wide.load39.3
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;58 &#61; add i64 &#37;17, 12
   &#37;59 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;58
   &#37;60 &#61; bitcast double* &#37;59 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;57, &lt;4 x double&gt;* &#37;60, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;61 &#61; add i64 &#37;15, 16
   &#37;62 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;61
   &#37;63 &#61; bitcast double* &#37;62 to &lt;4 x double&gt;*
   &#37;wide.load.4 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;63, align 8
   &#37;64 &#61; add i64 &#37;16, 16
   &#37;65 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;64
   &#37;66 &#61; bitcast double* &#37;65 to &lt;4 x double&gt;*
   &#37;wide.load39.4 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;66, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;67 &#61; fadd &lt;4 x double&gt; &#37;wide.load.4, &#37;wide.load39.4
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;68 &#61; add i64 &#37;17, 16
   &#37;69 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;68
   &#37;70 &#61; bitcast double* &#37;69 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;67, &lt;4 x double&gt;* &#37;70, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;71 &#61; add i64 &#37;15, 20
   &#37;72 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;71
   &#37;73 &#61; bitcast double* &#37;72 to &lt;4 x double&gt;*
   &#37;wide.load.5 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;73, align 8
   &#37;74 &#61; add i64 &#37;16, 20
   &#37;75 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;74
   &#37;76 &#61; bitcast double* &#37;75 to &lt;4 x double&gt;*
   &#37;wide.load39.5 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;76, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;77 &#61; fadd &lt;4 x double&gt; &#37;wide.load.5, &#37;wide.load39.5
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;78 &#61; add i64 &#37;17, 20
   &#37;79 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;78
   &#37;80 &#61; bitcast double* &#37;79 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;77, &lt;4 x double&gt;* &#37;80, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;81 &#61; add i64 &#37;15, 24
   &#37;82 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;81
   &#37;83 &#61; bitcast double* &#37;82 to &lt;4 x double&gt;*
   &#37;wide.load.6 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;83, align 8
   &#37;84 &#61; add i64 &#37;16, 24
   &#37;85 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;84
   &#37;86 &#61; bitcast double* &#37;85 to &lt;4 x double&gt;*
   &#37;wide.load39.6 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;86, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;87 &#61; fadd &lt;4 x double&gt; &#37;wide.load.6, &#37;wide.load39.6
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;88 &#61; add i64 &#37;17, 24
   &#37;89 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;88
   &#37;90 &#61; bitcast double* &#37;89 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;87, &lt;4 x double&gt;* &#37;90, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;91 &#61; add i64 &#37;15, 28
   &#37;92 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;91
   &#37;93 &#61; bitcast double* &#37;92 to &lt;4 x double&gt;*
   &#37;wide.load.7 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;93, align 8
   &#37;94 &#61; add i64 &#37;16, 28
   &#37;95 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;94
   &#37;96 &#61; bitcast double* &#37;95 to &lt;4 x double&gt;*
   &#37;wide.load39.7 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;96, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;97 &#61; fadd &lt;4 x double&gt; &#37;wide.load.7, &#37;wide.load39.7
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;98 &#61; add i64 &#37;17, 28
   &#37;99 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;98
   &#37;100 &#61; bitcast double* &#37;99 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;97, &lt;4 x double&gt;* &#37;100, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;101 &#61; add i64 &#37;15, 32
   &#37;102 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;101
   &#37;103 &#61; bitcast double* &#37;102 to &lt;4 x double&gt;*
   &#37;wide.load.8 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;103, align 8
   &#37;104 &#61; add i64 &#37;16, 32
   &#37;105 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;104
   &#37;106 &#61; bitcast double* &#37;105 to &lt;4 x double&gt;*
   &#37;wide.load39.8 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;106, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;107 &#61; fadd &lt;4 x double&gt; &#37;wide.load.8, &#37;wide.load39.8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;108 &#61; add i64 &#37;17, 32
   &#37;109 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;108
   &#37;110 &#61; bitcast double* &#37;109 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;107, &lt;4 x double&gt;* &#37;110, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;111 &#61; add i64 &#37;15, 36
   &#37;112 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;111
   &#37;113 &#61; bitcast double* &#37;112 to &lt;4 x double&gt;*
   &#37;wide.load.9 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;113, align 8
   &#37;114 &#61; add i64 &#37;16, 36
   &#37;115 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;114
   &#37;116 &#61; bitcast double* &#37;115 to &lt;4 x double&gt;*
   &#37;wide.load39.9 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;116, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;117 &#61; fadd &lt;4 x double&gt; &#37;wide.load.9, &#37;wide.load39.9
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;118 &#61; add i64 &#37;17, 36
   &#37;119 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;118
   &#37;120 &#61; bitcast double* &#37;119 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;117, &lt;4 x double&gt;* &#37;120, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;121 &#61; add i64 &#37;15, 40
   &#37;122 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;121
   &#37;123 &#61; bitcast double* &#37;122 to &lt;4 x double&gt;*
   &#37;wide.load.10 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;123, align 8
   &#37;124 &#61; add i64 &#37;16, 40
   &#37;125 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;124
   &#37;126 &#61; bitcast double* &#37;125 to &lt;4 x double&gt;*
   &#37;wide.load39.10 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;126, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;127 &#61; fadd &lt;4 x double&gt; &#37;wide.load.10, &#37;wide.load39.10
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;128 &#61; add i64 &#37;17, 40
   &#37;129 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;128
   &#37;130 &#61; bitcast double* &#37;129 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;127, &lt;4 x double&gt;* &#37;130, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;131 &#61; add i64 &#37;15, 44
   &#37;132 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;131
   &#37;133 &#61; bitcast double* &#37;132 to &lt;4 x double&gt;*
   &#37;wide.load.11 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;133, align 8
   &#37;134 &#61; add i64 &#37;16, 44
   &#37;135 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;134
   &#37;136 &#61; bitcast double* &#37;135 to &lt;4 x double&gt;*
   &#37;wide.load39.11 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;136, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;137 &#61; fadd &lt;4 x double&gt; &#37;wide.load.11, &#37;wide.load39.11
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;138 &#61; add i64 &#37;17, 44
   &#37;139 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;138
   &#37;140 &#61; bitcast double* &#37;139 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;137, &lt;4 x double&gt;* &#37;140, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;141 &#61; add i64 &#37;15, 48
   &#37;142 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;141
   &#37;143 &#61; bitcast double* &#37;142 to &lt;4 x double&gt;*
   &#37;wide.load.12 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;143, align 8
   &#37;144 &#61; add i64 &#37;16, 48
   &#37;145 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;144
   &#37;146 &#61; bitcast double* &#37;145 to &lt;4 x double&gt;*
   &#37;wide.load39.12 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;146, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;147 &#61; fadd &lt;4 x double&gt; &#37;wide.load.12, &#37;wide.load39.12
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;148 &#61; add i64 &#37;17, 48
   &#37;149 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;148
   &#37;150 &#61; bitcast double* &#37;149 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;147, &lt;4 x double&gt;* &#37;150, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;151 &#61; add i64 &#37;15, 52
   &#37;152 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;151
   &#37;153 &#61; bitcast double* &#37;152 to &lt;4 x double&gt;*
   &#37;wide.load.13 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;153, align 8
   &#37;154 &#61; add i64 &#37;16, 52
   &#37;155 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;154
   &#37;156 &#61; bitcast double* &#37;155 to &lt;4 x double&gt;*
   &#37;wide.load39.13 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;156, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;157 &#61; fadd &lt;4 x double&gt; &#37;wide.load.13, &#37;wide.load39.13
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;158 &#61; add i64 &#37;17, 52
   &#37;159 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;158
   &#37;160 &#61; bitcast double* &#37;159 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;157, &lt;4 x double&gt;* &#37;160, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;161 &#61; add i64 &#37;15, 56
   &#37;162 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;161
   &#37;163 &#61; bitcast double* &#37;162 to &lt;4 x double&gt;*
   &#37;wide.load.14 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;163, align 8
   &#37;164 &#61; add i64 &#37;16, 56
   &#37;165 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;164
   &#37;166 &#61; bitcast double* &#37;165 to &lt;4 x double&gt;*
   &#37;wide.load39.14 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;166, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;167 &#61; fadd &lt;4 x double&gt; &#37;wide.load.14, &#37;wide.load39.14
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;168 &#61; add i64 &#37;17, 56
   &#37;169 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;168
   &#37;170 &#61; bitcast double* &#37;169 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;167, &lt;4 x double&gt;* &#37;170, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;171 &#61; add i64 &#37;15, 60
   &#37;172 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;171
   &#37;173 &#61; bitcast double* &#37;172 to &lt;4 x double&gt;*
   &#37;wide.load.15 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;173, align 8
   &#37;174 &#61; add i64 &#37;16, 60
   &#37;175 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;174
   &#37;176 &#61; bitcast double* &#37;175 to &lt;4 x double&gt;*
   &#37;wide.load39.15 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;176, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;177 &#61; fadd &lt;4 x double&gt; &#37;wide.load.15, &#37;wide.load39.15
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;178 &#61; add i64 &#37;17, 60
   &#37;179 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;178
   &#37;180 &#61; bitcast double* &#37;179 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;177, &lt;4 x double&gt;* &#37;180, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;181 &#61; add i64 &#37;15, 64
   &#37;182 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;181
   &#37;183 &#61; bitcast double* &#37;182 to &lt;4 x double&gt;*
   &#37;wide.load.16 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;183, align 8
   &#37;184 &#61; add i64 &#37;16, 64
   &#37;185 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;184
   &#37;186 &#61; bitcast double* &#37;185 to &lt;4 x double&gt;*
   &#37;wide.load39.16 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;186, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;187 &#61; fadd &lt;4 x double&gt; &#37;wide.load.16, &#37;wide.load39.16
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;188 &#61; add i64 &#37;17, 64
   &#37;189 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;188
   &#37;190 &#61; bitcast double* &#37;189 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;187, &lt;4 x double&gt;* &#37;190, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;191 &#61; add i64 &#37;15, 68
   &#37;192 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;191
   &#37;193 &#61; bitcast double* &#37;192 to &lt;4 x double&gt;*
   &#37;wide.load.17 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;193, align 8
   &#37;194 &#61; add i64 &#37;16, 68
   &#37;195 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;194
   &#37;196 &#61; bitcast double* &#37;195 to &lt;4 x double&gt;*
   &#37;wide.load39.17 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;196, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;197 &#61; fadd &lt;4 x double&gt; &#37;wide.load.17, &#37;wide.load39.17
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;198 &#61; add i64 &#37;17, 68
   &#37;199 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;198
   &#37;200 &#61; bitcast double* &#37;199 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;197, &lt;4 x double&gt;* &#37;200, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;201 &#61; add i64 &#37;15, 72
   &#37;202 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;201
   &#37;203 &#61; bitcast double* &#37;202 to &lt;4 x double&gt;*
   &#37;wide.load.18 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;203, align 8
   &#37;204 &#61; add i64 &#37;16, 72
   &#37;205 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;204
   &#37;206 &#61; bitcast double* &#37;205 to &lt;4 x double&gt;*
   &#37;wide.load39.18 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;206, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;207 &#61; fadd &lt;4 x double&gt; &#37;wide.load.18, &#37;wide.load39.18
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;208 &#61; add i64 &#37;17, 72
   &#37;209 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;208
   &#37;210 &#61; bitcast double* &#37;209 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;207, &lt;4 x double&gt;* &#37;210, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;211 &#61; add i64 &#37;15, 76
   &#37;212 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;211
   &#37;213 &#61; bitcast double* &#37;212 to &lt;4 x double&gt;*
   &#37;wide.load.19 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;213, align 8
   &#37;214 &#61; add i64 &#37;16, 76
   &#37;215 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;214
   &#37;216 &#61; bitcast double* &#37;215 to &lt;4 x double&gt;*
   &#37;wide.load39.19 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;216, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;217 &#61; fadd &lt;4 x double&gt; &#37;wide.load.19, &#37;wide.load39.19
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;218 &#61; add i64 &#37;17, 76
   &#37;219 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;218
   &#37;220 &#61; bitcast double* &#37;219 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;217, &lt;4 x double&gt;* &#37;220, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;221 &#61; add i64 &#37;15, 80
   &#37;222 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;221
   &#37;223 &#61; bitcast double* &#37;222 to &lt;4 x double&gt;*
   &#37;wide.load.20 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;223, align 8
   &#37;224 &#61; add i64 &#37;16, 80
   &#37;225 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;224
   &#37;226 &#61; bitcast double* &#37;225 to &lt;4 x double&gt;*
   &#37;wide.load39.20 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;226, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;227 &#61; fadd &lt;4 x double&gt; &#37;wide.load.20, &#37;wide.load39.20
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;228 &#61; add i64 &#37;17, 80
   &#37;229 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;228
   &#37;230 &#61; bitcast double* &#37;229 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;227, &lt;4 x double&gt;* &#37;230, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;231 &#61; add i64 &#37;15, 84
   &#37;232 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;231
   &#37;233 &#61; bitcast double* &#37;232 to &lt;4 x double&gt;*
   &#37;wide.load.21 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;233, align 8
   &#37;234 &#61; add i64 &#37;16, 84
   &#37;235 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;234
   &#37;236 &#61; bitcast double* &#37;235 to &lt;4 x double&gt;*
   &#37;wide.load39.21 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;236, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;237 &#61; fadd &lt;4 x double&gt; &#37;wide.load.21, &#37;wide.load39.21
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;238 &#61; add i64 &#37;17, 84
   &#37;239 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;238
   &#37;240 &#61; bitcast double* &#37;239 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;237, &lt;4 x double&gt;* &#37;240, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;241 &#61; add i64 &#37;15, 88
   &#37;242 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;241
   &#37;243 &#61; bitcast double* &#37;242 to &lt;4 x double&gt;*
   &#37;wide.load.22 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;243, align 8
   &#37;244 &#61; add i64 &#37;16, 88
   &#37;245 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;244
   &#37;246 &#61; bitcast double* &#37;245 to &lt;4 x double&gt;*
   &#37;wide.load39.22 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;246, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;247 &#61; fadd &lt;4 x double&gt; &#37;wide.load.22, &#37;wide.load39.22
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;248 &#61; add i64 &#37;17, 88
   &#37;249 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;248
   &#37;250 &#61; bitcast double* &#37;249 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;247, &lt;4 x double&gt;* &#37;250, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;251 &#61; add i64 &#37;15, 92
   &#37;252 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;251
   &#37;253 &#61; bitcast double* &#37;252 to &lt;4 x double&gt;*
   &#37;wide.load.23 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;253, align 8
   &#37;254 &#61; add i64 &#37;16, 92
   &#37;255 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;254
   &#37;256 &#61; bitcast double* &#37;255 to &lt;4 x double&gt;*
   &#37;wide.load39.23 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;256, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;257 &#61; fadd &lt;4 x double&gt; &#37;wide.load.23, &#37;wide.load39.23
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;258 &#61; add i64 &#37;17, 92
   &#37;259 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;258
   &#37;260 &#61; bitcast double* &#37;259 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;257, &lt;4 x double&gt;* &#37;260, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;261 &#61; add i64 &#37;15, 96
   &#37;262 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;261
   &#37;263 &#61; bitcast double* &#37;262 to &lt;4 x double&gt;*
   &#37;wide.load.24 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;263, align 8
   &#37;264 &#61; add i64 &#37;16, 96
   &#37;265 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;264
   &#37;266 &#61; bitcast double* &#37;265 to &lt;4 x double&gt;*
   &#37;wide.load39.24 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt;* &#37;266, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;267 &#61; fadd &lt;4 x double&gt; &#37;wide.load.24, &#37;wide.load39.24
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;268 &#61; add i64 &#37;17, 96
   &#37;269 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;268
   &#37;270 &#61; bitcast double* &#37;269 to &lt;4 x double&gt;*
   store &lt;4 x double&gt; &#37;267, &lt;4 x double&gt;* &#37;270, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
; │┌ @ promotion.jl:521 within &#96;&#61;&#61;&#96;
    br label &#37;L25

L5:                                               ; preds &#61; &#37;L5, &#37;L2
    &#37;value_phi2 &#61; phi i64 &#91; &#37;670, &#37;L5 &#93;, &#91; 1, &#37;L2 &#93;
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;271 &#61; add nsw i64 &#37;value_phi2, -1
   &#37;272 &#61; add i64 &#37;271, &#37;15
   &#37;273 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;272
   &#37;arrayref &#61; load double, double* &#37;273, align 8
   &#37;274 &#61; add i64 &#37;271, &#37;16
   &#37;275 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;274
   &#37;arrayref9 &#61; load double, double* &#37;275, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;276 &#61; fadd double &#37;arrayref, &#37;arrayref9
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;277 &#61; add i64 &#37;271, &#37;17
   &#37;278 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;277
   store double &#37;276, double* &#37;278, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;279 &#61; add nuw nsw i64 &#37;value_phi2, 1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;280 &#61; add i64 &#37;value_phi2, &#37;15
   &#37;281 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;280
   &#37;arrayref.1 &#61; load double, double* &#37;281, align 8
   &#37;282 &#61; add i64 &#37;value_phi2, &#37;16
   &#37;283 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;282
   &#37;arrayref9.1 &#61; load double, double* &#37;283, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;284 &#61; fadd double &#37;arrayref.1, &#37;arrayref9.1
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;285 &#61; add i64 &#37;value_phi2, &#37;17
   &#37;286 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;285
   store double &#37;284, double* &#37;286, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;287 &#61; add nuw nsw i64 &#37;value_phi2, 2
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;288 &#61; add i64 &#37;279, &#37;15
   &#37;289 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;288
   &#37;arrayref.2 &#61; load double, double* &#37;289, align 8
   &#37;290 &#61; add i64 &#37;279, &#37;16
   &#37;291 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;290
   &#37;arrayref9.2 &#61; load double, double* &#37;291, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;292 &#61; fadd double &#37;arrayref.2, &#37;arrayref9.2
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;293 &#61; add i64 &#37;279, &#37;17
   &#37;294 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;293
   store double &#37;292, double* &#37;294, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;295 &#61; add nuw nsw i64 &#37;value_phi2, 3
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;296 &#61; add i64 &#37;287, &#37;15
   &#37;297 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;296
   &#37;arrayref.3 &#61; load double, double* &#37;297, align 8
   &#37;298 &#61; add i64 &#37;287, &#37;16
   &#37;299 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;298
   &#37;arrayref9.3 &#61; load double, double* &#37;299, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;300 &#61; fadd double &#37;arrayref.3, &#37;arrayref9.3
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;301 &#61; add i64 &#37;287, &#37;17
   &#37;302 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;301
   store double &#37;300, double* &#37;302, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;303 &#61; add nuw nsw i64 &#37;value_phi2, 4
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;304 &#61; add i64 &#37;295, &#37;15
   &#37;305 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;304
   &#37;arrayref.4 &#61; load double, double* &#37;305, align 8
   &#37;306 &#61; add i64 &#37;295, &#37;16
   &#37;307 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;306
   &#37;arrayref9.4 &#61; load double, double* &#37;307, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;308 &#61; fadd double &#37;arrayref.4, &#37;arrayref9.4
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;309 &#61; add i64 &#37;295, &#37;17
   &#37;310 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;309
   store double &#37;308, double* &#37;310, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;311 &#61; add nuw nsw i64 &#37;value_phi2, 5
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;312 &#61; add i64 &#37;303, &#37;15
   &#37;313 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;312
   &#37;arrayref.5 &#61; load double, double* &#37;313, align 8
   &#37;314 &#61; add i64 &#37;303, &#37;16
   &#37;315 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;314
   &#37;arrayref9.5 &#61; load double, double* &#37;315, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;316 &#61; fadd double &#37;arrayref.5, &#37;arrayref9.5
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;317 &#61; add i64 &#37;303, &#37;17
   &#37;318 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;317
   store double &#37;316, double* &#37;318, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;319 &#61; add nuw nsw i64 &#37;value_phi2, 6
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;320 &#61; add i64 &#37;311, &#37;15
   &#37;321 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;320
   &#37;arrayref.6 &#61; load double, double* &#37;321, align 8
   &#37;322 &#61; add i64 &#37;311, &#37;16
   &#37;323 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;322
   &#37;arrayref9.6 &#61; load double, double* &#37;323, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;324 &#61; fadd double &#37;arrayref.6, &#37;arrayref9.6
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;325 &#61; add i64 &#37;311, &#37;17
   &#37;326 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;325
   store double &#37;324, double* &#37;326, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;327 &#61; add nuw nsw i64 &#37;value_phi2, 7
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;328 &#61; add i64 &#37;319, &#37;15
   &#37;329 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;328
   &#37;arrayref.7 &#61; load double, double* &#37;329, align 8
   &#37;330 &#61; add i64 &#37;319, &#37;16
   &#37;331 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;330
   &#37;arrayref9.7 &#61; load double, double* &#37;331, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;332 &#61; fadd double &#37;arrayref.7, &#37;arrayref9.7
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;333 &#61; add i64 &#37;319, &#37;17
   &#37;334 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;333
   store double &#37;332, double* &#37;334, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;335 &#61; add nuw nsw i64 &#37;value_phi2, 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;336 &#61; add i64 &#37;327, &#37;15
   &#37;337 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;336
   &#37;arrayref.8 &#61; load double, double* &#37;337, align 8
   &#37;338 &#61; add i64 &#37;327, &#37;16
   &#37;339 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;338
   &#37;arrayref9.8 &#61; load double, double* &#37;339, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;340 &#61; fadd double &#37;arrayref.8, &#37;arrayref9.8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;341 &#61; add i64 &#37;327, &#37;17
   &#37;342 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;341
   store double &#37;340, double* &#37;342, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;343 &#61; add nuw nsw i64 &#37;value_phi2, 9
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;344 &#61; add i64 &#37;335, &#37;15
   &#37;345 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;344
   &#37;arrayref.9 &#61; load double, double* &#37;345, align 8
   &#37;346 &#61; add i64 &#37;335, &#37;16
   &#37;347 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;346
   &#37;arrayref9.9 &#61; load double, double* &#37;347, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;348 &#61; fadd double &#37;arrayref.9, &#37;arrayref9.9
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;349 &#61; add i64 &#37;335, &#37;17
   &#37;350 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;349
   store double &#37;348, double* &#37;350, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;351 &#61; add nuw nsw i64 &#37;value_phi2, 10
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;352 &#61; add i64 &#37;343, &#37;15
   &#37;353 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;352
   &#37;arrayref.10 &#61; load double, double* &#37;353, align 8
   &#37;354 &#61; add i64 &#37;343, &#37;16
   &#37;355 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;354
   &#37;arrayref9.10 &#61; load double, double* &#37;355, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;356 &#61; fadd double &#37;arrayref.10, &#37;arrayref9.10
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;357 &#61; add i64 &#37;343, &#37;17
   &#37;358 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;357
   store double &#37;356, double* &#37;358, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;359 &#61; add nuw nsw i64 &#37;value_phi2, 11
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;360 &#61; add i64 &#37;351, &#37;15
   &#37;361 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;360
   &#37;arrayref.11 &#61; load double, double* &#37;361, align 8
   &#37;362 &#61; add i64 &#37;351, &#37;16
   &#37;363 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;362
   &#37;arrayref9.11 &#61; load double, double* &#37;363, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;364 &#61; fadd double &#37;arrayref.11, &#37;arrayref9.11
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;365 &#61; add i64 &#37;351, &#37;17
   &#37;366 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;365
   store double &#37;364, double* &#37;366, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;367 &#61; add nuw nsw i64 &#37;value_phi2, 12
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;368 &#61; add i64 &#37;359, &#37;15
   &#37;369 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;368
   &#37;arrayref.12 &#61; load double, double* &#37;369, align 8
   &#37;370 &#61; add i64 &#37;359, &#37;16
   &#37;371 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;370
   &#37;arrayref9.12 &#61; load double, double* &#37;371, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;372 &#61; fadd double &#37;arrayref.12, &#37;arrayref9.12
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;373 &#61; add i64 &#37;359, &#37;17
   &#37;374 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;373
   store double &#37;372, double* &#37;374, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;375 &#61; add nuw nsw i64 &#37;value_phi2, 13
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;376 &#61; add i64 &#37;367, &#37;15
   &#37;377 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;376
   &#37;arrayref.13 &#61; load double, double* &#37;377, align 8
   &#37;378 &#61; add i64 &#37;367, &#37;16
   &#37;379 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;378
   &#37;arrayref9.13 &#61; load double, double* &#37;379, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;380 &#61; fadd double &#37;arrayref.13, &#37;arrayref9.13
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;381 &#61; add i64 &#37;367, &#37;17
   &#37;382 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;381
   store double &#37;380, double* &#37;382, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;383 &#61; add nuw nsw i64 &#37;value_phi2, 14
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;384 &#61; add i64 &#37;375, &#37;15
   &#37;385 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;384
   &#37;arrayref.14 &#61; load double, double* &#37;385, align 8
   &#37;386 &#61; add i64 &#37;375, &#37;16
   &#37;387 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;386
   &#37;arrayref9.14 &#61; load double, double* &#37;387, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;388 &#61; fadd double &#37;arrayref.14, &#37;arrayref9.14
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;389 &#61; add i64 &#37;375, &#37;17
   &#37;390 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;389
   store double &#37;388, double* &#37;390, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;391 &#61; add nuw nsw i64 &#37;value_phi2, 15
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;392 &#61; add i64 &#37;383, &#37;15
   &#37;393 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;392
   &#37;arrayref.15 &#61; load double, double* &#37;393, align 8
   &#37;394 &#61; add i64 &#37;383, &#37;16
   &#37;395 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;394
   &#37;arrayref9.15 &#61; load double, double* &#37;395, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;396 &#61; fadd double &#37;arrayref.15, &#37;arrayref9.15
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;397 &#61; add i64 &#37;383, &#37;17
   &#37;398 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;397
   store double &#37;396, double* &#37;398, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;399 &#61; add nuw nsw i64 &#37;value_phi2, 16
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;400 &#61; add i64 &#37;391, &#37;15
   &#37;401 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;400
   &#37;arrayref.16 &#61; load double, double* &#37;401, align 8
   &#37;402 &#61; add i64 &#37;391, &#37;16
   &#37;403 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;402
   &#37;arrayref9.16 &#61; load double, double* &#37;403, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;404 &#61; fadd double &#37;arrayref.16, &#37;arrayref9.16
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;405 &#61; add i64 &#37;391, &#37;17
   &#37;406 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;405
   store double &#37;404, double* &#37;406, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;407 &#61; add nuw nsw i64 &#37;value_phi2, 17
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;408 &#61; add i64 &#37;399, &#37;15
   &#37;409 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;408
   &#37;arrayref.17 &#61; load double, double* &#37;409, align 8
   &#37;410 &#61; add i64 &#37;399, &#37;16
   &#37;411 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;410
   &#37;arrayref9.17 &#61; load double, double* &#37;411, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;412 &#61; fadd double &#37;arrayref.17, &#37;arrayref9.17
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;413 &#61; add i64 &#37;399, &#37;17
   &#37;414 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;413
   store double &#37;412, double* &#37;414, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;415 &#61; add nuw nsw i64 &#37;value_phi2, 18
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;416 &#61; add i64 &#37;407, &#37;15
   &#37;417 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;416
   &#37;arrayref.18 &#61; load double, double* &#37;417, align 8
   &#37;418 &#61; add i64 &#37;407, &#37;16
   &#37;419 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;418
   &#37;arrayref9.18 &#61; load double, double* &#37;419, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;420 &#61; fadd double &#37;arrayref.18, &#37;arrayref9.18
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;421 &#61; add i64 &#37;407, &#37;17
   &#37;422 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;421
   store double &#37;420, double* &#37;422, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;423 &#61; add nuw nsw i64 &#37;value_phi2, 19
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;424 &#61; add i64 &#37;415, &#37;15
   &#37;425 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;424
   &#37;arrayref.19 &#61; load double, double* &#37;425, align 8
   &#37;426 &#61; add i64 &#37;415, &#37;16
   &#37;427 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;426
   &#37;arrayref9.19 &#61; load double, double* &#37;427, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;428 &#61; fadd double &#37;arrayref.19, &#37;arrayref9.19
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;429 &#61; add i64 &#37;415, &#37;17
   &#37;430 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;429
   store double &#37;428, double* &#37;430, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;431 &#61; add nuw nsw i64 &#37;value_phi2, 20
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;432 &#61; add i64 &#37;423, &#37;15
   &#37;433 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;432
   &#37;arrayref.20 &#61; load double, double* &#37;433, align 8
   &#37;434 &#61; add i64 &#37;423, &#37;16
   &#37;435 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;434
   &#37;arrayref9.20 &#61; load double, double* &#37;435, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;436 &#61; fadd double &#37;arrayref.20, &#37;arrayref9.20
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;437 &#61; add i64 &#37;423, &#37;17
   &#37;438 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;437
   store double &#37;436, double* &#37;438, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;439 &#61; add nuw nsw i64 &#37;value_phi2, 21
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;440 &#61; add i64 &#37;431, &#37;15
   &#37;441 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;440
   &#37;arrayref.21 &#61; load double, double* &#37;441, align 8
   &#37;442 &#61; add i64 &#37;431, &#37;16
   &#37;443 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;442
   &#37;arrayref9.21 &#61; load double, double* &#37;443, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;444 &#61; fadd double &#37;arrayref.21, &#37;arrayref9.21
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;445 &#61; add i64 &#37;431, &#37;17
   &#37;446 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;445
   store double &#37;444, double* &#37;446, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;447 &#61; add nuw nsw i64 &#37;value_phi2, 22
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;448 &#61; add i64 &#37;439, &#37;15
   &#37;449 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;448
   &#37;arrayref.22 &#61; load double, double* &#37;449, align 8
   &#37;450 &#61; add i64 &#37;439, &#37;16
   &#37;451 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;450
   &#37;arrayref9.22 &#61; load double, double* &#37;451, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;452 &#61; fadd double &#37;arrayref.22, &#37;arrayref9.22
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;453 &#61; add i64 &#37;439, &#37;17
   &#37;454 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;453
   store double &#37;452, double* &#37;454, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;455 &#61; add nuw nsw i64 &#37;value_phi2, 23
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;456 &#61; add i64 &#37;447, &#37;15
   &#37;457 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;456
   &#37;arrayref.23 &#61; load double, double* &#37;457, align 8
   &#37;458 &#61; add i64 &#37;447, &#37;16
   &#37;459 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;458
   &#37;arrayref9.23 &#61; load double, double* &#37;459, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;460 &#61; fadd double &#37;arrayref.23, &#37;arrayref9.23
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;461 &#61; add i64 &#37;447, &#37;17
   &#37;462 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;461
   store double &#37;460, double* &#37;462, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;463 &#61; add nuw nsw i64 &#37;value_phi2, 24
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;464 &#61; add i64 &#37;455, &#37;15
   &#37;465 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;464
   &#37;arrayref.24 &#61; load double, double* &#37;465, align 8
   &#37;466 &#61; add i64 &#37;455, &#37;16
   &#37;467 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;466
   &#37;arrayref9.24 &#61; load double, double* &#37;467, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;468 &#61; fadd double &#37;arrayref.24, &#37;arrayref9.24
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;469 &#61; add i64 &#37;455, &#37;17
   &#37;470 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;469
   store double &#37;468, double* &#37;470, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;471 &#61; add nuw nsw i64 &#37;value_phi2, 25
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;472 &#61; add i64 &#37;463, &#37;15
   &#37;473 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;472
   &#37;arrayref.25 &#61; load double, double* &#37;473, align 8
   &#37;474 &#61; add i64 &#37;463, &#37;16
   &#37;475 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;474
   &#37;arrayref9.25 &#61; load double, double* &#37;475, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;476 &#61; fadd double &#37;arrayref.25, &#37;arrayref9.25
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;477 &#61; add i64 &#37;463, &#37;17
   &#37;478 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;477
   store double &#37;476, double* &#37;478, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;479 &#61; add nuw nsw i64 &#37;value_phi2, 26
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;480 &#61; add i64 &#37;471, &#37;15
   &#37;481 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;480
   &#37;arrayref.26 &#61; load double, double* &#37;481, align 8
   &#37;482 &#61; add i64 &#37;471, &#37;16
   &#37;483 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;482
   &#37;arrayref9.26 &#61; load double, double* &#37;483, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;484 &#61; fadd double &#37;arrayref.26, &#37;arrayref9.26
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;485 &#61; add i64 &#37;471, &#37;17
   &#37;486 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;485
   store double &#37;484, double* &#37;486, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;487 &#61; add nuw nsw i64 &#37;value_phi2, 27
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;488 &#61; add i64 &#37;479, &#37;15
   &#37;489 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;488
   &#37;arrayref.27 &#61; load double, double* &#37;489, align 8
   &#37;490 &#61; add i64 &#37;479, &#37;16
   &#37;491 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;490
   &#37;arrayref9.27 &#61; load double, double* &#37;491, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;492 &#61; fadd double &#37;arrayref.27, &#37;arrayref9.27
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;493 &#61; add i64 &#37;479, &#37;17
   &#37;494 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;493
   store double &#37;492, double* &#37;494, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;495 &#61; add nuw nsw i64 &#37;value_phi2, 28
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;496 &#61; add i64 &#37;487, &#37;15
   &#37;497 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;496
   &#37;arrayref.28 &#61; load double, double* &#37;497, align 8
   &#37;498 &#61; add i64 &#37;487, &#37;16
   &#37;499 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;498
   &#37;arrayref9.28 &#61; load double, double* &#37;499, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;500 &#61; fadd double &#37;arrayref.28, &#37;arrayref9.28
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;501 &#61; add i64 &#37;487, &#37;17
   &#37;502 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;501
   store double &#37;500, double* &#37;502, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;503 &#61; add nuw nsw i64 &#37;value_phi2, 29
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;504 &#61; add i64 &#37;495, &#37;15
   &#37;505 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;504
   &#37;arrayref.29 &#61; load double, double* &#37;505, align 8
   &#37;506 &#61; add i64 &#37;495, &#37;16
   &#37;507 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;506
   &#37;arrayref9.29 &#61; load double, double* &#37;507, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;508 &#61; fadd double &#37;arrayref.29, &#37;arrayref9.29
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;509 &#61; add i64 &#37;495, &#37;17
   &#37;510 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;509
   store double &#37;508, double* &#37;510, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;511 &#61; add nuw nsw i64 &#37;value_phi2, 30
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;512 &#61; add i64 &#37;503, &#37;15
   &#37;513 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;512
   &#37;arrayref.30 &#61; load double, double* &#37;513, align 8
   &#37;514 &#61; add i64 &#37;503, &#37;16
   &#37;515 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;514
   &#37;arrayref9.30 &#61; load double, double* &#37;515, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;516 &#61; fadd double &#37;arrayref.30, &#37;arrayref9.30
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;517 &#61; add i64 &#37;503, &#37;17
   &#37;518 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;517
   store double &#37;516, double* &#37;518, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;519 &#61; add nuw nsw i64 &#37;value_phi2, 31
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;520 &#61; add i64 &#37;511, &#37;15
   &#37;521 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;520
   &#37;arrayref.31 &#61; load double, double* &#37;521, align 8
   &#37;522 &#61; add i64 &#37;511, &#37;16
   &#37;523 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;522
   &#37;arrayref9.31 &#61; load double, double* &#37;523, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;524 &#61; fadd double &#37;arrayref.31, &#37;arrayref9.31
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;525 &#61; add i64 &#37;511, &#37;17
   &#37;526 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;525
   store double &#37;524, double* &#37;526, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;527 &#61; add nuw nsw i64 &#37;value_phi2, 32
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;528 &#61; add i64 &#37;519, &#37;15
   &#37;529 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;528
   &#37;arrayref.32 &#61; load double, double* &#37;529, align 8
   &#37;530 &#61; add i64 &#37;519, &#37;16
   &#37;531 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;530
   &#37;arrayref9.32 &#61; load double, double* &#37;531, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;532 &#61; fadd double &#37;arrayref.32, &#37;arrayref9.32
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;533 &#61; add i64 &#37;519, &#37;17
   &#37;534 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;533
   store double &#37;532, double* &#37;534, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;535 &#61; add nuw nsw i64 &#37;value_phi2, 33
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;536 &#61; add i64 &#37;527, &#37;15
   &#37;537 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;536
   &#37;arrayref.33 &#61; load double, double* &#37;537, align 8
   &#37;538 &#61; add i64 &#37;527, &#37;16
   &#37;539 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;538
   &#37;arrayref9.33 &#61; load double, double* &#37;539, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;540 &#61; fadd double &#37;arrayref.33, &#37;arrayref9.33
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;541 &#61; add i64 &#37;527, &#37;17
   &#37;542 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;541
   store double &#37;540, double* &#37;542, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;543 &#61; add nuw nsw i64 &#37;value_phi2, 34
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;544 &#61; add i64 &#37;535, &#37;15
   &#37;545 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;544
   &#37;arrayref.34 &#61; load double, double* &#37;545, align 8
   &#37;546 &#61; add i64 &#37;535, &#37;16
   &#37;547 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;546
   &#37;arrayref9.34 &#61; load double, double* &#37;547, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;548 &#61; fadd double &#37;arrayref.34, &#37;arrayref9.34
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;549 &#61; add i64 &#37;535, &#37;17
   &#37;550 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;549
   store double &#37;548, double* &#37;550, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;551 &#61; add nuw nsw i64 &#37;value_phi2, 35
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;552 &#61; add i64 &#37;543, &#37;15
   &#37;553 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;552
   &#37;arrayref.35 &#61; load double, double* &#37;553, align 8
   &#37;554 &#61; add i64 &#37;543, &#37;16
   &#37;555 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;554
   &#37;arrayref9.35 &#61; load double, double* &#37;555, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;556 &#61; fadd double &#37;arrayref.35, &#37;arrayref9.35
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;557 &#61; add i64 &#37;543, &#37;17
   &#37;558 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;557
   store double &#37;556, double* &#37;558, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;559 &#61; add nuw nsw i64 &#37;value_phi2, 36
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;560 &#61; add i64 &#37;551, &#37;15
   &#37;561 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;560
   &#37;arrayref.36 &#61; load double, double* &#37;561, align 8
   &#37;562 &#61; add i64 &#37;551, &#37;16
   &#37;563 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;562
   &#37;arrayref9.36 &#61; load double, double* &#37;563, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;564 &#61; fadd double &#37;arrayref.36, &#37;arrayref9.36
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;565 &#61; add i64 &#37;551, &#37;17
   &#37;566 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;565
   store double &#37;564, double* &#37;566, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;567 &#61; add nuw nsw i64 &#37;value_phi2, 37
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;568 &#61; add i64 &#37;559, &#37;15
   &#37;569 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;568
   &#37;arrayref.37 &#61; load double, double* &#37;569, align 8
   &#37;570 &#61; add i64 &#37;559, &#37;16
   &#37;571 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;570
   &#37;arrayref9.37 &#61; load double, double* &#37;571, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;572 &#61; fadd double &#37;arrayref.37, &#37;arrayref9.37
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;573 &#61; add i64 &#37;559, &#37;17
   &#37;574 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;573
   store double &#37;572, double* &#37;574, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;575 &#61; add nuw nsw i64 &#37;value_phi2, 38
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;576 &#61; add i64 &#37;567, &#37;15
   &#37;577 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;576
   &#37;arrayref.38 &#61; load double, double* &#37;577, align 8
   &#37;578 &#61; add i64 &#37;567, &#37;16
   &#37;579 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;578
   &#37;arrayref9.38 &#61; load double, double* &#37;579, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;580 &#61; fadd double &#37;arrayref.38, &#37;arrayref9.38
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;581 &#61; add i64 &#37;567, &#37;17
   &#37;582 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;581
   store double &#37;580, double* &#37;582, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;583 &#61; add nuw nsw i64 &#37;value_phi2, 39
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;584 &#61; add i64 &#37;575, &#37;15
   &#37;585 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;584
   &#37;arrayref.39 &#61; load double, double* &#37;585, align 8
   &#37;586 &#61; add i64 &#37;575, &#37;16
   &#37;587 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;586
   &#37;arrayref9.39 &#61; load double, double* &#37;587, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;588 &#61; fadd double &#37;arrayref.39, &#37;arrayref9.39
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;589 &#61; add i64 &#37;575, &#37;17
   &#37;590 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;589
   store double &#37;588, double* &#37;590, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;591 &#61; add nuw nsw i64 &#37;value_phi2, 40
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;592 &#61; add i64 &#37;583, &#37;15
   &#37;593 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;592
   &#37;arrayref.40 &#61; load double, double* &#37;593, align 8
   &#37;594 &#61; add i64 &#37;583, &#37;16
   &#37;595 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;594
   &#37;arrayref9.40 &#61; load double, double* &#37;595, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;596 &#61; fadd double &#37;arrayref.40, &#37;arrayref9.40
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;597 &#61; add i64 &#37;583, &#37;17
   &#37;598 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;597
   store double &#37;596, double* &#37;598, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;599 &#61; add nuw nsw i64 &#37;value_phi2, 41
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;600 &#61; add i64 &#37;591, &#37;15
   &#37;601 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;600
   &#37;arrayref.41 &#61; load double, double* &#37;601, align 8
   &#37;602 &#61; add i64 &#37;591, &#37;16
   &#37;603 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;602
   &#37;arrayref9.41 &#61; load double, double* &#37;603, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;604 &#61; fadd double &#37;arrayref.41, &#37;arrayref9.41
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;605 &#61; add i64 &#37;591, &#37;17
   &#37;606 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;605
   store double &#37;604, double* &#37;606, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;607 &#61; add nuw nsw i64 &#37;value_phi2, 42
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;608 &#61; add i64 &#37;599, &#37;15
   &#37;609 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;608
   &#37;arrayref.42 &#61; load double, double* &#37;609, align 8
   &#37;610 &#61; add i64 &#37;599, &#37;16
   &#37;611 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;610
   &#37;arrayref9.42 &#61; load double, double* &#37;611, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;612 &#61; fadd double &#37;arrayref.42, &#37;arrayref9.42
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;613 &#61; add i64 &#37;599, &#37;17
   &#37;614 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;613
   store double &#37;612, double* &#37;614, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;615 &#61; add nuw nsw i64 &#37;value_phi2, 43
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;616 &#61; add i64 &#37;607, &#37;15
   &#37;617 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;616
   &#37;arrayref.43 &#61; load double, double* &#37;617, align 8
   &#37;618 &#61; add i64 &#37;607, &#37;16
   &#37;619 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;618
   &#37;arrayref9.43 &#61; load double, double* &#37;619, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;620 &#61; fadd double &#37;arrayref.43, &#37;arrayref9.43
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;621 &#61; add i64 &#37;607, &#37;17
   &#37;622 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;621
   store double &#37;620, double* &#37;622, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;623 &#61; add nuw nsw i64 &#37;value_phi2, 44
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;624 &#61; add i64 &#37;615, &#37;15
   &#37;625 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;624
   &#37;arrayref.44 &#61; load double, double* &#37;625, align 8
   &#37;626 &#61; add i64 &#37;615, &#37;16
   &#37;627 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;626
   &#37;arrayref9.44 &#61; load double, double* &#37;627, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;628 &#61; fadd double &#37;arrayref.44, &#37;arrayref9.44
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;629 &#61; add i64 &#37;615, &#37;17
   &#37;630 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;629
   store double &#37;628, double* &#37;630, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;631 &#61; add nuw nsw i64 &#37;value_phi2, 45
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;632 &#61; add i64 &#37;623, &#37;15
   &#37;633 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;632
   &#37;arrayref.45 &#61; load double, double* &#37;633, align 8
   &#37;634 &#61; add i64 &#37;623, &#37;16
   &#37;635 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;634
   &#37;arrayref9.45 &#61; load double, double* &#37;635, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;636 &#61; fadd double &#37;arrayref.45, &#37;arrayref9.45
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;637 &#61; add i64 &#37;623, &#37;17
   &#37;638 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;637
   store double &#37;636, double* &#37;638, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;639 &#61; add nuw nsw i64 &#37;value_phi2, 46
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;640 &#61; add i64 &#37;631, &#37;15
   &#37;641 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;640
   &#37;arrayref.46 &#61; load double, double* &#37;641, align 8
   &#37;642 &#61; add i64 &#37;631, &#37;16
   &#37;643 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;642
   &#37;arrayref9.46 &#61; load double, double* &#37;643, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;644 &#61; fadd double &#37;arrayref.46, &#37;arrayref9.46
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;645 &#61; add i64 &#37;631, &#37;17
   &#37;646 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;645
   store double &#37;644, double* &#37;646, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;647 &#61; add nuw nsw i64 &#37;value_phi2, 47
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;648 &#61; add i64 &#37;639, &#37;15
   &#37;649 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;648
   &#37;arrayref.47 &#61; load double, double* &#37;649, align 8
   &#37;650 &#61; add i64 &#37;639, &#37;16
   &#37;651 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;650
   &#37;arrayref9.47 &#61; load double, double* &#37;651, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;652 &#61; fadd double &#37;arrayref.47, &#37;arrayref9.47
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;653 &#61; add i64 &#37;639, &#37;17
   &#37;654 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;653
   store double &#37;652, double* &#37;654, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
   &#37;655 &#61; add nuw nsw i64 &#37;value_phi2, 48
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;656 &#61; add i64 &#37;647, &#37;15
   &#37;657 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;656
   &#37;arrayref.48 &#61; load double, double* &#37;657, align 8
   &#37;658 &#61; add i64 &#37;647, &#37;16
   &#37;659 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;658
   &#37;arrayref9.48 &#61; load double, double* &#37;659, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;660 &#61; fadd double &#37;arrayref.48, &#37;arrayref9.48
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;661 &#61; add i64 &#37;647, &#37;17
   &#37;662 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;661
   store double &#37;660, double* &#37;662, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ essentials.jl:14 within &#96;getindex&#96;
   &#37;663 &#61; add i64 &#37;655, &#37;15
   &#37;664 &#61; getelementptr inbounds double, double* &#37;arrayptr21, i64 &#37;663
   &#37;arrayref.49 &#61; load double, double* &#37;664, align 8
   &#37;665 &#61; add i64 &#37;655, &#37;16
   &#37;666 &#61; getelementptr inbounds double, double* &#37;arrayptr822, i64 &#37;665
   &#37;arrayref9.49 &#61; load double, double* &#37;666, align 8
; └
; ┌ @ float.jl:409 within &#96;&#43;&#96;
   &#37;667 &#61; fadd double &#37;arrayref.49, &#37;arrayref9.49
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
5 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ array.jl:1024 within &#96;setindex&#33;&#96;
   &#37;668 &#61; add i64 &#37;655, &#37;17
   &#37;669 &#61; getelementptr inbounds double, double* &#37;arrayptr1423, i64 &#37;668
   store double &#37;667, double* &#37;669, align 8
; └
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
6 within &#96;inner_noalloc_ib&#33;&#96;
; ┌ @ range.jl:901 within &#96;iterate&#96;
; │┌ @ promotion.jl:521 within &#96;&#61;&#61;&#96;
    &#37;.not.not.49 &#61; icmp eq i64 &#37;value_phi2, 51
; │└
   &#37;670 &#61; add nuw nsw i64 &#37;value_phi2, 50
; └
  br i1 &#37;.not.not.49, label &#37;L25, label &#37;L5

L25:                                              ; preds &#61; &#37;L5, &#37;vector.bo
dy.preheader
; ┌ @ range.jl:901 within &#96;iterate&#96;
; │┌ @ promotion.jl:521 within &#96;&#61;&#61;&#96;
    &#37;.not.not24 &#61; icmp eq i64 &#37;value_phi, 100
; │└
   &#37;671 &#61; add nuw nsw i64 &#37;value_phi, 1
; └
  &#37;indvar.next &#61; add i64 &#37;indvar, 1
  br i1 &#37;.not.not24, label &#37;L36, label &#37;L2

L36:                                              ; preds &#61; &#37;L25
  ret &#123;&#125;* inttoptr &#40;i64 140125612802056 to &#123;&#125;*&#41;
&#125;
</pre> <p>If you look closely, you will see things like:</p> <pre><code>&#37;wide.load24 &#61; load &lt;4 x double&gt;, &lt;4 x double&gt; addrspac&#40;13&#41;* &#37;46, align 8
; └
; ┌ @ float.jl:395 within &#96;&#43;&#39;
&#37;47 &#61; fadd &lt;4 x double&gt; &#37;wide.load, &#37;wide.load24</code></pre> <p>What this is saying is that it&#39;s loading and adding 4 <code>Float64</code>s at a time&#33; This feature of the processor is known as SIMD: single input multiple data. If certain primitive floating point operations, like <code>&#43;</code> and <code>*</code>, are done in succession &#40;i.e. no inbounds checks between them&#33;&#41;, then the processor can lump them together and do multiples at once. Since clock cycles have stopped improving while transistors have gotten smaller, this &quot;lumping&quot; has been a big source of speedups in computational mathematics even though the actual <code>&#43;</code> and <code>*</code> hasn&#39;t gotten faster. Thus to get full speed we want to make sure this is utilized whenever possible, which essentially just amounts to doing type inferred loops with no branches or bounds checks in the way.</p> <h3>FMA</h3> <p>Modern processors have a single operation that fuses the multiplication and the addition in the operation <code>x*y&#43;z</code>, known as a <em>fused multiply-add</em> or FMA. Note that FMA has less floating point roundoff error than the two operation form. We can see this intrinsic in the resulting LLVM IR:</p> <pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>fma</span><span class='hljl-p'>(</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>5.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>3.0</span><span class='hljl-p'>)</span>
</pre> <pre class=output >
;  @ floatfuncs.jl:439 within &#96;fma&#96;
define double @julia_fma_3976&#40;double &#37;0, double &#37;1, double &#37;2&#41; #0 &#123;
common.ret:
; ┌ @ floatfuncs.jl:434 within &#96;fma_llvm&#96;
   &#37;3 &#61; call double @llvm.fma.f64&#40;double &#37;0, double &#37;1, double &#37;2&#41;
; └
;  @ floatfuncs.jl within &#96;fma&#96;
  ret double &#37;3
&#125;
</pre> <p>The Julia function <code>muladd</code> will automatically choose between FMA and the original form depending on the availability of the routine in the processor. The MuladdMacro.jl package has a macro <code>@muladd</code> which pulls apart statements to add <code>muladd</code> expressions. For example, <code>x1*y1 &#43; x2*y2 &#43; x3*y3</code> can be rewritten as:</p> <pre><code>muladd&#40;x1,y1,muladd&#40;x2,y2,x3*y3&#41;&#41;</code></pre>
<p>Which reduces the linear combination to just 3 arithmetic operations. FMA operations can be SIMD&#39;d.</p>
<h3>Inlining</h3>
<p>All of this would go to waste if function call costs of 50 clock cycles were interrupting every single <code>&#43;</code>. Fortunately these function calls disappear during the compilation process due to what&#39;s known as inlining. Essentially, if the function call is determined to be &quot;cheap enough&quot;, the actual function call is removed and the code is basically pasted into the function caller. We can force a function call to occur by telling it to not inline:</p>


<pre class='hljl'>
<span class='hljl-nd'>@noinline</span><span class='hljl-t'> </span><span class='hljl-nf'>fnoinline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'>
</span><span class='hljl-nf'>finline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-cs'># Can add @inline, but this is automatic here</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>qinline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
  </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-n'>c</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>finline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>finline</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-nf'>finline</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>qnoinline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>a</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-t'>
  </span><span class='hljl-n'>b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-t'>
  </span><span class='hljl-n'>c</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>fnoinline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>a</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-n'>d</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>fnoinline</span><span class='hljl-p'>(</span><span class='hljl-n'>b</span><span class='hljl-p'>,</span><span class='hljl-n'>c</span><span class='hljl-p'>)</span><span class='hljl-t'>
  </span><span class='hljl-nf'>fnoinline</span><span class='hljl-p'>(</span><span class='hljl-n'>d</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span>
</pre>


<pre class=output >
qnoinline &#40;generic function with 1 method&#41;
</pre>



<pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>qinline</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>)</span>
</pre>


<pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
4 within &#96;qinline&#96;
define double @julia_qinline_3979&#40;double &#37;0, double &#37;1&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
7 within &#96;qinline&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:3 within &#96;finline&#96;
; │┌ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
    &#37;2 &#61; fadd double &#37;0, 4.000000e&#43;00
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
8 within &#96;qinline&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:3 within &#96;finline&#96;
; │┌ @ promotion.jl:422 within &#96;&#43;&#96; @ float.jl:409
    &#37;3 &#61; fadd double &#37;2, 2.000000e&#43;00
; └└
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
9 within &#96;qinline&#96;
; ┌ @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd
:3 within &#96;finline&#96;
; │┌ @ float.jl:409 within &#96;&#43;&#96;
    &#37;4 &#61; fadd double &#37;3, &#37;1
    ret double &#37;4
; └└
&#125;
</pre>



<pre class='hljl'>
<span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>qnoinline</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>)</span>
</pre>


<pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
11 within &#96;qnoinline&#96;
define double @julia_qnoinline_3981&#40;double &#37;0, double &#37;1&#41; #0 &#123;
top:
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
14 within &#96;qnoinline&#96;
  &#37;2 &#61; call double @j_fnoinline_3983&#40;double &#37;0, i64 signext 4&#41;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
15 within &#96;qnoinline&#96;
  &#37;3 &#61; call double @j_fnoinline_3984&#40;i64 signext 2, double &#37;2&#41;
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
16 within &#96;qnoinline&#96;
  &#37;4 &#61; call double @j_fnoinline_3985&#40;double &#37;3, double &#37;1&#41;
  ret double &#37;4
&#125;
</pre>


<p>We can see now that it keeps the function calls:</p>
<pre><code>&#37;4 &#61; call double @julia_fnoinline_21538&#40;double &#37;3, double &#37;1&#41;</code></pre>
<p>and this is slower in comparison to what we had before &#40;but it still infers&#41;.</p>


<pre class='hljl'>
<span class='hljl-n'>x</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>1.0</span><span class='hljl-t'>
</span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>2.0</span><span class='hljl-t'>
</span><span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>qinline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span>
</pre>


<pre class=output >
19.505 ns &#40;1 allocation: 16 bytes&#41;
9.0
</pre>



<pre class='hljl'>
<span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>qnoinline</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>y</span><span class='hljl-p'>)</span>
</pre>


<pre class=output >
24.110 ns &#40;1 allocation: 16 bytes&#41;
9.0
</pre>


<p>Note that if we ever want to go the other direction and tell Julia to inline as much as possible, one can use the macro <code>@inline</code>.</p>
<h3>Summary</h3>
<ul>
<li><p>Scalar operations are super cheap, and if they are cache-aligned then more than one will occur in a clock cycle.</p>

<li><p>Inlining a function will remove the high function call overhead.</p>

<li><p>Branch prediction is pretty good these days, so keep them out of super tight inner loops but don&#39;t worry all too much about them.</p>

<li><p>Cache misses are quite expensive the further out it goes.</p>

</ul>
<h2>Note on Benchmarking</h2>
<p>Julia&#39;s compiler is smart. This means that if you don&#39;t try hard enough, Julia&#39;s compiler might get rid of your issues. For example, it can delete branches and directly compute the result if all of the values are known at compile time. So be very careful when benchmarking: your tests may have just compiled away&#33;</p>
<p>Notice the following:</p>


<pre class='hljl'>
<span class='hljl-nd'>@btime</span><span class='hljl-t'> </span><span class='hljl-nf'>qinline</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>)</span>
</pre>


<pre class=output >
1.552 ns &#40;0 allocations: 0 bytes&#41;
9.0
</pre>


<p>Dang, that&#39;s much faster&#33; But if you look into it, Julia&#39;s compiler is actually &quot;cheating&quot; on this benchmark:</p>


<pre class='hljl'>
<span class='hljl-nf'>cheat</span><span class='hljl-p'>()</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>qinline</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-p'>,</span><span class='hljl-nfB'>2.0</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-nd'>@code_llvm</span><span class='hljl-t'> </span><span class='hljl-nf'>cheat</span><span class='hljl-p'>()</span>
</pre>


<pre class=output >
;  @ /home/runner/work/SciMLBook/SciMLBook/_weave/lecture02/optimizing.jmd:
2 within &#96;cheat&#96;
define double @julia_cheat_4013&#40;&#41; #0 &#123;
top:
  ret double 9.000000e&#43;00
&#125;
</pre>


<p>It realized that <code>1.0</code> and <code>2.0</code> are constants, so it did what&#39;s known as <em>constant propagation</em>, and then used those constants inside of the function. It realized that the solution is always <code>9</code>, so it compiled the function that... spits out <code>9</code>&#33; So it&#39;s fast because it&#39;s not computing anything. So be very careful about propagation of constants and literals. In general this is a very helpful feature, but when benchmarking this can cause some weird behavior. If a micro benchmark is taking less than a nanosecond, check and see if the compiler &quot;fixed&quot; your code&#33;</p>
<h2>Conclusion</h2>
<p>Optimize your serial code before you parallelize. There&#39;s a lot to think about.</p>
<h1>Discussion Questions</h1>
<p>Here&#39;s a few discussion questions to think about performance engineering in scientific tasks:</p>
<ol>
<li><p>What are the advantages of a <code>Vector&#123;Array&#125;</code> vs a <code>Matrix</code>? What are the disadvantage? &#40;What&#39;s different?&#41;</p>

<li><p>What is a good way to implement a data frame?</p>

<li><p>What are some good things that come out of generic functions for free? What are some things you should watch out for with generic functions?</p>

</ol>


<div class=footer >
  <p>
    Published from <a href=optimizing.jmd >optimizing.jmd</a>
    using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.12 on 2024-10-01.
  </p>
</div>

<div class=back-to-top >
  <span><a href="#" title="Back to Top"><i class="fa fa-chevron-circle-up"></i></a></span>
</div>


</div>
        </div> 
    </div>